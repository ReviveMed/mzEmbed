{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version:  1.3.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "\n",
    "from misc import save_json, get_dropbox_dir\n",
    "\n",
    "\n",
    "import sklearn\n",
    "print('sklearn version: ', sklearn.__version__)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sklearn_fitter(data_dict, param_grid, \n",
    "                      output_dir, model_kind, model_name,\n",
    "                      cv=None, n_iter=10, scoring_func=None, verbose=0):\n",
    "    if cv is None:\n",
    "        cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=20, random_state=42)\n",
    "    \n",
    "    if scoring_func is None:\n",
    "        # depends on which sklearn version we are using\n",
    "        # scoring_func = make_scorer(roc_auc_score, average='weighted', response_method='predict_proba')\n",
    "        scoring_func = make_scorer(roc_auc_score, average='weighted', needs_proba=True)\n",
    "\n",
    "    if model_kind == 'logistic_regression':\n",
    "        base_model = LogisticRegression(max_iter=1000)\n",
    "    elif model_kind == 'random_forest':\n",
    "        base_model = RandomForestClassifier()\n",
    "    elif model_kind == 'decision_tree':\n",
    "        base_model = DecisionTreeClassifier()\n",
    "    elif model_kind == 'svc':\n",
    "        base_model = SVC(probability=True)\n",
    "\n",
    "    model = RandomizedSearchCV(base_model, \n",
    "                               param_distributions=param_grid, \n",
    "                               n_iter=n_iter, \n",
    "                               cv=cv, \n",
    "                               scoring=scoring_func, \n",
    "                               verbose=verbose, \n",
    "                               random_state=1010,\n",
    "                               n_jobs=1)\n",
    "    X_train, y_train = data_dict['X_train'], data_dict['y_train']\n",
    "    X_val, y_val = data_dict['X_val'], data_dict['y_val']\n",
    "    X_test, y_test = data_dict['X_test'], data_dict['y_test']\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    model_results = pd.DataFrame(model.cv_results_)\n",
    "\n",
    "    model_results.sort_values('rank_test_score', inplace=True)\n",
    "    model_results.iloc[0]['mean_test_score']\n",
    "    cv_score = model_results.iloc[0]['mean_test_score']\n",
    "    cv_score_std = model_results.iloc[0]['std_test_score']\n",
    "    print(f'Train CV score: {cv_score} +/- {cv_score_std}')\n",
    "\n",
    "\n",
    "    y_train_proba = model.predict_proba(X_train)[:,1]\n",
    "    train_score = roc_auc_score(y_train, y_train_proba, average='weighted')\n",
    "    print(f'Training score: {train_score}')\n",
    "\n",
    "\n",
    "    y_val_proba = model.predict_proba(X_val)[:,1]\n",
    "    val_score = roc_auc_score(y_val, y_val_proba, average='weighted')\n",
    "    print(f'Validation score: {val_score}')\n",
    "\n",
    "\n",
    "    y_test_proba = model.predict_proba(X_test)[:,1]\n",
    "    test_score = roc_auc_score(y_test, y_test_proba, average='weighted')\n",
    "    print(f'Test score: {test_score}')\n",
    "\n",
    "\n",
    "    model_summary = {\n",
    "        'model_kind': model_kind,\n",
    "        'model_name': model_name,\n",
    "        'n_input ft': X_train.shape[1],\n",
    "        'param_grid' : param_grid,\n",
    "        'best_params': model.best_params_,\n",
    "        'score name': 'roc_auc (weighted)',\n",
    "        'cv_score': cv_score,\n",
    "        'cv_score_std': cv_score_std,\n",
    "        'train_score': train_score,\n",
    "        'val_score': val_score,\n",
    "        'test_score': test_score,\n",
    "        'train sz': X_train.shape[0],\n",
    "        'val sz': X_val.shape[0],\n",
    "        'test sz': X_test.shape[0],\n",
    "        'n_trials': n_iter,\n",
    "        'n_folds': cv.get_n_splits(),\n",
    "    }\n",
    "\n",
    "    save_json(model_summary, os.path.join(output_dir, f'{model_name}_summary.json'))\n",
    "\n",
    "    return model_summary\n",
    "\n",
    "\n",
    "dropbox_dir = get_dropbox_dir()\n",
    "base_dir = os.path.join(dropbox_dir, 'development_CohortCombination','alignment_RCC_2024_Feb_27')\n",
    "\n",
    "ref_freq = 0.6\n",
    "# input_freq = 0.1\n",
    "grid_id = 1\n",
    "matt_ft_dir = os.path.join(base_dir, 'matt_top_fts')\n",
    "\n",
    "# %%\n",
    "def get_key_ft_dct():\n",
    "\n",
    "    matt_ft_files = os.listdir(matt_ft_dir)\n",
    "    matt_ft_files = [f for f in matt_ft_files if f.endswith('.txt')]\n",
    "\n",
    "    matt_ft_dict = {}\n",
    "    for f in matt_ft_files:\n",
    "        ft_name = f.split('_feats')[0]\n",
    "        # with open(os.path.join(matt_ft_dir, f), 'r') as file:\n",
    "        #     ft = file.read().split(', ')\n",
    "        # if len(ft) == 1:\n",
    "        with open(os.path.join(matt_ft_dir, f), 'r') as file:\n",
    "            ft = file.read().splitlines()\n",
    "            # print(file.read()\n",
    "        # remove all of the ', and commas from the strings in the list\n",
    "        ft = [x.strip(',').strip(' ').strip('\"').strip(\"'\").strip('\\n').strip('\\t') for x in ft]\n",
    "        matt_ft_dict[ft_name] = ft\n",
    "        # break\n",
    "        print(ft_name + ': ' + str(len(ft)))\n",
    "\n",
    "    # %% [markdown]\n",
    "    # ### RCC Target Metabolites\n",
    "\n",
    "    # %%\n",
    "    # %%\n",
    "    rcc_peak_info_file = os.path.join(base_dir, 'rcc_result', 'peak_info.csv')\n",
    "    rcc_peak_info_df = pd.read_csv(rcc_peak_info_file, index_col=0)\n",
    "\n",
    "    rcc_peak_info_df = rcc_peak_info_df[rcc_peak_info_df['freq'] >= ref_freq].copy()\n",
    "\n",
    "    print(f'Number of peaks in the reference cohort after {ref_freq} filter: ', rcc_peak_info_df.shape[0])\n",
    "\n",
    "        \n",
    "    rcc_matched_targets_file = os.path.join(base_dir,'rcc_result', 'matched_targets HILIC POSITIVE ION MODE.csv')\n",
    "    rcc_matched_targets_df = pd.read_csv(rcc_matched_targets_file, index_col=0)\n",
    "    rcc_matched_targets_df.loc[rcc_peak_info_df.index]\n",
    "\n",
    "    potential_feats = rcc_matched_targets_df[rcc_matched_targets_df['potential_target']].index.to_list()\n",
    "    print('Number of features that potentially match to a target metabolite: ', len(potential_feats))\n",
    "\n",
    "    double_match_ids = rcc_matched_targets_df[rcc_matched_targets_df['potential_target_count'] > 1]\n",
    "    num_double_match = double_match_ids.shape[0]\n",
    "    print('Number of features that potentially match to more than one target metabolite: ', double_match_ids.shape[0])\n",
    "    print(rcc_matched_targets_df.loc[double_match_ids.index, 'potential_target_id'])\n",
    "\n",
    "    # here are the double matches in RCC, two are the same metabolite (but different adducts?)\n",
    "    # FT3202                           tryptophanTryptophan_μM\n",
    "    # FT3237                           kynurenineKynurenine_μM\n",
    "    # FT8451    C18:1 LPC plasmalogen_AC18:1 LPC plasmalogen_B\n",
    "\n",
    "\n",
    "    potential_feat_names = rcc_matched_targets_df.loc[potential_feats]['potential_target_id'].unique()\n",
    "    # print('Number of potential feature names: ', len(potential_feat_names))\n",
    "    print(potential_feat_names)\n",
    "\n",
    "    print('Number of target metabolite captured: ', len(potential_feat_names))\n",
    "\n",
    "    # for now don't remove the double counts, since they are NOT actually double counts\n",
    "    num_rcc_targets_found =  len(potential_feat_names)\n",
    "    rcc_target_feats = potential_feats\n",
    "\n",
    "    # add to the matt ft dictionary\n",
    "    matt_ft_dict['rcc_targets'] = rcc_target_feats\n",
    "\n",
    "    return matt_ft_dict, rcc_peak_info_df\n",
    "\n",
    "\n",
    "# Helper functions to finding the number and percentage of captured features\n",
    "def get_captured_fts(matt_ft_list, align_ft_list):\n",
    "    captured_fts = [ft for ft in matt_ft_list if ft in align_ft_list]\n",
    "    return captured_fts\n",
    "\n",
    "def get_captured_perc(matt_ft_list, align_ft_list):\n",
    "    captured_fts = get_captured_fts(matt_ft_list, align_ft_list)\n",
    "    matt_capture_perc = len(captured_fts) / len(matt_ft_list)\n",
    "    align_capture_perc = len(captured_fts) / len(align_ft_list)\n",
    "    return matt_capture_perc, align_capture_perc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_with_val(model, data_dict, param_grid,n_iter=20):\n",
    "    \n",
    "    all_res = []\n",
    "    \n",
    "    # cycle over all parameter combinations\n",
    "    param_combinations = []\n",
    "    for iter in range(3*n_iter):\n",
    "        param_kwargs = {}\n",
    "        for param_name in param_grid.keys():\n",
    "            param_kwargs[param_name] = np.random.choice(param_grid[param_name])\n",
    "\n",
    "        param_combinations.append(param_kwargs)\n",
    "\n",
    "    #remove duplicates\n",
    "    param_combinations = [dict(t) for t in {tuple(d.items()) for d in param_combinations}]\n",
    "    print(len(param_combinations))\n",
    "    if len(param_combinations) > n_iter:\n",
    "        param_combinations = param_combinations[:n_iter]\n",
    "\n",
    "    X_train, y_train = data_dict['X_train'], data_dict['y_train']\n",
    "    X_val, y_val = data_dict['X_val'], data_dict['y_val']\n",
    "    X_test, y_test = data_dict['X_test'], data_dict['y_test']\n",
    "\n",
    "\n",
    "    for model_param in param_combinations:\n",
    "\n",
    "        param = {k:v for k,v in model_param.items()}\n",
    "        model.set_params(**model_param)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_proba = model.predict_proba(X_train)[:,1]\n",
    "        train_score = roc_auc_score(y_train, y_train_proba, average='weighted')\n",
    "        param['train_score (fit on train)'] = train_score\n",
    "\n",
    "\n",
    "        y_val_proba = model.predict_proba(X_val)[:,1]\n",
    "        val_score = roc_auc_score(y_val, y_val_proba, average='weighted')\n",
    "        param['val_score (fit on train)'] = val_score\n",
    "\n",
    "        y_test_proba = model.predict_proba(X_test)[:,1]\n",
    "        test_score = roc_auc_score(y_test, y_test_proba, average='weighted')\n",
    "        param['test_score (fit on train)'] = test_score\n",
    "\n",
    "        # join the train and val sets\n",
    "        X_train_val = pd.concat([X_train, X_val], axis=0)\n",
    "        y_train_val = pd.concat([y_train, y_val], axis=0)\n",
    "        model.fit(X_train_val, y_train_val)\n",
    "        y_test_proba = model.predict_proba(X_test)[:,1]\n",
    "        test_score2 = roc_auc_score(y_test, y_test_proba, average='weighted')\n",
    "        param['test_score (fit on train+val)'] = test_score2\n",
    "\n",
    "        all_res.append(param)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    res_summary = pd.DataFrame(all_res)\n",
    "    res_summary['train sz'] = X_train.shape[0]\n",
    "    res_summary['val sz'] = X_val.shape[0]\n",
    "    res_summary['test sz'] = X_test.shape[0]\n",
    "    res_summary['n_trials'] = n_iter\n",
    "    res_summary['n_peaks'] = X_train.shape[1]\n",
    "\n",
    "    return res_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_dir = '/Users/jonaheaton/ReviveMed Dropbox/Jonah Eaton/development_CohortCombination/alignment_RCC_2024_Feb_27/March_12_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_10: 10\n",
      "top_25: 25\n",
      "168_os_pfs: 168\n",
      "net_matched: 86\n",
      "Number of peaks in the reference cohort after 0.6 filter:  4016\n",
      "Number of features that potentially match to a target metabolite:  188\n",
      "Number of features that potentially match to more than one target metabolite:  3\n",
      "feats\n",
      "FT3202                           tryptophanTryptophan_μM\n",
      "FT3237                           kynurenineKynurenine_μM\n",
      "FT8451    C18:1 LPC plasmalogen_AC18:1 LPC plasmalogen_B\n",
      "Name: potential_target_id, dtype: object\n",
      "['trimethylamine-N-oxide' 'alanine' 'GABA' 'serine' 'hypotaurine'\n",
      " 'cytosine' 'creatinine' 'betaine' 'threonine' 'niacinamide' 'taurine'\n",
      " 'ornithine' 'N-acetylalanine' 'N-carbamoyl-beta-alanine'\n",
      " 'N-methylproline' 'leucine' 'hydroxyproline' 'N-acetylputrescine'\n",
      " '1-methylnicotinamide' 'trigonelline' 'anthranilic acid' 'urocanic acid'\n",
      " 'imidazole propionate' 'ectoine' 'proline-betaine' 'glutamate'\n",
      " '4-acetamidobutanoate' 'butyrobetaine' 'glutamine' 'lysine' 'methionine'\n",
      " 'N1-methyl-2-pyridone-5-carboxamide' '4-hydroxy-3-methylacetophenone'\n",
      " 'guanine' 'allantoin' 'carnitine' '2-aminooctanoate' 'urate'\n",
      " '7-methylguanine' '3-methylxanthine' 'phenylalanine' 'N-acetylleucine'\n",
      " '3-methylhistidine' 'serotonin' 'citrulline' 'N6,N6-dimethyllysine'\n",
      " 'N-acetylornithine' 'cotinine' '5-hydroxytryptophol' 'arginine'\n",
      " 'tyrosine' 'hippurate' '4-pyridoxate' 'N6-acetyllysine'\n",
      " 'N6,N6,N6-trimethyllysine' 'N1-acetylspermidine' 'NMMA' 'kynurenic acid'\n",
      " 'N-acetylmethionine' 'hydroxycotinine' 'caffeine' '4-hydroxyhippurate'\n",
      " '1,7-dimethyluric acid' 'DMGV' 'SDMA' 'C2 carnitine'\n",
      " 'tryptophanTryptophan_μM' 'kynurenineKynurenine_μM' 'pantothenol'\n",
      " 'cinnamoylglycine' 'N-alpha-acetylarginine' 'C3 carnitine'\n",
      " 'acetyl-galactosamine' '5-hydroxytryptophan' 'pantothenate'\n",
      " 'myristoleate' 'C4 carnitine' 'C5:1 carnitine' 'C5 carnitine'\n",
      " 'C4-OH carnitine' 'N-acetyltryptophan' 'pseudouridine' 'ribothymidine'\n",
      " 'alpha-glycerophosphocholine' 'C3-DC-CH3 carnitine' 'C6 carnitine'\n",
      " 'thiamine' 'inosine' 'atenolol' 'metoprolol' 'phenylacetylglutamine'\n",
      " 'C5-DC carnitine' '1-methyladenosine' 'diacetylspermine'\n",
      " 'N4-acetylcytidine' 'C8 carnitine' 'piperine' '1-methylguanosine'\n",
      " 'C9 carnitine' 'sphinganine' 'threo-sphingosine' 'warfarin'\n",
      " '3-(N-acetyl-L-cystein-S-yl) acetaminophen' 'C10 carnitine'\n",
      " 'linoleoyl ethanolamide' 'acetaminophen glucuronide' 'C12 carnitine'\n",
      " 'C12:1 carnitine' 'oleoyl glycine' 'cortisol' 'cortisone'\n",
      " 'C14:1 carnitine' 'C14 carnitine' 'C16 carnitine' 'C18:2 carnitine'\n",
      " 'C18 carnitine' 'C18:1 carnitine' 'valsartan' 'C20:4 carnitine'\n",
      " 'glycodeoxycholate/glycochenodeoxycholate' 'C16:0 LPE' 'C14:0 LPC'\n",
      " 'glycocholate' 'C18:2 LPE' 'C18:1 LPE' 'C18:0 LPE'\n",
      " 'C16:1 LPC plasmalogen' 'C16:1 LPC' 'C16:0 LPC' 'C20:4 LPE'\n",
      " 'C18:1 LPC plasmalogen_B'\n",
      " 'C18:1 LPC plasmalogen_AC18:1 LPC plasmalogen_B' 'C20:0 LPE' 'C18:3 LPC'\n",
      " 'C18:0 LPC' 'C18:1 LPC' 'C22:6 LPE' 'C16:0 ceramide (d18:1)'\n",
      " 'C26 carnitine' 'C20:4 LPC' 'C20:5 LPC' 'C22:6 LPC' 'C22:5 LPC'\n",
      " 'biliverdin' 'bilirubin' 'urobilinogen' 'C34:1 DAG' 'C34:2 DAG'\n",
      " 'C34:1 DAG*' 'C24:1 ceramide (d18:1)' 'C14:0 SM' 'C34:3 PE plasmalogen'\n",
      " 'C34:2 PE plasmalogen' 'C16:0 SM' 'C16:1 SM' 'C30:0 PC' 'C34:2 PE'\n",
      " 'C36:5 PE plasmalogen' 'C34:0 PE' 'C18:1 SM' 'C36:3 PE plasmalogen'\n",
      " 'C32:2 PC' 'C18:0 SM' 'C34:3 PC plasmalogen' 'C36:4 PE' 'C36:2 PE'\n",
      " 'C38:7 PE plasmalogen' 'C38:5 PE plasmalogen' 'C38:6 PE plasmalogen'\n",
      " 'C34:4 PC' 'C20:0 SM' 'C34:3 PC' 'C38:6 PE' 'C38:4 PE'\n",
      " 'C36:5 PC plasmalogen' 'C36:2 PS plasmalogen' 'thyroxine'\n",
      " 'C40:7 PE plasmalogen' 'C36:2 PC' 'C38:6 PC plasmalogen' 'C40:6 PE'\n",
      " 'C38:7 PC plasmalogen']\n",
      "Number of target metabolite captured:  182\n"
     ]
    }
   ],
   "source": [
    "matt_ft_dict, rcc_peak_info_df = get_key_ft_dct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = pd.read_csv(os.path.join(subset_dir, 'X.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_mask = pd.read_csv(os.path.join(subset_dir, 'nans.csv'), index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = pd.read_csv(os.path.join(subset_dir, 'y.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples:  17685\n",
      "number of features:  2736\n"
     ]
    }
   ],
   "source": [
    "print('number of samples: ', X_data.shape[0])\n",
    "print('number of features: ', X_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_files = y_data[y_data['Set']=='Pretrain'].index.to_list()\n",
    "finetune_files = y_data[y_data['Set']=='Finetune'].index.to_list()\n",
    "holdout_test_files = y_data[y_data['Set']=='Test'].index.to_list()\n",
    "holdout_val_files = y_data[y_data['Set']=='Validation'].index.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2736, 3)\n"
     ]
    }
   ],
   "source": [
    "finetune_freq = 1 - nan_mask.loc[finetune_files].sum(axis=0)/ len(finetune_files)\n",
    "pretrain_freq = 1- nan_mask.loc[pretrain_files].sum(axis=0)/ len(pretrain_files)\n",
    "finetune_var = X_data.loc[finetune_files].var(axis=0)\n",
    "\n",
    "temp = pd.concat([finetune_freq, pretrain_freq, finetune_var], axis=1)\n",
    "temp.columns = ['finetune_freq', 'pretrain_freq', 'finetune_var']\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the peaks of size  2736\n",
      "Number of top_10 captured: 10 out of 10: 1.00\n",
      "Number of top_25 captured: 23 out of 25: 0.92\n",
      "Number of 168_os_pfs captured: 134 out of 168: 0.80\n",
      "Number of net_matched captured: 73 out of 86: 0.85\n",
      "Number of rcc_targets captured: 159 out of 188: 0.85\n"
     ]
    }
   ],
   "source": [
    "# check that the Matt feats are found in the RCC peaks\n",
    "print('In the peaks of size ', temp.shape[0])\n",
    "for matt_ft_name, matt_ft_list in matt_ft_dict.items():\n",
    "    captured_peaks = get_captured_fts(matt_ft_list, temp.index)\n",
    "    print(f'Number of {matt_ft_name} captured: {len(captured_peaks)} out of {len(matt_ft_list)}: {len(captured_peaks)/len(matt_ft_list):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jonaheaton/ReviveMed Dropbox/Jonah Eaton/development_CohortCombination/alignment_RCC_2024_Feb_27/March_12_Data'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a splits csv file that is just the validation data\n",
    "\n",
    "stratify_col = 'MSKCC BINARY'\n",
    "splits_dir = os.path.join(subset_dir, f'{stratify_col} predefined_val')\n",
    "os.makedirs(splits_dir, exist_ok=True)\n",
    "n_repeats = 100\n",
    "yes_remove_nans = True\n",
    "finetuen_and_val = finetune_files + holdout_val_files\n",
    "\n",
    "metadata_subset = y_data.loc[finetuen_and_val].copy()\n",
    "\n",
    "# check for nans\n",
    "if metadata_subset[stratify_col].isna().any():\n",
    "    if yes_remove_nans:\n",
    "        metadata_subset = metadata_subset[~metadata_subset[stratify_col].isna()]\n",
    "    else:\n",
    "        print('There are nans in the stratify column')\n",
    "        fill_val = metadata_subset[stratify_col].max() + 1\n",
    "        metadata_subset[stratify_col] = metadata_subset[stratify_col].fillna(fill_val)\n",
    "\n",
    "\n",
    "\n",
    "rskf_df = pd.DataFrame(index=finetuen_and_val)\n",
    "\n",
    "for i in range(n_repeats):\n",
    "    rskf_df[f'fold_{i}'] = False\n",
    "    rskf_df.loc[holdout_val_files, f'fold_{i}'] = True\n",
    "\n",
    "\n",
    "rskf_df.to_csv(os.path.join(splits_dir, 'splits.csv'))\n",
    "\n",
    "rskf_info = {\n",
    "    'rskf_params': None,\n",
    "    'stratify_col': stratify_col,\n",
    "    'size': rskf_df.shape[0],\n",
    "    'Train Bool' : False,\n",
    "    'Test Bool' : True,\n",
    "    'remove nans': yes_remove_nans\n",
    "}\n",
    "\n",
    "with open(os.path.join(splits_dir, 'splits_info.json'), 'w') as f:\n",
    "    json.dump(rskf_info, f, indent=4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_splits': 5, 'n_repeats': 1, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "stratify_col = 'MSKCC BINARY'\n",
    "splits_dir = os.path.join(subset_dir, f'{stratify_col} finetune_folds')\n",
    "\n",
    "# although 50 splits were created, only 5 are used for finetuning\n",
    "\n",
    "# with open(os.path.join(splits_dir, 'split_info.json'), 'r') as f:\n",
    "with open(os.path.join(splits_dir, 'splits_info_classical.json'), 'r') as f:\n",
    "    rskf_info = json.load(f)\n",
    "\n",
    "rskf_params = rskf_info['rskf_params']\n",
    "print(rskf_params)\n",
    "\n",
    "rskf_params['n_repeats'] = 100\n",
    "rskf = RepeatedStratifiedKFold(**rskf_params)\n",
    "\n",
    "splits = pd.read_csv(os.path.join(splits_dir, 'splits.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_dropna = True #drops nan values from the label column\n",
    "\n",
    "finetune_label_col = 'MSKCC BINARY'\n",
    "\n",
    "task_dir = os.path.join(splits_dir, finetune_label_col)\n",
    "os.makedirs(task_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8965741889899261\n",
      "(930, 3)\n",
      "In the peaks of size  930\n",
      "Number of top_10 captured: 2 out of 10: 0.20\n",
      "Number of top_25 captured: 9 out of 25: 0.36\n",
      "Number of 168_os_pfs captured: 50 out of 168: 0.30\n",
      "Number of net_matched captured: 25 out of 86: 0.29\n",
      "Number of rcc_targets captured: 80 out of 188: 0.43\n",
      "Overall frequency of chosen features: 0.549\n"
     ]
    }
   ],
   "source": [
    "finetune_var_q = 0.05\n",
    "# finetune_var_q = 0.05 # meant to use this one, but forgot to change it in the NN optimization\n",
    "finetune_var_th = temp['finetune_var'].quantile(finetune_var_q)\n",
    "print(finetune_var_th)\n",
    "# finetune_var_th = 0.5#0.75\n",
    "finetune_freq_th = 0.9\n",
    "pretrain_freq_th = 0.3 #0.35\n",
    "\n",
    "finetune_filter = (finetune_var >= finetune_var_th) & (finetune_freq >= finetune_freq_th) & (pretrain_freq >= pretrain_freq_th)\n",
    "\n",
    "temp_filter = temp[finetune_filter]\n",
    "print(temp_filter.shape)\n",
    "chosen_feats = temp_filter.index.to_list()\n",
    "all_feats = temp.index.to_list()\n",
    "\n",
    "\n",
    "print('In the peaks of size ', temp_filter.shape[0])\n",
    "for matt_ft_name, matt_ft_list in matt_ft_dict.items():\n",
    "    captured_peaks = get_captured_fts(matt_ft_list, temp_filter.index)\n",
    "    print(f'Number of {matt_ft_name} captured: {len(captured_peaks)} out of {len(matt_ft_list)}: {len(captured_peaks)/len(matt_ft_list):.2f}')\n",
    "\n",
    "\n",
    "overall_freq = (1 - nan_mask[chosen_feats].mean(axis=0)).mean()\n",
    "print(f'Overall frequency of chosen features: {overall_freq:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9353629930755045\n",
      "(878, 3)\n",
      "In the peaks of size  878\n",
      "Number of top_10 captured: 1 out of 10: 0.10\n",
      "Number of top_25 captured: 7 out of 25: 0.28\n",
      "Number of 168_os_pfs captured: 43 out of 168: 0.26\n",
      "Number of net_matched captured: 21 out of 86: 0.24\n",
      "Number of rcc_targets captured: 73 out of 188: 0.39\n"
     ]
    }
   ],
   "source": [
    "finetune_var_q = 0.1\n",
    "# finetune_var_q = 0.05 # meant to use this one, but forgot to change it in the NN optimization\n",
    "finetune_var_th = temp['finetune_var'].quantile(finetune_var_q)\n",
    "print(finetune_var_th)\n",
    "# finetune_var_th = 0.5#0.75\n",
    "finetune_freq_th = 0.9\n",
    "pretrain_freq_th = 0.3 #0.35\n",
    "\n",
    "finetune_filter = (finetune_var >= finetune_var_th) & (finetune_freq >= finetune_freq_th) & (pretrain_freq >= pretrain_freq_th)\n",
    "\n",
    "temp_filter = temp[finetune_filter]\n",
    "print(temp_filter.shape)\n",
    "filtered_feats = temp_filter.index.to_list()\n",
    "all_feats = temp.index.to_list()\n",
    "\n",
    "\n",
    "print('In the peaks of size ', temp_filter.shape[0])\n",
    "for matt_ft_name, matt_ft_list in matt_ft_dict.items():\n",
    "    captured_peaks = get_captured_fts(matt_ft_list, temp_filter.index)\n",
    "    print(f'Number of {matt_ft_name} captured: {len(captured_peaks)} out of {len(matt_ft_list)}: {len(captured_peaks)/len(matt_ft_list):.2f}')\n",
    "\n",
    "overall_freq = (1 - nan_mask[chosen_feats].mean(axis=0)).mean()\n",
    "print(f'Overall frequency of chosen features: {overall_freq:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Train, Val, and Test data sets\n",
    "\n",
    "X_train = X_data.loc[finetune_files]\n",
    "y_train = y_data.loc[finetune_files, finetune_label_col]\n",
    "y_train = y_train.dropna()\n",
    "X_train = X_train.loc[y_train.index]\n",
    "\n",
    "\n",
    "X_val = X_data.loc[holdout_val_files]\n",
    "y_val = y_data.loc[holdout_val_files, finetune_label_col]\n",
    "y_val = y_val.dropna()\n",
    "X_val = X_val.loc[y_val.index]\n",
    "\n",
    "\n",
    "X_test = X_data.loc[holdout_test_files]\n",
    "y_test = y_data.loc[holdout_test_files, finetune_label_col]\n",
    "y_test = y_test.dropna()\n",
    "X_test = X_test.loc[y_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_param_grid = {\n",
    "            # 'penalty': ['l1', 'l2'],\n",
    "            # 'solver' : ['liblinear'],\n",
    "            'penalty': ['elastic'],\n",
    "            'l1_ratio': [0, 0.25, 0.33, 0.5, 0.66, 0.75, 1],\n",
    "            'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10],\n",
    "            'class_weight': ['balanced']\n",
    "            }\n",
    "\n",
    "random_forest_param_grid = {\n",
    "                'n_estimators': [10, 20, 50, 100, 200, 400],\n",
    "                'max_depth': [2, 3, 5, 10, None],\n",
    "                'min_samples_split': [0.05, 0.1, 0.2, 2, 5, 7, 10],\n",
    "                'min_samples_leaf': [0.025, 0.05, 0.1, 2, 4, 6, 8],\n",
    "                'bootstrap': [True, False],\n",
    "                'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                'ccp_alpha': [0, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "                'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "decision_tree_param_grid = {\n",
    "                'max_depth': [2, 3, 5, 10, None],\n",
    "                'min_samples_split': [0.05, 0.1, 0.2, 2, 5, 7, 10],\n",
    "                'min_samples_leaf': [0.025, 0.05, 0.1, 2, 4, 6, 8],\n",
    "                'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "svc_param_grid = {\n",
    "                'C': [0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 0.66, 1, 1.5, 2, 5, 10],\n",
    "                'kernel': ['linear', 'rbf', 'poly'], \n",
    "                'gamma': ['scale', 'auto'],\n",
    "                # 'early_stopping': [True],\n",
    "                'class_weight': ['balanced'],\n",
    "                'probability': [True]\n",
    "                # 'validation_fraction': [0.1, 0.2]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression\n",
      "filtered peaks\n",
      "logistic_regression optimal_filtered peaks already exists\n",
      "Test score: 0.8778280542986425\n",
      "all peaks\n",
      "logistic_regression optimal_all peaks already exists\n",
      "Test score: 0.9193061840120663\n",
      "svc\n",
      "filtered peaks\n",
      "svc optimal_filtered peaks already exists\n",
      "Test score: 0.9087481146304676\n",
      "all peaks\n",
      "svc optimal_all peaks already exists\n",
      "Test score: 0.9147812971342382\n"
     ]
    }
   ],
   "source": [
    "# param_grids = [logistic_regression_param_grid]#, random_forest_param_grid, svc_param_grid]\n",
    "# model_kinds = ['logistic_regression']#, 'random_forest', 'svc']\n",
    "\n",
    "param_grids = [logistic_regression_param_grid,svc_param_grid]\n",
    "model_kinds = ['logistic_regression','svc']\n",
    "\n",
    "feat_filt_names = ['filtered peaks', 'all peaks']\n",
    "chosen_fts_list = [filtered_feats, all_feats]\n",
    "output_dir = os.path.join(task_dir, 'classical_models_alt2')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for param_grid, model_kind in zip(param_grids, model_kinds):\n",
    "    print(model_kind)\n",
    "    for feat_filt_name, chosen_fts in zip(feat_filt_names, chosen_fts_list):\n",
    "        print(feat_filt_name)\n",
    "        model_name = f'{model_kind} optimal'  + f'_{feat_filt_name}'\n",
    "\n",
    "        data_dict = {'X_train': X_train[chosen_fts], \n",
    "                    'y_train': y_train, \n",
    "                    'X_val': X_val[chosen_fts], \n",
    "                    'y_val': y_val, \n",
    "                    'X_test': X_test[chosen_fts], \n",
    "                    'y_test': y_test}\n",
    "\n",
    "        if os.path.exists(os.path.join(output_dir, f'{model_name}_summary.json')):\n",
    "            print(f'{model_name} already exists')\n",
    "            \n",
    "            with open(os.path.join(output_dir, f'{model_name}_summary.json'), 'r') as f:\n",
    "                model_summary = json.load(f)\n",
    "\n",
    "            param_kwargs = model_summary['best_params']\n",
    "\n",
    "            if model_kind == 'logistic_regression':\n",
    "                base_model = LogisticRegression(max_iter=1000)\n",
    "            elif model_kind == 'random_forest':\n",
    "                base_model = RandomForestClassifier()\n",
    "            elif model_kind == 'decision_tree':\n",
    "                base_model = DecisionTreeClassifier()\n",
    "            elif model_kind == 'svc':\n",
    "                base_model = SVC(probability=True)\n",
    "\n",
    "            model = base_model.set_params(**param_kwargs)\n",
    "            X_both = pd.concat([data_dict['X_train'], data_dict['X_val']], axis=0)\n",
    "            y_both = pd.concat([data_dict['y_train'], data_dict['y_val']], axis=0)\n",
    "            model.fit(X_both, y_both)\n",
    "            y_test_proba = model.predict_proba(data_dict['X_test'])[:,1]\n",
    "            test_score = roc_auc_score(data_dict['y_test'], y_test_proba, average='weighted')\n",
    "            print(f'Test score: {test_score}')\n",
    "            model_summary['test_score (fit on train and val)'] = test_score\n",
    "            save_json(model_summary, os.path.join(output_dir, f'{model_name}_summary2.json'))\n",
    "\n",
    "        else:\n",
    "            out = my_sklearn_fitter(data_dict, param_grid, \n",
    "                                output_dir, model_kind, model_name,\n",
    "                                cv=rskf, n_iter=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rskf.get_n_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression optimal_filtered peaks_summary.json\n",
      "svc optimal_filtered peaks_summary.json\n",
      "svc optimal_all peaks_summary.json\n",
      "logistic_regression optimal_all peaks_summary.json\n"
     ]
    }
   ],
   "source": [
    "output_files = os.listdir(output_dir)\n",
    "output_summary_files = [f for f in output_files if f.endswith('summary.json')]\n",
    "other_files = [f for f in output_files if f not in output_summary_files]\n",
    "\n",
    "all_res = []\n",
    "df_cols = ['model_kind','model_name','n_input ft','cv_score','cv_score_std','train_score','val_score', 'test_score']\n",
    "for f in output_summary_files:\n",
    "    print(f)\n",
    "    model_name = f.split('_summary.json')[0]\n",
    "    res = json.load(open(os.path.join(output_dir, f)))\n",
    "    res_df = pd.DataFrame({k: res[k] for k in df_cols}, index=[model_name])\n",
    "    all_res.append(res_df)\n",
    "\n",
    "\n",
    "res_summary = pd.concat(all_res, axis=0)    \n",
    "res_summary = res_summary.round(4)\n",
    "res_summary.to_csv(os.path.join(task_dir, 'classical_alt_summary.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do parameter optimization using the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression\n",
      "filtered peaks\n",
      "13\n",
      "all peaks\n",
      "14\n",
      "random_forest\n",
      "filtered peaks\n",
      "55\n",
      "all peaks\n",
      "54\n",
      "svc\n",
      "filtered peaks\n",
      "28\n",
      "all peaks\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "param_grids = [logistic_regression_param_grid, random_forest_param_grid, svc_param_grid]\n",
    "model_kinds = ['logistic_regression', 'random_forest', 'svc']\n",
    "\n",
    "\n",
    "feat_filt_names = ['filtered peaks', 'all peaks']\n",
    "chosen_fts_list = [filtered_feats, all_feats]\n",
    "output_dir = os.path.join(task_dir, 'classical_models_alt3')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for param_grid, model_kind in zip(param_grids, model_kinds):\n",
    "    print(model_kind)\n",
    "    for feat_filt_name, chosen_fts in zip(feat_filt_names, chosen_fts_list):\n",
    "        print(feat_filt_name)\n",
    "        model_name = f'{model_kind} optimal'  + f'_{feat_filt_name}'\n",
    "\n",
    "        data_dict = {'X_train': X_train[chosen_fts], \n",
    "                    'y_train': y_train, \n",
    "                    'X_val': X_val[chosen_fts], \n",
    "                    'y_val': y_val, \n",
    "                    'X_test': X_test[chosen_fts], \n",
    "                    'y_test': y_test}\n",
    "        \n",
    "        if model_kind == 'svc':\n",
    "            model = SVC(probability=True)\n",
    "        elif model_kind == 'logistic_regression':\n",
    "            model = LogisticRegression(max_iter=1000)\n",
    "        elif model_kind == 'random_forest':\n",
    "            model = RandomForestClassifier()\n",
    "        elif model_kind == 'decision_tree':\n",
    "            model = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "        out = optimize_with_val(model, data_dict, param_grid,n_iter=20)\n",
    "\n",
    "\n",
    "        out.to_csv(os.path.join(output_dir, f'{model_name}_optimal_by_val.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241, 2736)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6473029045643154"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6623376623376623"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSKCC BINARY\n",
       "1.0    51\n",
       "0.0    26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6410256410256411"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([y_train.loc[splits.iloc[:,x]].count() for x in range(0,5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6472789115646259"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([y_train.loc[splits.iloc[:,x]].mean() for x in range(0,5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6473013816925735"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([y_train.loc[~splits.iloc[:,x]].mean() for x in range(0,5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6458333333333334"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.loc[~splits.iloc[:,0]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
