{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Sklearn models to train and predict RCC3 labels using Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import zipfile\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn_models import run_train_sklearn_model\n",
    "from misc import save_json, get_dropbox_dir\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load (and explain) the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_dir = '/Users/jonaheaton/ReviveMed Dropbox/Jonah Eaton/development_CohortCombination/alignment_RCC_2024_Feb_27/March_8_Data'\n",
    "subset_dir = '/Users/jonaheaton/ReviveMed Dropbox/Jonah Eaton/development_CohortCombination/alignment_RCC_2024_Feb_27/March_6_Data'\n",
    "# subset_dir = 'example_data'\n",
    "example_data_url = 'https://www.dropbox.com/scl/fo/d1yqlmyafvu8tzujlg4nk/h?rlkey=zrxfapacmgb6yxsmonw4yt986&dl=1'\n",
    "# Download the data\n",
    "\n",
    "# download_data_dir(example_data_url, save_dir=subset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropbox_dir = get_dropbox_dir()\n",
    "base_dir = os.path.join(dropbox_dir, 'development_CohortCombination','alignment_RCC_2024_Feb_27')\n",
    "\n",
    "ref_freq = 0.6\n",
    "# input_freq = 0.1\n",
    "grid_id = 1\n",
    "matt_ft_dir = os.path.join(base_dir, 'matt_top_fts')\n",
    "\n",
    "# %%\n",
    "def get_key_ft_dct():\n",
    "\n",
    "    matt_ft_files = os.listdir(matt_ft_dir)\n",
    "    matt_ft_files = [f for f in matt_ft_files if f.endswith('.txt')]\n",
    "\n",
    "    matt_ft_dict = {}\n",
    "    for f in matt_ft_files:\n",
    "        ft_name = f.split('_feats')[0]\n",
    "        # with open(os.path.join(matt_ft_dir, f), 'r') as file:\n",
    "        #     ft = file.read().split(', ')\n",
    "        # if len(ft) == 1:\n",
    "        with open(os.path.join(matt_ft_dir, f), 'r') as file:\n",
    "            ft = file.read().splitlines()\n",
    "            # print(file.read()\n",
    "        # remove all of the ', and commas from the strings in the list\n",
    "        ft = [x.strip(',').strip(' ').strip('\"').strip(\"'\").strip('\\n').strip('\\t') for x in ft]\n",
    "        matt_ft_dict[ft_name] = ft\n",
    "        # break\n",
    "        print(ft_name + ': ' + str(len(ft)))\n",
    "\n",
    "    # %% [markdown]\n",
    "    # ### RCC Target Metabolites\n",
    "\n",
    "    # %%\n",
    "    # %%\n",
    "    rcc_peak_info_file = os.path.join(base_dir, 'rcc_result', 'peak_info.csv')\n",
    "    rcc_peak_info_df = pd.read_csv(rcc_peak_info_file, index_col=0)\n",
    "\n",
    "    rcc_peak_info_df = rcc_peak_info_df[rcc_peak_info_df['freq'] >= ref_freq].copy()\n",
    "\n",
    "    print(f'Number of peaks in the reference cohort after {ref_freq} filter: ', rcc_peak_info_df.shape[0])\n",
    "\n",
    "        \n",
    "    rcc_matched_targets_file = os.path.join(base_dir,'rcc_result', 'matched_targets HILIC POSITIVE ION MODE.csv')\n",
    "    rcc_matched_targets_df = pd.read_csv(rcc_matched_targets_file, index_col=0)\n",
    "    rcc_matched_targets_df.loc[rcc_peak_info_df.index]\n",
    "\n",
    "    potential_feats = rcc_matched_targets_df[rcc_matched_targets_df['potential_target']].index.to_list()\n",
    "    print('Number of features that potentially match to a target metabolite: ', len(potential_feats))\n",
    "\n",
    "    double_match_ids = rcc_matched_targets_df[rcc_matched_targets_df['potential_target_count'] > 1]\n",
    "    num_double_match = double_match_ids.shape[0]\n",
    "    print('Number of features that potentially match to more than one target metabolite: ', double_match_ids.shape[0])\n",
    "    print(rcc_matched_targets_df.loc[double_match_ids.index, 'potential_target_id'])\n",
    "\n",
    "    # here are the double matches in RCC, two are the same metabolite (but different adducts?)\n",
    "    # FT3202                           tryptophanTryptophan_μM\n",
    "    # FT3237                           kynurenineKynurenine_μM\n",
    "    # FT8451    C18:1 LPC plasmalogen_AC18:1 LPC plasmalogen_B\n",
    "\n",
    "\n",
    "    potential_feat_names = rcc_matched_targets_df.loc[potential_feats]['potential_target_id'].unique()\n",
    "    # print('Number of potential feature names: ', len(potential_feat_names))\n",
    "    print(potential_feat_names)\n",
    "\n",
    "    print('Number of target metabolite captured: ', len(potential_feat_names))\n",
    "\n",
    "    # for now don't remove the double counts, since they are NOT actually double counts\n",
    "    num_rcc_targets_found =  len(potential_feat_names)\n",
    "    rcc_target_feats = potential_feats\n",
    "\n",
    "    # add to the matt ft dictionary\n",
    "    matt_ft_dict['rcc_targets'] = rcc_target_feats\n",
    "\n",
    "    return matt_ft_dict, rcc_peak_info_df\n",
    "\n",
    "\n",
    "# Helper functions to finding the number and percentage of captured features\n",
    "def get_captured_fts(matt_ft_list, align_ft_list):\n",
    "    captured_fts = [ft for ft in matt_ft_list if ft in align_ft_list]\n",
    "    return captured_fts\n",
    "\n",
    "def get_captured_perc(matt_ft_list, align_ft_list):\n",
    "    captured_fts = get_captured_fts(matt_ft_list, align_ft_list)\n",
    "    matt_capture_perc = len(captured_fts) / len(matt_ft_list)\n",
    "    align_capture_perc = len(captured_fts) / len(align_ft_list)\n",
    "    return matt_capture_perc, align_capture_perc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_10: 10\n",
      "top_25: 25\n",
      "168_os_pfs: 168\n",
      "net_matched: 86\n",
      "Number of peaks in the reference cohort after 0.6 filter:  4016\n",
      "Number of features that potentially match to a target metabolite:  188\n",
      "Number of features that potentially match to more than one target metabolite:  3\n",
      "feats\n",
      "FT3202                           tryptophanTryptophan_μM\n",
      "FT3237                           kynurenineKynurenine_μM\n",
      "FT8451    C18:1 LPC plasmalogen_AC18:1 LPC plasmalogen_B\n",
      "Name: potential_target_id, dtype: object\n",
      "['trimethylamine-N-oxide' 'alanine' 'GABA' 'serine' 'hypotaurine'\n",
      " 'cytosine' 'creatinine' 'betaine' 'threonine' 'niacinamide' 'taurine'\n",
      " 'ornithine' 'N-acetylalanine' 'N-carbamoyl-beta-alanine'\n",
      " 'N-methylproline' 'leucine' 'hydroxyproline' 'N-acetylputrescine'\n",
      " '1-methylnicotinamide' 'trigonelline' 'anthranilic acid' 'urocanic acid'\n",
      " 'imidazole propionate' 'ectoine' 'proline-betaine' 'glutamate'\n",
      " '4-acetamidobutanoate' 'butyrobetaine' 'glutamine' 'lysine' 'methionine'\n",
      " 'N1-methyl-2-pyridone-5-carboxamide' '4-hydroxy-3-methylacetophenone'\n",
      " 'guanine' 'allantoin' 'carnitine' '2-aminooctanoate' 'urate'\n",
      " '7-methylguanine' '3-methylxanthine' 'phenylalanine' 'N-acetylleucine'\n",
      " '3-methylhistidine' 'serotonin' 'citrulline' 'N6,N6-dimethyllysine'\n",
      " 'N-acetylornithine' 'cotinine' '5-hydroxytryptophol' 'arginine'\n",
      " 'tyrosine' 'hippurate' '4-pyridoxate' 'N6-acetyllysine'\n",
      " 'N6,N6,N6-trimethyllysine' 'N1-acetylspermidine' 'NMMA' 'kynurenic acid'\n",
      " 'N-acetylmethionine' 'hydroxycotinine' 'caffeine' '4-hydroxyhippurate'\n",
      " '1,7-dimethyluric acid' 'DMGV' 'SDMA' 'C2 carnitine'\n",
      " 'tryptophanTryptophan_μM' 'kynurenineKynurenine_μM' 'pantothenol'\n",
      " 'cinnamoylglycine' 'N-alpha-acetylarginine' 'C3 carnitine'\n",
      " 'acetyl-galactosamine' '5-hydroxytryptophan' 'pantothenate'\n",
      " 'myristoleate' 'C4 carnitine' 'C5:1 carnitine' 'C5 carnitine'\n",
      " 'C4-OH carnitine' 'N-acetyltryptophan' 'pseudouridine' 'ribothymidine'\n",
      " 'alpha-glycerophosphocholine' 'C3-DC-CH3 carnitine' 'C6 carnitine'\n",
      " 'thiamine' 'inosine' 'atenolol' 'metoprolol' 'phenylacetylglutamine'\n",
      " 'C5-DC carnitine' '1-methyladenosine' 'diacetylspermine'\n",
      " 'N4-acetylcytidine' 'C8 carnitine' 'piperine' '1-methylguanosine'\n",
      " 'C9 carnitine' 'sphinganine' 'threo-sphingosine' 'warfarin'\n",
      " '3-(N-acetyl-L-cystein-S-yl) acetaminophen' 'C10 carnitine'\n",
      " 'linoleoyl ethanolamide' 'acetaminophen glucuronide' 'C12 carnitine'\n",
      " 'C12:1 carnitine' 'oleoyl glycine' 'cortisol' 'cortisone'\n",
      " 'C14:1 carnitine' 'C14 carnitine' 'C16 carnitine' 'C18:2 carnitine'\n",
      " 'C18 carnitine' 'C18:1 carnitine' 'valsartan' 'C20:4 carnitine'\n",
      " 'glycodeoxycholate/glycochenodeoxycholate' 'C16:0 LPE' 'C14:0 LPC'\n",
      " 'glycocholate' 'C18:2 LPE' 'C18:1 LPE' 'C18:0 LPE'\n",
      " 'C16:1 LPC plasmalogen' 'C16:1 LPC' 'C16:0 LPC' 'C20:4 LPE'\n",
      " 'C18:1 LPC plasmalogen_B'\n",
      " 'C18:1 LPC plasmalogen_AC18:1 LPC plasmalogen_B' 'C20:0 LPE' 'C18:3 LPC'\n",
      " 'C18:0 LPC' 'C18:1 LPC' 'C22:6 LPE' 'C16:0 ceramide (d18:1)'\n",
      " 'C26 carnitine' 'C20:4 LPC' 'C20:5 LPC' 'C22:6 LPC' 'C22:5 LPC'\n",
      " 'biliverdin' 'bilirubin' 'urobilinogen' 'C34:1 DAG' 'C34:2 DAG'\n",
      " 'C34:1 DAG*' 'C24:1 ceramide (d18:1)' 'C14:0 SM' 'C34:3 PE plasmalogen'\n",
      " 'C34:2 PE plasmalogen' 'C16:0 SM' 'C16:1 SM' 'C30:0 PC' 'C34:2 PE'\n",
      " 'C36:5 PE plasmalogen' 'C34:0 PE' 'C18:1 SM' 'C36:3 PE plasmalogen'\n",
      " 'C32:2 PC' 'C18:0 SM' 'C34:3 PC plasmalogen' 'C36:4 PE' 'C36:2 PE'\n",
      " 'C38:7 PE plasmalogen' 'C38:5 PE plasmalogen' 'C38:6 PE plasmalogen'\n",
      " 'C34:4 PC' 'C20:0 SM' 'C34:3 PC' 'C38:6 PE' 'C38:4 PE'\n",
      " 'C36:5 PC plasmalogen' 'C36:2 PS plasmalogen' 'thyroxine'\n",
      " 'C40:7 PE plasmalogen' 'C36:2 PC' 'C38:6 PC plasmalogen' 'C40:6 PE'\n",
      " 'C38:7 PC plasmalogen']\n",
      "Number of target metabolite captured:  182\n"
     ]
    }
   ],
   "source": [
    "matt_ft_dict, rcc_peak_info_df = get_key_ft_dct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nivo Benefit BINARY finetune_folds', '.DS_Store', 'MSKCC BINARY finetune_folds', 'Cohort ID Expanded pretrain_folds', 'readme.txt', 'X.csv', 'y.csv', 'nans.csv']\n"
     ]
    }
   ],
   "source": [
    "#what is inside the example directory?\n",
    "print(os.listdir(subset_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X data\n",
    "- the input peak matrix, columns are peaks, rows are samples\n",
    "- nans are already imputed using the mean of the peak within its corresponding study\n",
    "- in this example, the peaks are those determined by alignment\n",
    "- also in this example, we are including a lot of pretraining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = pd.read_csv(os.path.join(subset_dir, 'X.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nan mask\n",
    "- nans is a binary matrix indicating which peaks were originally missing in which samples\n",
    "- columns are the peaks, rows are the samples\n",
    "- should have the exact same size and organization as X data\n",
    "- Since nans were already imputed, this is not used in this example\n",
    "- is useful if you want to change the imputation method, or calculate peak frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_mask = pd.read_csv(os.path.join(subset_dir, 'nans.csv'), index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Y data\n",
    "- the metadata associated with the samples\n",
    "- includes metadata from alignment with pre-training data AND metadata associated with the RCC studies\n",
    "- RCC related metadata has been cleaned and simplified. combines the information between genomics dataset, the the Nature communication dataset. A lot of superfolous information has been removed\n",
    "- the \"Matt Set\" column indicates whether a sample belongs in Matt's Train/Val/Split\n",
    "- the \"Set\" column corresponds to the \"Matt Set\" for the RCC3 *baseline* samples, all other samples are labeled as pretrai\n",
    "- columns have been created specifically for the Binary classification task \"Nivo Benefit BINARY\" and \"MSKCC BINARY\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcc_metadata_file = os.path.join(dropbox_dir, 'development_CohortCombination','clean_rcc_metadata_encoded.csv')\n",
    "rcc_metadata = pd.read_csv(rcc_metadata_file, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = pd.read_csv(os.path.join(subset_dir, 'y.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cohort_id', 'Study ID', 'Cohort Label', 'Cohort ID Expanded',\n",
       "       'Study ID Expanded', 'Cohort ID', 'OS', 'OS_Event', 'Age', 'subject ID',\n",
       "       'study_week', 'Region', 'Sex', 'Race', 'Dose (mg/kg)', 'phase',\n",
       "       'Treatment', 'Prior_2', 'batch_id', 'runtime_hour', 'run_order',\n",
       "       'MSKCC', 'ORR', 'Benefit', 'ExtremeResponder', 'PFS', 'PFS_Event', 'MV',\n",
       "       'Age_Group', 'Benefit BINARY', 'Benefit ORDINAL', 'Nivo Benefit BINARY',\n",
       "       'MSKCC BINARY', 'MSKCC ORDINAL', 'Matt Set', 'Set'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data['Study ID'].value_counts().nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Set\n",
       "Pretrain      16944\n",
       "Finetune        449\n",
       "Test            149\n",
       "Validation      143\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data['Set'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples:  17685\n",
      "number of features:  2736\n"
     ]
    }
   ],
   "source": [
    "print('number of samples: ', X_data.shape[0])\n",
    "print('number of features: ', X_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_files = y_data[y_data['Set']=='Pretrain'].index.to_list()\n",
    "finetune_files = y_data[y_data['Set']=='Finetune'].index.to_list()\n",
    "holdout_test_files = y_data[y_data['Set']=='Test'].index.to_list()\n",
    "holdout_val_files = y_data[y_data['Set']=='Validation'].index.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Classical Models on the desired tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the task directory and properly format the X and y for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSKCC BINARY\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "yes_dropna = True\n",
    "\n",
    "finetune_label_col = 'MSKCC BINARY'\n",
    "finetune_label_mapper = {}\n",
    "finetune_filter = []\n",
    "\n",
    "desc_str = 'MSKCC BINARY'\n",
    "desc_str = finetune_label_col\n",
    "\n",
    "splits_dir = os.path.join(subset_dir, f'{desc_str} finetune_folds')\n",
    "\n",
    "\n",
    "print(finetune_label_col)\n",
    "print(finetune_label_mapper)\n",
    "\n",
    "\n",
    "task_dir = os.path.join(splits_dir, finetune_label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_freq = 1 - nan_mask.loc[finetune_files].sum(axis=0)/ len(finetune_files)\n",
    "pretrain_freq = 1- nan_mask.loc[pretrain_files].sum(axis=0)/ len(pretrain_files)\n",
    "finetune_var = X_data.loc[finetune_files].var(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Fraction of non-NaN values in Training Data')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finetune_freq.hist(bins=np.arange(0,1,0.05))\n",
    "plt.xlabel('Fraction of non-NaN values in Training Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Fraction of non-NaN values in Pretraining Data')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGwCAYAAACD0J42AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3ZklEQVR4nO3deXxU1f3/8XcSkgmBJBAgm4RF1iBhFwhYRbawfBGV1oWIwVKoGKwSUaFlCaBCKSpqER72SwEtEYvVWoECAQXKphCJbCkFBKmFhB8gBEgZJpn7+8NH5uuQBJiQyZyE1/PxmAfee8+ce87Hm8k7996Z8bMsyxIAAIBB/H09AAAAgKsRUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjFPD1wMoD6fTqRMnTig0NFR+fn6+Hg4AALgBlmXpwoULio2Nlb//tc+RVMmAcuLECcXFxfl6GAAAoBz+/e9/q2HDhtdsUyUDSmhoqKQfJhgWFlahfTscDq1bt079+/dXYGBghfaNa6P2vkHdfYfa+w619438/HzFxcW5fo9fS5UMKMWXdcLCwrwSUEJCQhQWFsZBW8movW9Qd9+h9r5D7X3rRm7P4CZZAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHFq+HoAqFhNJq7yav/HZg/2av8AAEicQQEAAAYioAAAAOMQUAAAgHEIKAAAwDgeBZQFCxaoXbt2CgsLU1hYmBITE/X3v//dtf3y5ctKTU1VvXr1VLt2bQ0bNkx5eXlufRw/flyDBw9WSEiIIiMj9fzzz6uwsLBiZgMAAKoFjwJKw4YNNXv2bGVlZWnXrl3q3bu3hg4dqv3790uSxo8fr08//VQrVqzQpk2bdOLECT344IOu5xcVFWnw4MG6cuWKtm3bpqVLl2rJkiWaOnVqxc4KAABUaR69zXjIkCFuyy+//LIWLFigHTt2qGHDhlq0aJEyMjLUu3dvSdLixYsVHx+vHTt2qHv37lq3bp0OHDig9evXKyoqSh06dNDMmTP14osvKj09XUFBQRU3MwAAUGWV+3NQioqKtGLFCl26dEmJiYnKysqSw+FQ3759XW1at26tRo0aafv27erevbu2b9+uhIQERUVFudokJSVp7Nix2r9/vzp27Fjqvux2u+x2u2s5Pz9fkuRwOORwOMo7hVIV91fR/VYWW4Dl1f69WZeqXvuqirr7DrX3HWrvG57U2+OAsnfvXiUmJury5cuqXbu2Pv74Y7Vp00bZ2dkKCgpSnTp13NpHRUUpNzdXkpSbm+sWToq3F28ry6xZszR9+vQS69etW6eQkBBPp3BDMjMzvdKvt83p6t3+V69e7d0dqOrWvqqj7r5D7X2H2leugoKCG27rcUBp1aqVsrOzdf78eX344YdKSUnRpk2bPO3GI5MmTVJaWpprOT8/X3Fxcerfv7/CwsIqdF8Oh0OZmZnq16+fAgMDK7TvytA2fa1X+9+XnuS1vqt67asq6u471N53qL1vFF8BuREeB5SgoCA1b95cktS5c2ft3LlTb7zxhh5++GFduXJF586dczuLkpeXp+joaElSdHS0vvzyS7f+it/lU9ymNDabTTabrcT6wMBArx1Y3uzbm+xFfl7tvzJqUlVrX9VRd9+h9r5D7SuXJ7W+6c9BcTqdstvt6ty5swIDA7VhwwbXtoMHD+r48eNKTEyUJCUmJmrv3r06deqUq01mZqbCwsLUpk2bmx0KAACoJjw6gzJp0iQNHDhQjRo10oULF5SRkaGNGzdq7dq1Cg8P16hRo5SWlqaIiAiFhYXp6aefVmJiorp37y5J6t+/v9q0aaMRI0Zozpw5ys3N1eTJk5WamlrqGRIAAHBr8iignDp1So8//rhOnjyp8PBwtWvXTmvXrlW/fv0kSa+//rr8/f01bNgw2e12JSUl6e2333Y9PyAgQCtXrtTYsWOVmJioWrVqKSUlRTNmzKjYWQEAgCrNo4CyaNGia24PDg7W/PnzNX/+/DLbNG7cuFLeCYKqq236Wq/cS3Ns9uAK7xMA4B18Fw8AADAOAQUAABiHgAIAAIxDQAEAAMYp93fxAHDXZOIqr/bPTb4AbiWcQQEAAMYhoAAAAONwiQce8eZlDFuA5dVvY/b2JRgAQMXhDAoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcTwKKLNmzdKdd96p0NBQRUZG6v7779fBgwfd2vTq1Ut+fn5ujyeffNKtzfHjxzV48GCFhIQoMjJSzz//vAoLC29+NgAAoFqo4UnjTZs2KTU1VXfeeacKCwv161//Wv3799eBAwdUq1YtV7vRo0drxowZruWQkBDXfxcVFWnw4MGKjo7Wtm3bdPLkST3++OMKDAzUK6+8UgFTAgAAVZ1HAWXNmjVuy0uWLFFkZKSysrJ09913u9aHhIQoOjq61D7WrVunAwcOaP369YqKilKHDh00c+ZMvfjii0pPT1dQUFA5pgEAAKoTjwLK1c6fPy9JioiIcFu/bNky/elPf1J0dLSGDBmiKVOmuM6ibN++XQkJCYqKinK1T0pK0tixY7V//3517NixxH7sdrvsdrtrOT8/X5LkcDjkcDhuZgolFPdX0f1WFluA5eshlJvN33L7F+68dUxW9WO+KqP2vkPtfcOTevtZllWu3wZOp1P33Xefzp07py1btrjWv/POO2rcuLFiY2O1Z88evfjii+ratas++ugjSdKYMWP07bffau3ata7nFBQUqFatWlq9erUGDhxYYl/p6emaPn16ifUZGRlul48AAIC5CgoKNHz4cJ0/f15hYWHXbFvuMyipqanat2+fWziRfgggxRISEhQTE6M+ffroyJEjatasWbn2NWnSJKWlpbmW8/PzFRcXp/79+193gp5yOBzKzMxUv379FBgYWKF9V4a26Wuv38hQNn9LM7s4NWWXv+xOP18Pxzj70pO80m9VP+arMmrvO9TeN4qvgNyIcgWUcePGaeXKldq8ebMaNmx4zbbdunWTJB0+fFjNmjVTdHS0vvzyS7c2eXl5klTmfSs2m002m63E+sDAQK8dWN7s25vsRVX/F7vd6Vct5lHRvH08VtVjvjqg9r5D7SuXJ7X26G3GlmVp3Lhx+vjjj/XZZ5+padOm131Odna2JCkmJkaSlJiYqL179+rUqVOuNpmZmQoLC1ObNm08GQ4AAKimPDqDkpqaqoyMDH3yyScKDQ1Vbm6uJCk8PFw1a9bUkSNHlJGRoUGDBqlevXras2ePxo8fr7vvvlvt2rWTJPXv319t2rTRiBEjNGfOHOXm5mry5MlKTU0t9SwJAAC49Xh0BmXBggU6f/68evXqpZiYGNfjgw8+kCQFBQVp/fr16t+/v1q3bq3nnntOw4YN06effurqIyAgQCtXrlRAQIASExP12GOP6fHHH3f73BQAAHBr8+gMyvXe8BMXF6dNmzZdt5/GjRtr9erVnuwaAADcQvguHgAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHFq+HoAAG5Mk4mrvNKvLcDSnK5e6RoAyo0zKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAON4FFBmzZqlO++8U6GhoYqMjNT999+vgwcPurW5fPmyUlNTVa9ePdWuXVvDhg1TXl6eW5vjx49r8ODBCgkJUWRkpJ5//nkVFhbe/GwAAEC14FFA2bRpk1JTU7Vjxw5lZmbK4XCof//+unTpkqvN+PHj9emnn2rFihXatGmTTpw4oQcffNC1vaioSIMHD9aVK1e0bds2LV26VEuWLNHUqVMrblYAAKBKq+FJ4zVr1rgtL1myRJGRkcrKytLdd9+t8+fPa9GiRcrIyFDv3r0lSYsXL1Z8fLx27Nih7t27a926dTpw4IDWr1+vqKgodejQQTNnztSLL76o9PR0BQUFldiv3W6X3W53Lefn50uSHA6HHA6Hx5O+luL+KrrfymILsHw9hHKz+Vtu/6JyFNe7qh7zVVlVf72pyqi9b3hSb48CytXOnz8vSYqIiJAkZWVlyeFwqG/fvq42rVu3VqNGjbR9+3Z1795d27dvV0JCgqKiolxtkpKSNHbsWO3fv18dO3YssZ9Zs2Zp+vTpJdavW7dOISEhNzOFMmVmZnqlX2+b09XXI7h5M7s4fT2EW1JVPearA2rvO9S+chUUFNxw23IHFKfTqWeffVY9e/ZU27ZtJUm5ubkKCgpSnTp13NpGRUUpNzfX1ebH4aR4e/G20kyaNElpaWmu5fz8fMXFxal///4KCwsr7xRK5XA4lJmZqX79+ikwMLBC+64MbdPX+noI5WbztzSzi1NTdvnL7vTz9XBuGcV1r6rHfFVW1V9vqjJq7xvFV0BuRLkDSmpqqvbt26ctW7aUt4sbZrPZZLPZSqwPDAz02oHlzb69yV5U9X+x251+1WIeVU1VPearA2rvO9S+cnlS63K9zXjcuHFauXKlPv/8czVs2NC1Pjo6WleuXNG5c+fc2ufl5Sk6OtrV5up39RQvF7cBAAC3No8CimVZGjdunD7++GN99tlnatq0qdv2zp07KzAwUBs2bHCtO3jwoI4fP67ExERJUmJiovbu3atTp0652mRmZiosLExt2rS5mbkAAIBqwqNLPKmpqcrIyNAnn3yi0NBQ1z0j4eHhqlmzpsLDwzVq1CilpaUpIiJCYWFhevrpp5WYmKju3btLkvr37682bdpoxIgRmjNnjnJzczV58mSlpqaWehkHAADcejwKKAsWLJAk9erVy2394sWLNXLkSEnS66+/Ln9/fw0bNkx2u11JSUl6++23XW0DAgK0cuVKjR07VomJiapVq5ZSUlI0Y8aMm5sJAACoNjwKKJZ1/c+nCA4O1vz58zV//vwy2zRu3FirV6/2ZNcAAOAWwnfxAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGCcGr4eAAAztE1fK3uRn1f6PjZ7sFf6BVB9cQYFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABjH44CyefNmDRkyRLGxsfLz89Nf//pXt+0jR46Un5+f22PAgAFubc6ePavk5GSFhYWpTp06GjVqlC5evHhTEwEAANWHxwHl0qVLat++vebPn19mmwEDBujkyZOux/vvv++2PTk5Wfv371dmZqZWrlypzZs3a8yYMZ6PHgAAVEsefxfPwIEDNXDgwGu2sdlsio6OLnVbTk6O1qxZo507d6pLly6SpLfeekuDBg3S3LlzFRsbW+I5drtddrvdtZyfny9Jcjgccjgcnk7hmor7q+h+K4stwPL1EMrN5m+5/YvKURl1r6o/T95W1V9vqjJq7xue1NsrXxa4ceNGRUZGqm7duurdu7deeukl1atXT5K0fft21alTxxVOJKlv377y9/fXF198oQceeKBEf7NmzdL06dNLrF+3bp1CQkK8MQVlZmZ6pV9vm9PV1yO4eTO7OH09hFuSN+u+evVqr/VdHVTV15vqgNpXroKCghtuW+EBZcCAAXrwwQfVtGlTHTlyRL/+9a81cOBAbd++XQEBAcrNzVVkZKT7IGrUUEREhHJzc0vtc9KkSUpLS3Mt5+fnKy4uTv3791dYWFiFjt/hcCgzM1P9+vVTYGBghfZdGdqmr/X1EMrN5m9pZhenpuzyl93pnW/VRUmVUfd96Ule6beqq+qvN1UZtfeN4isgN6LCA8ojjzzi+u+EhAS1a9dOzZo108aNG9WnT59y9Wmz2WSz2UqsDwwM9NqB5c2+vcleVPV/sdudftViHlWNN+teFX+WKlNVfb2pDqh95fKk1l5/m/Htt9+u+vXr6/Dhw5Kk6OhonTp1yq1NYWGhzp49W+Z9KwAA4Nbi9YDy3Xff6cyZM4qJiZEkJSYm6ty5c8rKynK1+eyzz+R0OtWtWzdvDwcAAFQBHl/iuXjxoutsiCQdPXpU2dnZioiIUEREhKZPn65hw4YpOjpaR44c0QsvvKDmzZsrKemHa9Dx8fEaMGCARo8erYULF8rhcGjcuHF65JFHSn0HDwAAuPV4fAZl165d6tixozp27ChJSktLU8eOHTV16lQFBARoz549uu+++9SyZUuNGjVKnTt31j/+8Q+3e0iWLVum1q1bq0+fPho0aJDuuusuvfPOOxU3KwAAUKV5fAalV69esqyyPy9h7drrv4skIiJCGRkZnu4aAADcIvguHgAAYBwCCgAAMA4BBQAAGIeAAgAAjOOV7+JB2ZpMXOXrIQAAYDzOoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxTw9cDAFD9NZm4yqv9H5s92Kv9A6h8nEEBAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAObzMGUOXxNmag+uEMCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYx+OAsnnzZg0ZMkSxsbHy8/PTX//6V7ftlmVp6tSpiomJUc2aNdW3b18dOnTIrc3Zs2eVnJyssLAw1alTR6NGjdLFixdvaiIAAKD68DigXLp0Se3bt9f8+fNL3T5nzhy9+eabWrhwob744gvVqlVLSUlJunz5sqtNcnKy9u/fr8zMTK1cuVKbN2/WmDFjyj8LAABQrXj8ZYEDBw7UwIEDS91mWZbmzZunyZMna+jQoZKkd999V1FRUfrrX/+qRx55RDk5OVqzZo127typLl26SJLeeustDRo0SHPnzlVsbGyJfu12u+x2u2s5Pz9fkuRwOORwODydwjUV91fR/RazBVhe6bc6sPlbbv+iclD36/PW64G3X29QNmrvG57U28+yrHK/Kvn5+enjjz/W/fffL0n65ptv1KxZM+3evVsdOnRwtbvnnnvUoUMHvfHGG/rjH/+o5557Tt9//71re2FhoYKDg7VixQo98MADJfaTnp6u6dOnl1ifkZGhkJCQ8g4fAABUooKCAg0fPlznz59XWFjYNdt6fAblWnJzcyVJUVFRbuujoqJc23JzcxUZGek+iBo1FBER4WpztUmTJiktLc21nJ+fr7i4OPXv3/+6E/SUw+FQZmam+vXrp8DAwArtW5Lapq+t8D6rC5u/pZldnJqyy192p5+vh3PLoO7Xty89ySv9evv1BmWj9r5RfAXkRlRoQPEWm80mm81WYn1gYKDXDixv9W0v4hfA9didftTJB6h72bz9C8ybr2W4NmpfuTypdYW+zTg6OlqSlJeX57Y+Ly/PtS06OlqnTp1y215YWKizZ8+62gAAgFtbhQaUpk2bKjo6Whs2bHCty8/P1xdffKHExERJUmJios6dO6esrCxXm88++0xOp1PdunWryOEAAIAqyuNLPBcvXtThw4ddy0ePHlV2drYiIiLUqFEjPfvss3rppZfUokULNW3aVFOmTFFsbKzrRtr4+HgNGDBAo0eP1sKFC+VwODRu3Dg98sgjpb6DBwB8rcnEVV7p1xZgaU5Xr3QNVHkeB5Rdu3bp3nvvdS0X37yakpKiJUuW6IUXXtClS5c0ZswYnTt3TnfddZfWrFmj4OBg13OWLVumcePGqU+fPvL399ewYcP05ptvVsB0AABAdeBxQOnVq5eu9c5kPz8/zZgxQzNmzCizTUREhDIyMjzdNQAAuEXwXTwAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHGqxLcZAwDKx1sf01/s2OzBXu0fty7OoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBxukgUAH2ubvlb2Ij9fDwMwCmdQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADG4XNQAADlxpcRwls4gwIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA6fgwIAMJa3PmfFFmBpTlevdI0KwhkUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADG4V08AIBbVtv0tbIX+Xmlb76J+eZwBgUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjFPhASU9PV1+fn5uj9atW7u2X758WampqapXr55q166tYcOGKS8vr6KHAQAAqjCvnEG54447dPLkSddjy5Ytrm3jx4/Xp59+qhUrVmjTpk06ceKEHnzwQW8MAwAAVFFe+bLAGjVqKDo6usT68+fPa9GiRcrIyFDv3r0lSYsXL1Z8fLx27Nih7t27e2M4AACgivFKQDl06JBiY2MVHBysxMREzZo1S40aNVJWVpYcDof69u3ratu6dWs1atRI27dvLzOg2O122e1213J+fr4kyeFwyOFwVOjYi/ur6H6L2QIsr/RbHdj8Lbd/UTmou+9Qe9+pjNp76/dIVeZJTfwsy6rQ/zt///vfdfHiRbVq1UonT57U9OnT9Z///Ef79u3Tp59+qieeeMItbEhS165dde+99+q3v/1tqX2mp6dr+vTpJdZnZGQoJCSkIocPAAC8pKCgQMOHD9f58+cVFhZ2zbYVHlCudu7cOTVu3FivvfaaatasWa6AUtoZlLi4OJ0+ffq6E/SUw+FQZmam+vXrp8DAwArtW5Lapq+t8D6rC5u/pZldnJqyy192p5+vh3PLoO6+Q+19pzJqvy89ySv9VmX5+fmqX7/+DQUUr1zi+bE6deqoZcuWOnz4sPr166crV67o3LlzqlOnjqtNXl5eqfesFLPZbLLZbCXWBwYGeiVEeLNvexEvQtdjd/pRJx+g7r5D7X3Hm7X31u+nqsyTmnj9c1AuXryoI0eOKCYmRp07d1ZgYKA2bNjg2n7w4EEdP35ciYmJ3h4KAACoIir8DMqECRM0ZMgQNW7cWCdOnNC0adMUEBCgRx99VOHh4Ro1apTS0tIUERGhsLAwPf3000pMTOQdPAAAwKXCA8p3332nRx99VGfOnFGDBg101113aceOHWrQoIEk6fXXX5e/v7+GDRsmu92upKQkvf322xU9DAAAUIVVeEBZvnz5NbcHBwdr/vz5mj9/fkXvGgAAVBN8Fw8AADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYp4avBwAAQHXUZOIqr/Z/bPZgr/bva5xBAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHFq+HoAAADAc00mrvJq/8dmD/Zq/9fDGRQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHF8GlDmz5+vJk2aKDg4WN26ddOXX37py+EAAABD+CygfPDBB0pLS9O0adP01VdfqX379kpKStKpU6d8NSQAAGAInwWU1157TaNHj9YTTzyhNm3aaOHChQoJCdEf//hHXw0JAAAYwicfdX/lyhVlZWVp0qRJrnX+/v7q27evtm/fXqK93W6X3W53LZ8/f16SdPbsWTkcjgodm8PhUEFBgc6cOaPAwMAK7VuSahReqvA+q4saTksFBU7VcPiryOnn6+HcMqi771B736H213fmzJkK7/PChQuSJMuyrtvWJwHl9OnTKioqUlRUlNv6qKgo/fOf/yzRftasWZo+fXqJ9U2bNvXaGOEbw309gFsUdfcdau871P7a6r/qvb4vXLig8PDwa7apEl8WOGnSJKWlpbmWnU6nzp49q3r16snPr2KTb35+vuLi4vTvf/9bYWFhFdo3ro3a+wZ19x1q7zvU3jcsy9KFCxcUGxt73bY+CSj169dXQECA8vLy3Nbn5eUpOjq6RHubzSabzea2rk6dOt4cosLCwjhofYTa+wZ19x1q7zvUvvJd78xJMZ/cJBsUFKTOnTtrw4YNrnVOp1MbNmxQYmKiL4YEAAAM4rNLPGlpaUpJSVGXLl3UtWtXzZs3T5cuXdITTzzhqyEBAABD+CygPPzww/p//+//aerUqcrNzVWHDh20Zs2aEjfOVjabzaZp06aVuKQE76P2vkHdfYfa+w61N5+fdSPv9QEAAKhEfBcPAAAwDgEFAAAYh4ACAACMQ0ABAADGuSUDyvz589WkSRMFBwerW7du+vLLL6/ZfsWKFWrdurWCg4OVkJCg1atXV9JIqx9Pav+HP/xBP/nJT1S3bl3VrVtXffv2ve7/K5TO02O+2PLly+Xn56f777/fuwOsxjyt/blz55SamqqYmBjZbDa1bNmS15xy8rT28+bNU6tWrVSzZk3FxcVp/Pjxunz5ciWNFiVYt5jly5dbQUFB1h//+Edr//791ujRo606depYeXl5pbbfunWrFRAQYM2ZM8c6cOCANXnyZCswMNDau3dvJY+86vO09sOHD7fmz59v7d6928rJybFGjhxphYeHW999910lj7xq87TuxY4ePWrddttt1k9+8hNr6NChlTPYasbT2tvtdqtLly7WoEGDrC1btlhHjx61Nm7caGVnZ1fyyKs+T2u/bNkyy2azWcuWLbOOHj1qrV271oqJibHGjx9fySNHsVsuoHTt2tVKTU11LRcVFVmxsbHWrFmzSm3/0EMPWYMHD3Zb161bN+uXv/ylV8dZHXla+6sVFhZaoaGh1tKlS701xGqpPHUvLCy0evToYf3v//6vlZKSQkApJ09rv2DBAuv222+3rly5UllDrLY8rX1qaqrVu3dvt3VpaWlWz549vTpOlO2WusRz5coVZWVlqW/fvq51/v7+6tu3r7Zv317qc7Zv3+7WXpKSkpLKbI/Slaf2VysoKJDD4VBERIS3hlntlLfuM2bMUGRkpEaNGlUZw6yWylP7v/3tb0pMTFRqaqqioqLUtm1bvfLKKyoqKqqsYVcL5al9jx49lJWV5boM9M0332j16tUaNGhQpYwZJVWJbzOuKKdPn1ZRUVGJT6uNiorSP//5z1Kfk5ubW2r73Nxcr42zOipP7a/24osvKjY2tkRgRNnKU/ctW7Zo0aJFys7OroQRVl/lqf0333yjzz77TMnJyVq9erUOHz6sp556Sg6HQ9OmTauMYVcL5an98OHDdfr0ad11112yLEuFhYV68skn9etf/7oyhoxS3FJnUFB1zZ49W8uXL9fHH3+s4OBgXw+n2rpw4YJGjBihP/zhD6pfv76vh3PLcTqdioyM1DvvvKPOnTvr4Ycf1m9+8xstXLjQ10Or9jZu3KhXXnlFb7/9tr766it99NFHWrVqlWbOnOnrod2ybqkzKPXr11dAQIDy8vLc1ufl5Sk6OrrU50RHR3vUHqUrT+2LzZ07V7Nnz9b69evVrl07bw6z2vG07keOHNGxY8c0ZMgQ1zqn0ylJqlGjhg4ePKhmzZp5d9DVRHmO+ZiYGAUGBiogIMC1Lj4+Xrm5ubpy5YqCgoK8Oubqojy1nzJlikaMGKFf/OIXkqSEhARdunRJY8aM0W9+8xv5+/P3fGW7pSoeFBSkzp07a8OGDa51TqdTGzZsUGJiYqnPSUxMdGsvSZmZmWW2R+nKU3tJmjNnjmbOnKk1a9aoS5culTHUasXTurdu3Vp79+5Vdna263Hffffp3nvvVXZ2tuLi4ipz+FVaeY75nj176vDhw65QKEn/+te/FBMTQzjxQHlqX1BQUCKEFAdFi6+s8w1f36Vb2ZYvX27ZbDZryZIl1oEDB6wxY8ZYderUsXJzcy3LsqwRI0ZYEydOdLXfunWrVaNGDWvu3LlWTk6ONW3aNN5mXE6e1n727NlWUFCQ9eGHH1onT550PS5cuOCrKVRJntb9aryLp/w8rf3x48et0NBQa9y4cdbBgwetlStXWpGRkdZLL73kqylUWZ7Wftq0aVZoaKj1/vvvW9988421bt06q1mzZtZDDz3kqync8m65gGJZlvXWW29ZjRo1soKCgqyuXbtaO3bscG275557rJSUFLf2f/7zn62WLVtaQUFB1h133GGtWrWqkkdcfXhS+8aNG1uSSjymTZtW+QOv4jw95n+MgHJzPK39tm3brG7dulk2m826/fbbrZdfftkqLCys5FFXD57U3uFwWOnp6VazZs2s4OBgKy4uznrqqaes77//vvIHDsuyLMvPsjh3BQAAzHJL3YMCAACqBgIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQYbePGjfLz89O5c+d8PRRt3bpVCQkJCgwM1P333+/r4VRbS5YsUZ06dXw6hl69eunZZ5/16Rgqi6dzPXbsmPz8/JSdne21MQESAQVlGDlypPz8/Eo8Dh8+7LV9lvZC2aNHD508eVLh4eFe2++NSktLU4cOHXT06FEtWbLE18MpoUmTJvLz89OOHTvc1j/77LPq1auXz/qqij766CPNnDnzpvr48c9QUFCQmjdvrhkzZqiwsPCm+63IgOzpXOPi4nTy5Em1bdu2wsZQmuIgVPwIDQ3VHXfcodTUVB06dMjj/po0aaJ58+ZV/EDhNQQUlGnAgAE6efKk26Np06Yl2l25csVrYwgKClJ0dLT8/Py8to8bdeTIEfXu3VsNGzb0+V/4ZQkODtaLL75oXF9VTUREhEJDQ2+6n+KfoUOHDum5555Tenq6fve735XatqJ/jhwOxw2183SuAQEBio6OVo0aNco7NI+sX79eJ0+e1Ndff61XXnlFOTk5at++fYlvmUf1Q0BBmWw2m6Kjo90eAQEB6tWrl8aNG6dnn31W9evXV1JSkiTptddeU0JCgmrVqqW4uDg99dRTunjxolufW7duVa9evRQSEqK6desqKSlJ33//vUaOHKlNmzbpjTfecP3FdOzYsVIv8fzlL3/RHXfcIZvNpiZNmujVV19120eTJk30yiuv6Oc//7lCQ0PVqFEjvfPOO9ecq91u169+9StFRkYqODhYd911l3bu3Cnp//6SO3PmjH7+85/Lz8+vzDMoN7LvvXv3qnfv3qpZs6bq1aunMWPGuNWp+C/kuXPnKiYmRvXq1VNqauoN/cIZM2aMduzYodWrV5fZZufOnerXr5/q16+v8PBw3XPPPfrqq6/K1dePOZ1ONWzYUAsWLHBbv3v3bvn7++vbb7+VdGPHyY+Vdsbg6jM5TqdTs2bNUtOmTVWzZk21b99eH374oWv7999/r+TkZDVo0EA1a9ZUixYttHjx4jL3efXZvPIcU9L//Qw1btxYY8eOVd++ffW3v/3NbV4vv/yyYmNj1apVK0nSv//9bz300EOqU6eOIiIiNHToUB07dkySlJ6erqVLl+qTTz5x/Zxs3LjRdYx+8MEHuueeexQcHKxly5bpzJkzevTRR3XbbbcpJCRECQkJev/9929qrldf4in+Gd2wYYO6dOmikJAQ9ejRQwcPHnTbz0svvaTIyEiFhobqF7/4hSZOnKgOHTpct4b16tVTdHS0br/9dg0dOlTr169Xt27dNGrUKBUVFUn64Y+HoUOHKioqSrVr19add96p9evXu83x22+/1fjx4111k3RD9YHvEFBQLkuXLlVQUJC2bt2qhQsXSpL8/f315ptvav/+/Vq6dKk+++wzvfDCC67nZGdnq0+fPmrTpo22b9+uLVu2aMiQISoqKtIbb7yhxMREjR492nW2Ji4ursR+s7Ky9NBDD+mRRx7R3r17lZ6erilTppQIDK+++qq6dOmi3bt366mnntLYsWNLvGD+2AsvvKC//OUvWrp0qb766is1b95cSUlJOnv2rOuUdlhYmObNm6eTJ0/q4YcfLrOva+370qVLSkpKUt26dbVz506tWLFC69ev17hx49z6+Pzzz3XkyBF9/vnnWrp0qZYsWXJDl5WaNm2qJ598UpMmTZLT6Sy1zYULF5SSkqItW7Zox44datGihQYNGqQLFy543NeP+fv769FHH1VGRobb+mXLlqlnz55q3Lixq921jpPymDVrlt59910tXLhQ+/fv1/jx4/XYY49p06ZNkqQpU6bowIED+vvf/66cnBwtWLBA9evX92gfnh5TpalZs6bbmZINGzbo4MGDyszM1MqVK+VwOJSUlKTQ0FD94x//0NatW1W7dm0NGDBAV65c0YQJE/TQQw+5nd3s0aOHq7+JEyfqmWeeUU5OjpKSknT58mV17txZq1at0r59+zRmzBiNGDFCX375ZYXP9Te/+Y1effVV7dq1SzVq1NDPf/5z17Zly5bp5Zdf1m9/+1tlZWWpUaNGJYLsjfL399czzzyjb7/9VllZWZKkixcvatCgQdqwYYN2796tAQMGaMiQITp+/LikHy5jNWzYUDNmzHDVTVK564NK4uuvU4aZUlJSrICAAKtWrVqux09/+lPLsn74mvKOHTtet48VK1ZY9erVcy0/+uijVs+ePctsf88991jPPPOM27rPP//ckuT6yvPhw4db/fr1c2vz/PPPW23atHEtN27c2Hrsscdcy06n04qMjLQWLFhQ6n4vXrxoBQYGWsuWLXOtu3LlihUbG2vNmTPHtS48PNxavHhxmeO/kX2/8847Vt26da2LFy+62qxatcry9/e3cnNzLcv6ofaNGze2CgsLXW1+9rOfWQ8//PB19/36669bp06dskJDQ613333XsizLeuaZZ6x77rmnzOcVFRVZoaGh1qeffnrTfe3evdvy8/Ozvv32W1fft912W5m1t6ySx8nixYut8PBw13JKSoo1dOhQt+f8eByXL1+2QkJCrG3btrm1GTVqlPXoo49almVZQ4YMsZ544okyx3C1q49FT4+pq8ftdDqtzMxMy2azWRMmTHBtj4qKsux2u+s57733ntWqVSvL6XS61tntdqtmzZrW2rVrS/Rb7OjRo5Yka968eded2+DBg63nnnuu3HMt3tfu3bsty/q/n9H169e7nrNq1SpLkvXf//7XsizL6tatm5Wamuo2jp49e1rt27cvc5xX7+fHcnJyLEnWBx98UObz77jjDuutt95ym9frr79eZvtiV9cHvsMZFJTp3nvvVXZ2tuvx5ptvurZ17ty5RPv169erT58+uu222xQaGqoRI0bozJkzKigokPR/Z1BuRk5Ojnr27Om2rmfPnjp06JDrdK8ktWvXzvXffn5+io6O1qlTp0rt88iRI3I4HG79BgYGqmvXrsrJyfF4jNfad/H181q1armN3+l0uv2FescddyggIMC1HBMT4+rjlVdeUe3atV2P4r8SizVo0EATJkzQ1KlTS72vIS8vT6NHj1aLFi0UHh6usLAwXbx4sUQ/N9LX1Tp06KD4+HjXWZRNmzbp1KlT+tnPfuZqc73jxFOHDx9WQUGB+vXr51aXd999V0eOHJEkjR07VsuXL1eHDh30wgsvaNu2bR7vx5NjqtjKlStVu3ZtBQcHa+DAgXr44YeVnp7u2p6QkKCgoCDX8tdff63Dhw8rNDTUNY+IiAhdvnzZNZdr6dKli9tyUVGRZs6cqYSEBEVERKh27dpau3Ztqf+vb3auP35OTEyMJLmec/DgQXXt2tWt/dXLnrAsyzU26YczKBMmTFB8fLzq1Kmj2rVrKycn57rzLG99UDkq5y4nVEm1atVS8+bNy9z2Y8eOHdP//M//aOzYsXr55ZcVERGhLVu2aNSoUbpy5YpCQkJUs2bNyhi2pB8Cxo/5+fnd0GUKU/Z9rT6efPJJPfTQQ65tsbGxJZ6flpamt99+W2+//XaJbSkpKTpz5ozeeOMNNW7cWDabTYmJiWUGkGv1VZrk5GRlZGRo4sSJysjI0IABA1SvXj1JN3acXM3f39/1C6nYj+/HKb5/ZdWqVbrtttvc2tlsNknSwIED9e2332r16tXKzMxUnz59lJqaqrlz597QnKTy/X+99957tWDBAgUFBSk2NrbEjaVX/xxdvHhRnTt31rJly0r01aBBg+uO8er+fve73+mNN97QvHnzXPf9PPvss9cNm+WZ64+fUxwcvPUzV/yHQ/FN+xMmTFBmZqbmzp2r5s2bq2bNmvrpT3963XmWtz6oHJxBQYXIysqS0+nUq6++qu7du6tly5Y6ceKEW5t27dpd8877oKAgt7MgpYmPj9fWrVvd1m3dulUtW7Z0O+PgiWbNmrnupynmcDi0c+dOtWnTplx9liU+Pl5ff/21Ll265Fq3detW+fv7u26SvJ6IiAg1b97c9Sjt3RS1a9fWlClT9PLLL5e4t2Tr1q361a9+pUGDBrluNj59+nSZ+7tWX6UZPny49u3bp6ysLH344YdKTk52bbuR4+RqDRo0cN0zUOzHn8HRpk0b2Ww2HT9+3K0uzZs3d7uPqUGDBkpJSdGf/vQnzZs374Zucr1ZxSG/UaNGN/Sul06dOunQoUOKjIwsMZfit9rfyM9Jsa1bt2ro0KF67LHH1L59e91+++3617/+dVNzKo9WrVq5bjovdvXyjXI6nXrzzTfVtGlTdezYUdIP8xw5cqQeeOABJSQkKDo62nVjcbHS6mZKfVA6AgoqRPPmzeVwOPTWW2/pm2++0Xvvvee6ebbYpEmTtHPnTj311FPas2eP/vnPf2rBggWuX45NmjTRF198oWPHjun06dOl/vX13HPPacOGDZo5c6b+9a9/aenSpfr973+vCRMmlHvstWrV0tixY/X8889rzZo1OnDggEaPHq2CggKNGjWq3P2WJjk5WcHBwUpJSdG+ffv0+eef6+mnn9aIESMUFRVVofsaM2aMwsPDS9y02qJFC7333nvKycnRF198oeTk5Oue3Sqrr9I0adJEPXr0cL3L4r777nNtu5Hj5Gq9e/fWrl279O677+rQoUOaNm2a9u3b59oeGhqqCRMmaPz48Vq6dKmOHDmir776Sm+99ZaWLl0qSZo6dao++eQTHT58WPv379fKlSsVHx9/3blUtuTkZNWvX19Dhw7VP/7xDx09elQbN27Ur371K3333XeSfqjvnj17dPDgQZ0+ffqa7+5q0aKFMjMztW3bNuXk5OiXv/yl8vLyKms6Lk8//bQWLVqkpUuX6tChQ3rppZe0Z8+eG/r4gDNnzig3N1fffPON/va3v6lv37768ssvtWjRItcfJS1atNBHH32k7Oxsff311xo+fHiJ148mTZpo8+bN+s9//uN6zTGlPigdAQUVon379nrttdf029/+Vm3bttWyZcs0a9YstzYtW7bUunXr9PXXX6tr165KTEzUJ5984vrLcsKECQoICFCbNm3UoEGDUq8Dd+rUSX/+85+1fPlytW3bVlOnTtWMGTM0cuTImxr/7NmzNWzYMI0YMUKdOnXS4cOHtXbtWtWtW/em+r1aSEiI1q5dq7Nnz+rOO+/UT3/6U/Xp00e///3vK3Q/0g+n3GfOnKnLly+7rV+0aJG+//57derUSSNGjHC9vbo8fZUlOTlZX3/9tR544AG38HMjx8nVkpKSNGXKFL3wwgu68847deHCBT3++ONubWbOnKkpU6Zo1qxZio+P14ABA7Rq1SrXJYCgoCBNmjRJ7dq10913362AgAAtX778huZSmUJCQrR582Y1atRIDz74oOLj4zVq1ChdvnxZYWFhkqTRo0erVatW6tKlixo0aFDijOKPTZ48WZ06dVJSUpJ69eql6Ohon3wKcnJysiZNmqQJEyaoU6dOOnr0qEaOHKng4ODrPrdv376KiYlRQkKCJk6cqPj4eO3Zs0f33nuvq81rr72munXrqkePHhoyZIiSkpLUqVMnt35mzJihY8eOqVmzZq7LZabUB6Xzs66+uAsAgJf169dP0dHReu+993w9FBiKm2QBAF5VUFCghQsXKikpSQEBAXr//fe1fv16ZWZm+npoMBhnUAAAXvXf//5XQ4YM0e7du3X58mW1atVKkydP1oMPPujrocFgBBQAAGAcbpIFAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIzz/wGlYiIGPQ6XAQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretrain_freq.hist(bins=np.arange(0,1,0.05))\n",
    "plt.xlabel('Fraction of non-NaN values in Pretraining Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Peak Variance in Finetune Data')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finetune_var.hist(bins=50)\n",
    "plt.xlabel('Peak Variance in Finetune Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chose a fraction of the peaks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2736, 3)\n"
     ]
    }
   ],
   "source": [
    "temp = pd.concat([finetune_freq, pretrain_freq, finetune_var], axis=1)\n",
    "temp.columns = ['finetune_freq', 'pretrain_freq', 'finetune_var']\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the peaks of size  2736\n",
      "Number of top_10 captured: 10 out of 10: 1.00\n",
      "Number of top_25 captured: 23 out of 25: 0.92\n",
      "Number of 168_os_pfs captured: 134 out of 168: 0.80\n",
      "Number of net_matched captured: 73 out of 86: 0.85\n",
      "Number of rcc_targets captured: 159 out of 188: 0.85\n"
     ]
    }
   ],
   "source": [
    "# check that the Matt feats are found in the RCC peaks\n",
    "print('In the peaks of size ', temp.shape[0])\n",
    "for matt_ft_name, matt_ft_list in matt_ft_dict.items():\n",
    "    captured_peaks = get_captured_fts(matt_ft_list, temp.index)\n",
    "    print(f'Number of {matt_ft_name} captured: {len(captured_peaks)} out of {len(matt_ft_list)}: {len(captured_peaks)/len(matt_ft_list):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9068523076506994\n",
      "(941, 3)\n",
      "In the peaks of size  941\n",
      "Number of top_10 captured: 2 out of 10: 0.20\n",
      "Number of top_25 captured: 9 out of 25: 0.36\n",
      "Number of 168_os_pfs captured: 52 out of 168: 0.31\n",
      "Number of net_matched captured: 26 out of 86: 0.30\n",
      "Number of rcc_targets captured: 84 out of 188: 0.45\n"
     ]
    }
   ],
   "source": [
    "finetune_var_q = 0.05\n",
    "finetune_var_th = temp['finetune_var'].quantile(finetune_var_q)\n",
    "print(finetune_var_th)\n",
    "# finetune_var_th = 0.5#0.75\n",
    "finetune_freq_th = 0.9\n",
    "pretrain_freq_th = 0.3 #0.35\n",
    "\n",
    "finetune_filter = (finetune_var >= finetune_var_th) & (finetune_freq >= finetune_freq_th) & (pretrain_freq >= pretrain_freq_th)\n",
    "\n",
    "temp_filter = temp[finetune_filter]\n",
    "print(temp_filter.shape)\n",
    "\n",
    "\n",
    "print('In the peaks of size ', temp_filter.shape[0])\n",
    "for matt_ft_name, matt_ft_list in matt_ft_dict.items():\n",
    "    captured_peaks = get_captured_fts(matt_ft_list, temp_filter.index)\n",
    "    print(f'Number of {matt_ft_name} captured: {len(captured_peaks)} out of {len(matt_ft_list)}: {len(captured_peaks)/len(matt_ft_list):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finetune_freq</th>\n",
       "      <th>pretrain_freq</th>\n",
       "      <th>finetune_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FT10031</th>\n",
       "      <td>0.463252</td>\n",
       "      <td>0.272486</td>\n",
       "      <td>1.035956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT10035</th>\n",
       "      <td>0.982183</td>\n",
       "      <td>0.227632</td>\n",
       "      <td>1.027943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT10037</th>\n",
       "      <td>0.467706</td>\n",
       "      <td>0.396542</td>\n",
       "      <td>1.079680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT10039</th>\n",
       "      <td>0.982183</td>\n",
       "      <td>0.296978</td>\n",
       "      <td>0.976793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT10041</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.267764</td>\n",
       "      <td>1.045069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT9985</th>\n",
       "      <td>0.759465</td>\n",
       "      <td>0.147014</td>\n",
       "      <td>0.968094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT9988</th>\n",
       "      <td>0.859688</td>\n",
       "      <td>0.196471</td>\n",
       "      <td>1.147949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT9989</th>\n",
       "      <td>0.979955</td>\n",
       "      <td>0.348737</td>\n",
       "      <td>1.038769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT9997</th>\n",
       "      <td>0.953229</td>\n",
       "      <td>0.260033</td>\n",
       "      <td>1.082380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT9999</th>\n",
       "      <td>0.933185</td>\n",
       "      <td>0.127892</td>\n",
       "      <td>0.974373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2736 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         finetune_freq  pretrain_freq  finetune_var\n",
       "FT10031       0.463252       0.272486      1.035956\n",
       "FT10035       0.982183       0.227632      1.027943\n",
       "FT10037       0.467706       0.396542      1.079680\n",
       "FT10039       0.982183       0.296978      0.976793\n",
       "FT10041       1.000000       0.267764      1.045069\n",
       "...                ...            ...           ...\n",
       "FT9985        0.759465       0.147014      0.968094\n",
       "FT9988        0.859688       0.196471      1.147949\n",
       "FT9989        0.979955       0.348737      1.038769\n",
       "FT9997        0.953229       0.260033      1.082380\n",
       "FT9999        0.933185       0.127892      0.974373\n",
       "\n",
       "[2736 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Train, Val, and Test data sets\n",
    "\n",
    "X_train = X_data.loc[finetune_files]\n",
    "y_train = y_data.loc[finetune_files, finetune_label_col]\n",
    "y_train = y_train.dropna()\n",
    "X_train = X_train.loc[y_train.index]\n",
    "\n",
    "\n",
    "X_val = X_data.loc[holdout_val_files]\n",
    "y_val = y_data.loc[holdout_val_files, finetune_label_col]\n",
    "y_val = y_val.dropna()\n",
    "X_val = X_val.loc[y_val.index]\n",
    "\n",
    "\n",
    "X_test = X_data.loc[holdout_test_files]\n",
    "y_test = y_data.loc[holdout_test_files, finetune_label_col]\n",
    "y_test = y_test.dropna()\n",
    "X_test = X_test.loc[y_test.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print('sklearn version: ', sklearn.__version__)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=20, random_state=42)\n",
    "# n_iter = 10\n",
    "# verbose = 0\n",
    "\n",
    "# def scoring_func(estimator, X, y):\n",
    "#     y_prob = estimator.predict_proba(X)[:,1]\n",
    "#     return roc_auc_score(y, y_prob, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sklearn_fitter(data_dict, param_grid, \n",
    "                      output_dir, model_kind, model_name,\n",
    "                      cv=None, n_iter=10, scoring_func=None, verbose=0):\n",
    "    if cv is None:\n",
    "        cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=20, random_state=42)\n",
    "    \n",
    "    if scoring_func is None:\n",
    "        # depends on which sklearn version we are using\n",
    "        # scoring_func = make_scorer(roc_auc_score, average='weighted', response_method='predict_proba')\n",
    "        scoring_func = make_scorer(roc_auc_score, average='weighted', needs_proba=True)\n",
    "\n",
    "    if model_kind == 'logistic_regression':\n",
    "        base_model = LogisticRegression(max_iter=1000)\n",
    "    elif model_kind == 'random_forest':\n",
    "        base_model = RandomForestClassifier()\n",
    "    elif model_kind == 'decision_tree':\n",
    "        base_model = DecisionTreeClassifier()\n",
    "    elif model_kind == 'svc':\n",
    "        base_model = SVC(probability=True)\n",
    "\n",
    "    model = RandomizedSearchCV(base_model, \n",
    "                               param_distributions=param_grid, \n",
    "                               n_iter=n_iter, \n",
    "                               cv=cv, \n",
    "                               scoring=scoring_func, \n",
    "                               verbose=verbose, \n",
    "                               random_state=1010,\n",
    "                               n_jobs=1)\n",
    "    X_train, y_train = data_dict['X_train'], data_dict['y_train']\n",
    "    X_val, y_val = data_dict['X_val'], data_dict['y_val']\n",
    "    X_test, y_test = data_dict['X_test'], data_dict['y_test']\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    model_results = pd.DataFrame(model.cv_results_)\n",
    "\n",
    "    model_results.sort_values('rank_test_score', inplace=True)\n",
    "    model_results.iloc[0]['mean_test_score']\n",
    "    cv_score = model_results.iloc[0]['mean_test_score']\n",
    "    cv_score_std = model_results.iloc[0]['std_test_score']\n",
    "    print(f'Train CV score: {cv_score} +/- {cv_score_std}')\n",
    "\n",
    "\n",
    "    y_train_proba = model.predict_proba(X_train)[:,1]\n",
    "    train_score = roc_auc_score(y_train, y_train_proba, average='weighted')\n",
    "    print(f'Training score: {train_score}')\n",
    "\n",
    "\n",
    "    y_val_proba = model.predict_proba(X_val)[:,1]\n",
    "    val_score = roc_auc_score(y_val, y_val_proba, average='weighted')\n",
    "    print(f'Validation score: {val_score}')\n",
    "\n",
    "\n",
    "    y_test_proba = model.predict_proba(X_test)[:,1]\n",
    "    test_score = roc_auc_score(y_test, y_test_proba, average='weighted')\n",
    "    print(f'Test score: {test_score}')\n",
    "\n",
    "\n",
    "    model_summary = {\n",
    "        'model_kind': model_kind,\n",
    "        'model_name': model_name,\n",
    "        'n_input ft': X_train.shape[1],\n",
    "        'param_grid' : param_grid,\n",
    "        'best_params': model.best_params_,\n",
    "        'score name': 'roc_auc (weighted)',\n",
    "        'cv_score': cv_score,\n",
    "        'cv_score_std': cv_score_std,\n",
    "        'train_score': train_score,\n",
    "        'val_score': val_score,\n",
    "        'test_score': test_score,\n",
    "        'train sz': X_train.shape[0],\n",
    "        'val sz': X_val.shape[0],\n",
    "        'test sz': X_test.shape[0],\n",
    "    }\n",
    "\n",
    "    save_json(model_summary, os.path.join(output_dir, f'{model_name}_summary.json'))\n",
    "\n",
    "    return model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CV score: 0.9002987502964895 +/- 0.03896609936556677\n",
      "Training score: 1.0\n",
      "Validation score: 0.8724489795918368\n",
      "Test score: 0.9145299145299145\n",
      "Train CV score: 0.8972884176351993 +/- 0.039409576371011154\n",
      "Training score: 1.0\n",
      "Validation score: 0.8731778425655978\n",
      "Test score: 0.9138176638176638\n",
      "Train CV score: 0.899369514943074 +/- 0.03948372857823047\n",
      "Training score: 1.0\n",
      "Validation score: 0.8709912536443148\n",
      "Test score: 0.9116809116809117\n",
      "Train CV score: 0.8964920096062617 +/- 0.040219899490247964\n",
      "Training score: 1.0\n",
      "Validation score: 0.8644314868804666\n",
      "Test score: 0.9081196581196581\n",
      "Train CV score: 0.8961666493714421 +/- 0.04129368129163213\n",
      "Training score: 0.9999236874236874\n",
      "Validation score: 0.8651603498542275\n",
      "Test score: 0.9045584045584044\n",
      "Train CV score: 0.8982221003320684 +/- 0.04055922191551272\n",
      "Training score: 0.9999236874236874\n",
      "Validation score: 0.8709912536443147\n",
      "Test score: 0.8981481481481481\n",
      "Train CV score: 0.8930581045422202 +/- 0.041262554436873766\n",
      "Training score: 0.9987789987789988\n",
      "Validation score: 0.8556851311953352\n",
      "Test score: 0.8952991452991453\n"
     ]
    }
   ],
   "source": [
    "var_quantile = 0.\n",
    "for var_quantile in [0,0.05,0.1,0.2,0.25,0.33,0.5]:\n",
    "\n",
    "    chosen_fts = finetune_var[finetune_var>finetune_var.quantile(var_quantile)].index.to_list()\n",
    "    feat_filt_name = 'var q{}'.format(var_quantile)\n",
    "\n",
    "\n",
    "    param_grid = {\n",
    "                'penalty': ['l1', 'l2'],\n",
    "                'C': [0.005, 0.1, 0.5, 1, 2, 5, 10],\n",
    "                'solver' : ['liblinear'],\n",
    "                'class_weight': ['balanced']\n",
    "                }\n",
    "\n",
    "    model_kind = 'logistic_regression' \n",
    "    model_name = f'{model_kind} optimal'  + f'_{feat_filt_name}'\n",
    "    output_dir = os.path.join(task_dir, 'classical_models_alt')\n",
    "\n",
    "    data_dict = {'X_train': X_train[chosen_fts], \n",
    "                'y_train': y_train, \n",
    "                'X_val': X_val[chosen_fts], \n",
    "                'y_val': y_val, \n",
    "                'X_test': X_test[chosen_fts], \n",
    "                'y_test': y_test}\n",
    "\n",
    "\n",
    "    out = my_sklearn_fitter(data_dict, param_grid, \n",
    "                        output_dir, model_kind, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression optimal_var q0.1_summary.json\n",
      "logistic_regression optimal_var q0_summary.json\n",
      "logistic_regression optimal_var q0.33_summary.json\n",
      "logistic_regression optimal_var q0.05_summary.json\n",
      "logistic_regression optimal_var q0.25_summary.json\n",
      "logistic_regression optimal_var q0.5_summary.json\n",
      "logistic_regression optimal_var q0.2_summary.json\n"
     ]
    }
   ],
   "source": [
    "output_files = os.listdir(output_dir)\n",
    "output_summary_files = [f for f in output_files if f.endswith('summary.json')]\n",
    "other_files = [f for f in output_files if f not in output_summary_files]\n",
    "\n",
    "all_res = []\n",
    "df_cols = ['model_kind','model_name','n_input ft','cv_score','train_score','val_score', 'test_score']\n",
    "for f in output_summary_files:\n",
    "    print(f)\n",
    "    model_name = f.split('_summary.json')[0]\n",
    "    res = json.load(open(os.path.join(output_dir, f)))\n",
    "    res_df = pd.DataFrame({k: res[k] for k in df_cols}, index=[model_name])\n",
    "    all_res.append(res_df)\n",
    "\n",
    "\n",
    "res_summary = pd.concat(all_res, axis=0)    \n",
    "res_summary = res_summary.round(4)\n",
    "res_summary.to_csv(os.path.join(task_dir, 'classical_alt_summary.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notepad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CV score: 0.9003188374644213 +/- 0.03904511044706044\n",
      "Training score: 1.0\n",
      "Validation score: 0.8731778425655976\n",
      "Test score: 0.9145299145299145\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'C': [0.005, 0.1, 0.5, 1, 2, 5, 10],\n",
    "            'solver' : ['liblinear'],\n",
    "            'class_weight': ['balanced']\n",
    "            }\n",
    "model_kind = 'logistic_regression' \n",
    "model_name = f'{model_kind} optimal1'   \n",
    "output_dir = os.path.join(task_dir, 'classical_models_alt')\n",
    "\n",
    "\n",
    "out2 = my_sklearn_fitter(data_dict, param_grid, \n",
    "                      output_dir, model_kind, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonaheaton/opt/miniconda3/envs/mzlearn_3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 14 is smaller than n_iter=50. Running 14 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CV score: 0.9003188374644213 +/- 0.03904511044706044\n",
      "Training score: 1.0\n",
      "Validation score: 0.8731778425655976\n",
      "Test score: 0.9145299145299145\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'C': [0.005, 0.1, 0.5, 1, 2, 5, 10],\n",
    "            'solver' : ['liblinear'],\n",
    "            'class_weight': ['balanced']\n",
    "            }\n",
    "model_kind = 'logistic_regression' \n",
    "model_name = f'{model_kind} optimal1'   \n",
    "output_dir = os.path.join(task_dir, 'classical_models_alt')\n",
    "\n",
    "\n",
    "out1 = my_sklearn_fitter(data_dict, param_grid, \n",
    "                      output_dir, model_kind, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = LogisticRegression(max_iter=1000)\n",
    "param_grid = {\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'C': [0.005, 0.1, 0.5, 1, 2, 5, 10],\n",
    "            'solver' : ['liblinear'],\n",
    "            'class_weight': ['balanced']\n",
    "            }\n",
    "model = RandomizedSearchCV(base_model, param_distributions=param_grid, \n",
    "                        n_iter=n_iter, cv=cv, verbose=verbose, \n",
    "                        random_state=1010, n_jobs=-1, scoring=scoring_func)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "# save the model results\n",
    "model_results = pd.DataFrame(model.cv_results_)\n",
    "best_model = model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CV score: 0.9003188374644213 +/- 0.03904511044706044\n"
     ]
    }
   ],
   "source": [
    "model_results.sort_values('rank_test_score', inplace=True)\n",
    "model_results.iloc[0]['mean_test_score']\n",
    "cv_score = model_results.iloc[0]['mean_test_score']\n",
    "cv_score_std = model_results.iloc[0]['std_test_score']\n",
    "print(f'Train CV score: {cv_score} +/- {cv_score_std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_train_proba = best_model.predict_proba(X_train)[:,1]\n",
    "train_score = roc_auc_score(y_train, y_train_proba, average='weighted')\n",
    "print(f'Training score: {train_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.8731778425655976\n"
     ]
    }
   ],
   "source": [
    "y_val_proba = best_model.predict_proba(X_val)[:,1]\n",
    "val_score = roc_auc_score(y_val, y_val_proba, average='weighted')\n",
    "print(f'Validation score: {val_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.9145299145299145\n"
     ]
    }
   ],
   "source": [
    "y_test_proba = best_model.predict_proba(X_test)[:,1]\n",
    "test_score = roc_auc_score(y_test, y_test_proba, average='weighted')\n",
    "print(f'Test score: {test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary = {\n",
    "    'model_kind': model_kind,\n",
    "    'model_name': model_name,\n",
    "    'param_grid' : param_grid,\n",
    "    'best_params': model.best_params_,\n",
    "    'cv_score': cv_score,\n",
    "    'cv_score_std': cv_score_std,\n",
    "    'train_score': train_score,\n",
    "    'val_score': val_score,\n",
    "    'test_score': test_score\n",
    "}\n",
    "\n",
    "save_json(model_summary, os.path.join(output_dir, f'{model_name}_summary.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_kind': 'logistic_regression',\n",
       " 'model_name': 'logistic_regression optimal',\n",
       " 'param_grid': {'penalty': ['l1', 'l2'],\n",
       "  'C': [0.005, 0.1, 0.5, 1, 2, 5, 10],\n",
       "  'solver': ['liblinear'],\n",
       "  'class_weight': ['balanced']},\n",
       " 'best_params': {'solver': 'liblinear',\n",
       "  'penalty': 'l2',\n",
       "  'class_weight': 'balanced',\n",
       "  'C': 0.005},\n",
       " 'cv_score': 0.9003188374644213,\n",
       " 'cv_score_std': 0.03904511044706044,\n",
       " 'train_score': 1.0,\n",
       " 'val_score': 0.8731778425655976,\n",
       " 'test_score': 0.9145299145299145}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cycle over the different models and run repeated cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression optimal_summary.json\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m     res \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, f)))\n\u001b[1;32m     11\u001b[0m     res_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({k: res[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m df_cols}, index\u001b[38;5;241m=\u001b[39m[model_name])\n\u001b[0;32m---> 14\u001b[0m res_summary \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m    \n\u001b[1;32m     15\u001b[0m res_summary \u001b[38;5;241m=\u001b[39m res_summary\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# res_summary.to_csv(os.path.join(task_dir, 'classical_summary.csv'))\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/mzlearn_3/lib/python3.9/site-packages/pandas/core/reshape/concat.py:380\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/mzlearn_3/lib/python3.9/site-packages/pandas/core/reshape/concat.py:443\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[0;32m--> 443\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    446\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/mzlearn_3/lib/python3.9/site-packages/pandas/core/reshape/concat.py:505\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    502\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "output_files = os.listdir(output_dir)\n",
    "output_summary_files = [f for f in output_files if f.endswith('summary.json')]\n",
    "other_files = [f for f in output_files if f not in output_summary_files]\n",
    "\n",
    "all_res = []\n",
    "df_cols = ['model_kind','model_name','n_input ft','cv_score','train_score','val_score', 'test_score']\n",
    "for f in output_summary_files:\n",
    "    print(f)\n",
    "    model_name = f.split('_summary.json')[0]\n",
    "    res = json.load(open(os.path.join(output_dir, f)))\n",
    "    res_df = pd.DataFrame({k: res[k] for k in df_cols}, index=[model_name])\n",
    "\n",
    "\n",
    "res_summary = pd.concat(all_res, axis=1)    \n",
    "res_summary = res_summary.round(4)\n",
    "# res_summary.to_csv(os.path.join(task_dir, 'classical_summary.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_kind</th>\n",
       "      <th>model_name</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>cv_score_std</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic_regression optimal</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>logistic_regression optimal</td>\n",
       "      <td>0.900319</td>\n",
       "      <td>0.039045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.873178</td>\n",
       "      <td>0.91453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      model_kind                   model_name  \\\n",
       "logistic_regression optimal  logistic_regression  logistic_regression optimal   \n",
       "\n",
       "                             cv_score  cv_score_std  train_score  val_score  \\\n",
       "logistic_regression optimal  0.900319      0.039045          1.0   0.873178   \n",
       "\n",
       "                             test_score  \n",
       "logistic_regression optimal     0.91453  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_kind': 'logistic_regression',\n",
       " 'model_name': 'logistic_regression optimal',\n",
       " 'param_grid': {'penalty': ['l1', 'l2'],\n",
       "  'C': [0.005, 0.1, 0.5, 1, 2, 5, 10],\n",
       "  'solver': ['liblinear'],\n",
       "  'class_weight': ['balanced']},\n",
       " 'best_params': {'solver': 'liblinear',\n",
       "  'penalty': 'l2',\n",
       "  'class_weight': 'balanced',\n",
       "  'C': 0.005},\n",
       " 'cv_score': 0.9003188374644213,\n",
       " 'cv_score_std': 0.03904511044706044,\n",
       " 'train_score': 1.0,\n",
       " 'val_score': 0.8731778425655976,\n",
       " 'test_score': 0.9145299145299145}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_hold_idx = holdout_val_files\n",
    "Xval = X_data.loc[val_hold_idx]\n",
    "yval = y_data.loc[val_hold_idx, finetune_label_col]\n",
    "if yes_dropna:\n",
    "    yval = yval.dropna()\n",
    "    Xval = Xval.loc[yval.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping nan values in the y column\n",
      "number of samples after dropping nan values in the y column:  240\n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.join(task_dir, 'classical_models')\n",
    "if finetune_label_mapper:\n",
    "    y_values = y[finetune_label_col].map(finetune_label_mapper)\n",
    "else:\n",
    "    y_values = y[finetune_label_col]\n",
    "    \n",
    "if yes_dropna:\n",
    "    print('dropping nan values in the y column')\n",
    "    y_values = y_values.dropna()\n",
    "    X = X.loc[y_values.index]\n",
    "    splits_df = splits_df.loc[y_values.index]\n",
    "\n",
    "    print('number of samples after dropping nan values in the y column: ', y_values.shape[0])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping nan values in the y column\n",
      "number of samples after dropping nan values in the y column:  156\n",
      "svc_default_summary.csv\n",
      "logistic_regression_default_summary.csv\n",
      "random_forest_default_summary.csv\n"
     ]
    }
   ],
   "source": [
    "delete_other_files = False #delete the files generated from each fitting in the repeated Cross-validation\n",
    "optimization_desc = 'default' #use sklearn's default hyperparameters\n",
    "# optimization_desc = 'optimal' # use the default hyperparameter gridsearch specified in run_train_sklearn_model\n",
    "\n",
    "which_models = ['logistic_regression', 'random_forest', 'svc']\n",
    "# which_models = ['logistic_regression']\n",
    "\n",
    "\n",
    "for model_kind in which_models:\n",
    "    gather_output = []\n",
    "    model_name = model_kind + '_' + optimization_desc\n",
    "    output_summary_file = os.path.join(output_dir, f'{model_name}_summary.csv')\n",
    "    \n",
    "    if optimization_desc == 'default':\n",
    "        param_grid = {}\n",
    "    elif optimization_desc == 'optimal':\n",
    "        param_grid = None # use the default hyperparameter gridsearch specified in run_train_sklearn_model\n",
    "\n",
    "    for subset_id in range(n_folds):\n",
    "\n",
    "\n",
    "\n",
    "        train_idx = splits_df.index[splits_df[f'fold_{subset_id}'] == False]\n",
    "        test_idx = splits_df.index[splits_df[f'fold_{subset_id}'] == True]\n",
    "        finetune_dataset = SimpleDataset(X.loc[train_idx], y_values.loc[train_idx])\n",
    "        \n",
    "        class_weights = 1 / torch.bincount(finetune_dataset.y.long())\n",
    "\n",
    "        test_dataset = SimpleDataset(X.loc[test_idx], y_values.loc[test_idx])\n",
    "\n",
    "        data_dict = {'train': finetune_dataset, 'CV': test_dataset}\n",
    "\n",
    "        #if you want to add the validation set to the final evaluation\n",
    "        data_dict['val'] = SimpleDataset(Xval, yval)\n",
    "\n",
    "        ##### ##### ##### ##### ##### ##### ##### ##### ##### #####\n",
    "        ##### Here is the code that actually runs the model optimization #####\n",
    "        output_data = run_train_sklearn_model(data_dict,output_dir,\n",
    "                                model_kind = model_kind,\n",
    "                                model_name=f'{model_name}_{subset_id}',\n",
    "                                param_grid=param_grid\n",
    "                                )\n",
    "        ##### ##### ##### ##### ##### ##### ##### ##### ##### #####\n",
    "        \n",
    "\n",
    "        gather_output.append(output_data)\n",
    "\n",
    "    ## Summarize the important results\n",
    "    # best_epoch_list = [output['best_epoch'] for output in gather_output]\n",
    "        \n",
    "    auc_summary_dct = {}\n",
    "    for phase in data_dict.keys():\n",
    "        auc_summary_dct[phase + ' AUROC'] = [output['end_state_auroc'][phase] for output in gather_output]\n",
    "\n",
    "    # cv_auroc_list = [output['end_state_auroc']['CV'] for output in gather_output]\n",
    "    # train_auroc_list = [output['end_state_auroc']['train'] for output in gather_output]\n",
    "    # model_name = gather_output[0]['model_name']\n",
    "    auc_summary = pd.DataFrame(auc_summary_dct)\n",
    "\n",
    "\n",
    "    result_summary_avg = auc_summary.mean()\n",
    "    result_summary_std = auc_summary.std()\n",
    "    result_summary_avg.index = [f'AVG {col}' for col in result_summary_avg.index]\n",
    "    result_summary_std.index = [f'STD {col}' for col in result_summary_std.index]\n",
    "    result_summary = pd.concat([result_summary_avg, result_summary_std])\n",
    "    result_summary.to_csv(output_summary_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "output_files = os.listdir(output_dir)\n",
    "output_summary_files = [f for f in output_files if f.endswith('summary.csv')]\n",
    "other_files = [f for f in output_files if f not in output_summary_files]\n",
    "\n",
    "all_res = []\n",
    "\n",
    "for f in output_summary_files:\n",
    "    print(f)\n",
    "    model_name = f.split('_summary.csv')[0]\n",
    "    res = pd.read_csv(os.path.join(output_dir, f), index_col=0)\n",
    "    res.columns = [model_name]\n",
    "    all_res.append(res)\n",
    "    \n",
    "# delete the other files to save room\n",
    "if delete_other_files:\n",
    "    for f in other_files:\n",
    "        os.remove(os.path.join(output_dir, f))    \n",
    "\n",
    "res_summary = pd.concat(all_res, axis=1)    \n",
    "res_summary = res_summary.round(4)\n",
    "res_summary.to_csv(os.path.join(task_dir, 'classical_summary.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression_default val val auc: 0.8607871532440186\n",
      "random_forest_default val val auc: 0.931851327419281\n",
      "svc_default val val auc: 0.9256560802459717\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "data_dict['train'] = SimpleDataset(X, y_values)\n",
    "data_dict['test'] = SimpleDataset(Xval, yval)\n",
    "\n",
    "for model_kind in which_models:\n",
    "\n",
    "        model_name = model_kind + '_' + optimization_desc +' val'\n",
    "\n",
    "        output_data = run_train_sklearn_model(data_dict,output_dir,\n",
    "                                model_kind = model_kind,\n",
    "                                model_name=f'{model_name}',\n",
    "                                param_grid=param_grid\n",
    "                                )\n",
    "        \n",
    "        valauc = output_data['end_state_auroc']['test']\n",
    "        print(f'{model_name} val auc: {valauc}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SimpleDataset at 0x7fc8fd402070>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svc_default</th>\n",
       "      <th>logistic_regression_default</th>\n",
       "      <th>logistic_regression_optimal</th>\n",
       "      <th>random_forest_default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AVG train AUROC</th>\n",
       "      <td>0.980</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVG CV AUROC</th>\n",
       "      <td>0.646</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD train AUROC</th>\n",
       "      <td>0.141</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD CV AUROC</th>\n",
       "      <td>0.090</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 svc_default  logistic_regression_default  \\\n",
       "AVG train AUROC        0.980                        1.000   \n",
       "AVG CV AUROC           0.646                        0.655   \n",
       "STD train AUROC        0.141                        0.000   \n",
       "STD CV AUROC           0.090                        0.074   \n",
       "\n",
       "                 logistic_regression_optimal  random_forest_default  \n",
       "AVG train AUROC                        0.998                  1.000  \n",
       "AVG CV AUROC                           0.634                  0.629  \n",
       "STD train AUROC                        0.008                  0.000  \n",
       "STD CV AUROC                           0.080                  0.074  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_summary.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train AUROC</th>\n",
       "      <th>CV AUROC</th>\n",
       "      <th>val AUROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999881</td>\n",
       "      <td>0.891841</td>\n",
       "      <td>0.908163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857685</td>\n",
       "      <td>0.919096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973435</td>\n",
       "      <td>0.924198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999761</td>\n",
       "      <td>0.884250</td>\n",
       "      <td>0.934402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999881</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>0.930029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.927114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920304</td>\n",
       "      <td>0.910350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.999761</td>\n",
       "      <td>0.861480</td>\n",
       "      <td>0.931487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872865</td>\n",
       "      <td>0.917638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845703</td>\n",
       "      <td>0.928572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.924927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891841</td>\n",
       "      <td>0.924198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950664</td>\n",
       "      <td>0.922741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897533</td>\n",
       "      <td>0.934402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.791016</td>\n",
       "      <td>0.917639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.874763</td>\n",
       "      <td>0.922741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.999881</td>\n",
       "      <td>0.880455</td>\n",
       "      <td>0.912536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.999881</td>\n",
       "      <td>0.876660</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933586</td>\n",
       "      <td>0.924927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.767578</td>\n",
       "      <td>0.916910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.999761</td>\n",
       "      <td>0.918406</td>\n",
       "      <td>0.932945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.999881</td>\n",
       "      <td>0.833017</td>\n",
       "      <td>0.915452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.999881</td>\n",
       "      <td>0.920304</td>\n",
       "      <td>0.911808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878558</td>\n",
       "      <td>0.913265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.851562</td>\n",
       "      <td>0.927843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914611</td>\n",
       "      <td>0.911079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.917639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950664</td>\n",
       "      <td>0.923469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899431</td>\n",
       "      <td>0.922012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.999644</td>\n",
       "      <td>0.806641</td>\n",
       "      <td>0.935860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.999881</td>\n",
       "      <td>0.943074</td>\n",
       "      <td>0.917639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.787476</td>\n",
       "      <td>0.919096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.999881</td>\n",
       "      <td>0.905123</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.919096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.999881</td>\n",
       "      <td>0.892578</td>\n",
       "      <td>0.924198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908918</td>\n",
       "      <td>0.930029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.795066</td>\n",
       "      <td>0.924927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891841</td>\n",
       "      <td>0.916910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922201</td>\n",
       "      <td>0.920554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.999763</td>\n",
       "      <td>0.910156</td>\n",
       "      <td>0.918367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.927894</td>\n",
       "      <td>0.920554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.999761</td>\n",
       "      <td>0.914611</td>\n",
       "      <td>0.922012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.999761</td>\n",
       "      <td>0.848197</td>\n",
       "      <td>0.918367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.999881</td>\n",
       "      <td>0.844402</td>\n",
       "      <td>0.920554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893555</td>\n",
       "      <td>0.920554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893738</td>\n",
       "      <td>0.911808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876660</td>\n",
       "      <td>0.929300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.999642</td>\n",
       "      <td>0.878558</td>\n",
       "      <td>0.924927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922201</td>\n",
       "      <td>0.922012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900391</td>\n",
       "      <td>0.935131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train AUROC  CV AUROC  val AUROC\n",
       "0      0.999881  0.891841   0.908163\n",
       "1      1.000000  0.857685   0.919096\n",
       "2      1.000000  0.973435   0.924198\n",
       "3      0.999761  0.884250   0.934402\n",
       "4      0.999881  0.882812   0.930029\n",
       "5      1.000000  0.941176   0.927114\n",
       "6      1.000000  0.920304   0.910350\n",
       "7      0.999761  0.861480   0.931487\n",
       "8      1.000000  0.872865   0.917638\n",
       "9      1.000000  0.845703   0.928572\n",
       "10     1.000000  0.882353   0.924927\n",
       "11     1.000000  0.891841   0.924198\n",
       "12     1.000000  0.950664   0.922741\n",
       "13     1.000000  0.897533   0.934402\n",
       "14     1.000000  0.791016   0.917639\n",
       "15     1.000000  0.874763   0.922741\n",
       "16     0.999881  0.880455   0.912536\n",
       "17     0.999881  0.876660   0.928571\n",
       "18     1.000000  0.933586   0.924927\n",
       "19     1.000000  0.767578   0.916910\n",
       "20     0.999761  0.918406   0.932945\n",
       "21     0.999881  0.833017   0.915452\n",
       "22     0.999881  0.920304   0.911808\n",
       "23     1.000000  0.878558   0.913265\n",
       "24     1.000000  0.851562   0.927843\n",
       "25     1.000000  0.914611   0.911079\n",
       "26     1.000000  0.838710   0.917639\n",
       "27     1.000000  0.950664   0.923469\n",
       "28     1.000000  0.899431   0.922012\n",
       "29     0.999644  0.806641   0.935860\n",
       "30     0.999881  0.943074   0.917639\n",
       "31     1.000000  0.787476   0.919096\n",
       "32     0.999881  0.905123   0.928571\n",
       "33     1.000000  0.882353   0.919096\n",
       "34     0.999881  0.892578   0.924198\n",
       "35     1.000000  0.908918   0.930029\n",
       "36     1.000000  0.795066   0.924927\n",
       "37     1.000000  0.891841   0.916910\n",
       "38     1.000000  0.922201   0.920554\n",
       "39     0.999763  0.910156   0.918367\n",
       "40     1.000000  0.927894   0.920554\n",
       "41     0.999761  0.914611   0.922012\n",
       "42     0.999761  0.848197   0.918367\n",
       "43     0.999881  0.844402   0.920554\n",
       "44     1.000000  0.893555   0.920554\n",
       "45     1.000000  0.893738   0.911808\n",
       "46     1.000000  0.876660   0.929300\n",
       "47     0.999642  0.878558   0.924927\n",
       "48     1.000000  0.922201   0.922012\n",
       "49     1.000000  0.900391   0.935131"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to check if a variable is a function\n",
    "callable(run_train_sklearn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callable(subset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17685, 2736)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FT10031   -0.002666\n",
       "FT10035   -0.005164\n",
       "FT10037   -0.003603\n",
       "FT10039   -0.004585\n",
       "FT10041   -0.007062\n",
       "             ...   \n",
       "FT9985    -0.007561\n",
       "FT9988    -0.006673\n",
       "FT9989    -0.004516\n",
       "FT9997    -0.006612\n",
       "FT9999    -0.008210\n",
       "Length: 2736, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.sum(axis=0)/X_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mzlearn_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
