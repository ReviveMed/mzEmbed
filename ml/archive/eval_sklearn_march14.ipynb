{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version:  1.3.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "\n",
    "from misc import save_json, get_dropbox_dir\n",
    "\n",
    "from sklearn_models import sklearn_fit_eval_wrapper, sklearn_fitCV_eval_wrapper\n",
    "\n",
    "\n",
    "import sklearn\n",
    "print('sklearn version: ', sklearn.__version__)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_dir = '/Users/jonaheaton/ReviveMed Dropbox/Jonah Eaton/development_CohortCombination/alignment_RCC_2024_Feb_27/March_12_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = pd.read_csv(os.path.join(subset_dir, 'X.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_mask = pd.read_csv(os.path.join(subset_dir, 'nans.csv'), index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = pd.read_csv(os.path.join(subset_dir, 'y.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples:  17685\n",
      "number of features:  2736\n"
     ]
    }
   ],
   "source": [
    "print('number of samples: ', X_data.shape[0])\n",
    "print('number of features: ', X_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_files = y_data[y_data['Set']=='Pretrain'].index.to_list()\n",
    "finetune_files = y_data[y_data['Set']=='Finetune'].index.to_list()\n",
    "holdout_test_files = y_data[y_data['Set']=='Test'].index.to_list()\n",
    "holdout_val_files = y_data[y_data['Set']=='Validation'].index.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2736, 3)\n"
     ]
    }
   ],
   "source": [
    "finetune_freq = 1 - nan_mask.loc[finetune_files].sum(axis=0)/ len(finetune_files)\n",
    "pretrain_freq = 1- nan_mask.loc[pretrain_files].sum(axis=0)/ len(pretrain_files)\n",
    "finetune_var = X_data.loc[finetune_files].var(axis=0)\n",
    "\n",
    "temp = pd.concat([finetune_freq, pretrain_freq, finetune_var], axis=1)\n",
    "temp.columns = ['finetune_freq', 'pretrain_freq', 'finetune_var']\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_splits': 5, 'n_repeats': 10, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "stratify_col = 'MSKCC BINARY'\n",
    "splits_dir = os.path.join(subset_dir, f'{stratify_col} finetune_folds')\n",
    "\n",
    "# although 50 splits were created, only 5 are used for finetuning\n",
    "\n",
    "with open(os.path.join(splits_dir, 'splits_info.json'), 'r') as f:\n",
    "    rskf_info = json.load(f)\n",
    "\n",
    "rskf_params = rskf_info['rskf_params']\n",
    "print(rskf_params)\n",
    "\n",
    "rskf_params['n_repeats'] = 100\n",
    "rskf = RepeatedStratifiedKFold(**rskf_params)\n",
    "\n",
    "splits = pd.read_csv(os.path.join(splits_dir, 'splits.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_dropna = True #drops nan values from the label column\n",
    "\n",
    "finetune_label_col = 'MSKCC BINARY'\n",
    "\n",
    "task_dir = os.path.join(splits_dir, finetune_label_col)\n",
    "os.makedirs(task_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8965741889899261\n",
      "(930, 3)\n",
      "Overall frequency of chosen features: 0.549\n"
     ]
    }
   ],
   "source": [
    "finetune_var_q = 0.05\n",
    "# finetune_var_q = 0.05 # meant to use this one, but forgot to change it in the NN optimization\n",
    "finetune_var_th = temp['finetune_var'].quantile(finetune_var_q)\n",
    "print(finetune_var_th)\n",
    "# finetune_var_th = 0.5#0.75\n",
    "finetune_freq_th = 0.9\n",
    "pretrain_freq_th = 0.3 #0.35\n",
    "\n",
    "finetune_filter = (finetune_var >= finetune_var_th) & (finetune_freq >= finetune_freq_th) & (pretrain_freq >= pretrain_freq_th)\n",
    "\n",
    "temp_filter = temp[finetune_filter]\n",
    "print(temp_filter.shape)\n",
    "filtered_feats = temp_filter.index.to_list()\n",
    "all_feats = temp.index.to_list()\n",
    "\n",
    "overall_freq = (1 - nan_mask[filtered_feats].mean(axis=0)).mean()\n",
    "print(f'Overall frequency of chosen features: {overall_freq:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Train, Val, and Test data sets\n",
    "\n",
    "X_train = X_data.loc[finetune_files]\n",
    "y_train = y_data.loc[finetune_files, finetune_label_col]\n",
    "y_train = y_train.dropna()\n",
    "X_train = X_train.loc[y_train.index]\n",
    "\n",
    "\n",
    "X_val = X_data.loc[holdout_val_files]\n",
    "y_val = y_data.loc[holdout_val_files, finetune_label_col]\n",
    "y_val = y_val.dropna()\n",
    "X_val = X_val.loc[y_val.index]\n",
    "\n",
    "\n",
    "X_test = X_data.loc[holdout_test_files]\n",
    "y_test = y_data.loc[holdout_test_files, finetune_label_col]\n",
    "y_test = y_test.dropna()\n",
    "X_test = X_test.loc[y_test.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run RandomGridSearchCV to choose the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    \n",
    "    model_kinds = ['logistic_regression','svc', 'random_forest']\n",
    "\n",
    "    feat_filt_names = ['filtered peaks', 'all peaks']\n",
    "    chosen_fts_list = [filtered_feats, all_feats]\n",
    "    subdir = 'classical_models_alt2'\n",
    "\n",
    "    output_dir = os.path.join(task_dir, subdir)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for model_kind in model_kinds:\n",
    "        print(model_kind)\n",
    "        for feat_filt_name, chosen_fts in zip(feat_filt_names, chosen_fts_list):\n",
    "            print(feat_filt_name)\n",
    "            model_name = f'{model_kind} optimal'  + f'_{feat_filt_name}'\n",
    "\n",
    "            data_dict = {'X_train': X_train[chosen_fts], \n",
    "                        'y_train': y_train, \n",
    "                        'X_val': X_val[chosen_fts], \n",
    "                        'y_val': y_val, \n",
    "                        'X_test': X_test[chosen_fts], \n",
    "                        'y_test': y_test}\n",
    "\n",
    "            if os.path.exists(os.path.join(output_dir, f'{model_name}_summary.json')):\n",
    "                print(f'{model_name} already exists')\n",
    "                \n",
    "                with open(os.path.join(output_dir, f'{model_name}_summary.json'), 'r') as f:\n",
    "                    model_summary = json.load(f)\n",
    "\n",
    "                param_kwargs = model_summary['best_params']\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                out = sklearn_fitCV_eval_wrapper(data_dict=data_dict, \n",
    "                                                model_kind=model_kind, \n",
    "                                                output_dir=output_dir, \n",
    "                                                model_name=model_name, \n",
    "                                                cv = rskf,\n",
    "                                                n_iter=20)\n",
    "                \n",
    "\n",
    "\n",
    "    # compile results into one table\n",
    "\n",
    "    output_files = os.listdir(output_dir)\n",
    "    output_summary_files = [f for f in output_files if f.endswith('summary.json')]\n",
    "    other_files = [f for f in output_files if f not in output_summary_files]\n",
    "\n",
    "    all_res = []\n",
    "    df_cols = ['model_kind','model_name','n_input ft','cv_score','cv_score_std','train_score','val_score', 'test_score', 'test_score (fit on train+val)']\n",
    "    for f in output_summary_files:\n",
    "        print(f)\n",
    "        model_name = f.split('_summary.json')[0]\n",
    "        res = json.load(open(os.path.join(output_dir, f)))\n",
    "        res_df = pd.DataFrame({k: res[k] for k in df_cols}, index=[model_name])\n",
    "        all_res.append(res_df)\n",
    "\n",
    "\n",
    "    res_summary = pd.concat(all_res, axis=0)    \n",
    "    res_summary = res_summary.round(4)\n",
    "    res_summary.to_csv(os.path.join(task_dir, f'{subdir}_summary.csv'))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the validation set to choose the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression\n",
      "filtered peaks\n",
      "all peaks\n",
      "random_forest\n",
      "filtered peaks\n",
      "400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all peaks\n",
      "398\n",
      "svc\n",
      "filtered peaks\n",
      "77\n",
      "warning, running on fewer iterations 77 than requested 100\n",
      "all peaks\n",
      "78\n",
      "warning, running on fewer iterations 78 than requested 100\n"
     ]
    }
   ],
   "source": [
    "model_kinds = ['logistic_regression', 'random_forest', 'svc']\n",
    "\n",
    "\n",
    "feat_filt_names = ['filtered peaks', 'all peaks']\n",
    "chosen_fts_list = [filtered_feats, all_feats]\n",
    "subdir = 'classical_models_alt4'\n",
    "output_dir = os.path.join(task_dir, subdir)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "for model_kind in model_kinds:\n",
    "    print(model_kind)\n",
    "    for feat_filt_name, chosen_fts in zip(feat_filt_names, chosen_fts_list):\n",
    "        print(feat_filt_name)\n",
    "        model_name = f'{model_kind} optimal'  + f'_{feat_filt_name}'\n",
    "\n",
    "        data_dict = {'X_train': X_train[chosen_fts], \n",
    "                    'y_train': y_train, \n",
    "                    'X_val': X_val[chosen_fts], \n",
    "                    'y_val': y_val, \n",
    "                    'X_test': X_test[chosen_fts], \n",
    "                    'y_test': y_test}\n",
    "        \n",
    "        if os.path.exists(os.path.join(output_dir, f'{model_name}_summary.csv')):\n",
    "            continue\n",
    "\n",
    "        sklearn_fit_eval_wrapper(\n",
    "            data_dict=data_dict, \n",
    "            model_kind=model_kind, \n",
    "            output_dir=output_dir, \n",
    "            model_name=model_name,\n",
    "            # param_grid=random_forest_param_grid,\n",
    "            n_iter=100\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
