{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "from neptune.utils import stringify_unsupported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train2 import get_end_state_eval_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 10:18:45.204628: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from setup import setup_neptune_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/jonaheaton/ReviveMed Dropbox/Jonah Eaton/development_CohortCombination/alignment_RCC_2024_Feb_27/March_22_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = 'leakyrelu'\n",
    "encoder_kind = 'AE'\n",
    "# encoder_kind = trial.suggest_categorical('encoder_kind', ['AE', 'VAE'])\n",
    "latent_size = 8\n",
    "\n",
    "\n",
    "\n",
    "encoder_kwargs = {\n",
    "    'activation': activation,\n",
    "    'latent_size': latent_size,\n",
    "    'num_hidden_layers': 2,\n",
    "    'dropout_rate': 0.2,\n",
    "    'use_batch_norm': False,\n",
    "    'hidden_size': 12,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "kwargs = {\n",
    "        ################\n",
    "        ## General ##\n",
    "        'encoder_kind': 'AE',\n",
    "        'encoder_kwargs': encoder_kwargs,\n",
    "        'other_size': 1,\n",
    "\n",
    "        ################\n",
    "        ## Pretrain ##\n",
    "\n",
    "        'holdout_frac': 0.3, # each trial the train/val samples will be different, also not stratified?\n",
    "        'batch_size': 64,\n",
    "        'head_kind': 'NA',\n",
    "        'head_kwargs' : {},\n",
    "        \n",
    "        'adv_kind': 'NA',\n",
    "        'adv_kwargs' : {},\n",
    "\n",
    "        'train_kwargs': {\n",
    "            # 'num_epochs': trial.suggest_int('pretrain_epochs', 10, 100,log=True),\n",
    "            'num_epochs': 10,\n",
    "            'lr': 0.01,\n",
    "            'weight_decay': 0,\n",
    "            'l1_reg_weight': 0,\n",
    "            'l2_reg_weight': 0.001,\n",
    "            'encoder_weight': 1,\n",
    "            'head_weight': 0,\n",
    "            'adversary_weight': 0,\n",
    "            'noise_factor': 0.1,\n",
    "            'early_stopping_patience': 3,\n",
    "            'eval_funcs': get_end_state_eval_funcs(),\n",
    "            'adversarial_mini_epochs': 2,\n",
    "        },\n",
    "\n",
    "        'eval_kwargs' :{\n",
    "            'eval_funcs': get_end_state_eval_funcs(),\n",
    "            'sklearn_models': {\n",
    "                'Adversary Logistic Regression': LogisticRegression(max_iter=1000, C=1.0, solver='lbfgs')\n",
    "            }\n",
    "\n",
    "        }\n",
    "}\n",
    "\n",
    "\n",
    "kwargs['adv_kind'] = 'MultiClassClassifier'\n",
    "kwargs['adv_kwargs'] = {\n",
    "    'hidden_size': 4,\n",
    "    'num_hidden_layers': 1,\n",
    "    'dropout_rate': 0,\n",
    "    'activation': 'leakyrelu',\n",
    "    'use_batch_norm': False,\n",
    "    'num_classes': 19,\n",
    "    }\n",
    "kwargs['train_kwargs']['adversary_weight'] = 1.5\n",
    "\n",
    "\n",
    "kwargs['head_kind'] = 'BinaryClassifier'\n",
    "kwargs['head_kwargs'] = {\n",
    "    'hidden_size': 4,\n",
    "    'num_hidden_layers': 1,\n",
    "    'dropout_rate': 0,\n",
    "    'activation': 'leakyrelu',\n",
    "    'use_batch_norm': False,\n",
    "    'num_classes': 2,\n",
    "    }\n",
    "kwargs['train_kwargs']['head_weight'] = 0.5\n",
    "\n",
    "kwargs['run_training'] = False\n",
    "kwargs['run_evaluation'] = True\n",
    "kwargs['plot_latent_space'] = 'both'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/revivemed/RCC/e/RCC-29\n",
      "Continuing run: RCC-29\n",
      "Error in sklearn model evaluation: 'numpy.ndarray' object has no attribute 'is_floating_point'\n",
      "Error in sklearn model evaluation: 'numpy.ndarray' object has no attribute 'is_floating_point'\n"
     ]
    },
    {
     "ename": "MissingFieldException",
     "evalue": "\n\u001b[95m\n----MissingFieldException-------------------------------------------------------\n\u001b[0m\nThe field \"pretrain/Z_embed_val\" was not found.\n\nThere are two possible reasons:\n    - There is a typo in the path. Double-check your code for typos.\n    - You are fetching a field that another process created, but the local representation is not synchronized.\n    If you are sending metadata from multiple processes at the same time, synchronize the local representation before fetching values:\n        \u001b[96mrun.sync()\u001b[0m\n\n\u001b[92mNeed help?\u001b[0m-> https://docs.neptune.ai/getting_help\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingFieldException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msetup_neptune_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43msetup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpretrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mwith_run_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRCC-29\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mz_embed_engine/ml/setup.py:262\u001b[0m, in \u001b[0;36msetup_neptune_run\u001b[0;34m(data_dir, setup_id, with_run_id, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m     Z_embed \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(Z_embed_savepath, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# download the Z_embed file from neptune\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m     \u001b[43mrun\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msetup_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/Z_embed_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43meval_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ_embed_savepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     Z_embed \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(Z_embed_savepath, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (plot_latent_space\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseaborn\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (plot_latent_space\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (plot_latent_space\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msns\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/mzlearn_3/lib/python3.9/site-packages/neptune/handler.py:88\u001b[0m, in \u001b[0;36mcheck_protected_paths.<locals>.inner_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fun)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHandler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m     validate_path_not_protected(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/mzlearn_3/lib/python3.9/site-packages/neptune/handler.py:638\u001b[0m, in \u001b[0;36mHandler.download\u001b[0;34m(self, destination, progress_bar)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;129m@check_protected_paths\u001b[39m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload\u001b[39m(\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    610\u001b[0m     destination: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    611\u001b[0m     progress_bar: Optional[ProgressBarType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    612\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    613\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Downloads the stored files to the working directory or to the specified destination.\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \n\u001b[1;32m    615\u001b[0m \u001b[38;5;124;03m    Available for the following field types:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03m       https://docs.neptune.ai/api-reference/field-types\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pass_call_to_attr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdownload\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/mzlearn_3/lib/python3.9/site-packages/neptune/handler.py:718\u001b[0m, in \u001b[0;36mHandler._pass_call_to_attr\u001b[0;34m(self, function_name, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pass_call_to_attr\u001b[39m(\u001b[38;5;28mself\u001b[39m, function_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 718\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_attribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, function_name)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/mzlearn_3/lib/python3.9/site-packages/neptune/handler.py:143\u001b[0m, in \u001b[0;36mHandler._get_attribute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingFieldException(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attr\n",
      "\u001b[0;31mMissingFieldException\u001b[0m: \n\u001b[95m\n----MissingFieldException-------------------------------------------------------\n\u001b[0m\nThe field \"pretrain/Z_embed_val\" was not found.\n\nThere are two possible reasons:\n    - There is a typo in the path. Double-check your code for typos.\n    - You are fetching a field that another process created, but the local representation is not synchronized.\n    If you are sending metadata from multiple processes at the same time, synchronize the local representation before fetching values:\n        \u001b[96mrun.sync()\u001b[0m\n\n\u001b[92mNeed help?\u001b[0m-> https://docs.neptune.ai/getting_help\n"
     ]
    }
   ],
   "source": [
    "setup_neptune_run(data_dir,setup_id='pretrain',with_run_id='RCC-29',**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/revivemed/RCC/e/RCC-29\n"
     ]
    }
   ],
   "source": [
    "NEPTUNE_API_TOKEN = 'eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxMGM5ZDhiMy1kOTlhLTRlMTAtOGFlYy1hOTQzMDE1YjZlNjcifQ=='\n",
    "\n",
    "run = neptune.init_run(project='revivemed/RCC',\n",
    "    api_token=NEPTUNE_API_TOKEN,\n",
    "    with_id='RCC-29')\n",
    "\n",
    "# run[\"sys/id\"].fetch()\n",
    "# run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adv_kind': 'MultiClassClassifier',\n",
       " 'adv_kwargs': {'activation': 'leakyrelu',\n",
       "  'dropout_rate': 0,\n",
       "  'hidden_size': 4,\n",
       "  'num_classes': 19,\n",
       "  'num_hidden_layers': 1,\n",
       "  'use_batch_norm': False},\n",
       " 'batch_size': 64,\n",
       " 'encoder_kind': 'AE',\n",
       " 'encoder_kwargs': {'activation': 'leakyrelu',\n",
       "  'dropout_rate': 0.2,\n",
       "  'hidden_size': 12,\n",
       "  'latent_size': 8,\n",
       "  'num_hidden_layers': 2,\n",
       "  'use_batch_norm': False},\n",
       " 'eval_kwargs': {'eval_funcs': {'adversary_auc': '<function evaluate_adversary_auc at 0x7fb26bbfe820>',\n",
       "   'head_auc': '<function evaluate_head_auc at 0x7fb26bbfe8b0>'},\n",
       "  'sklearn_models': {'Adversary Logistic Regression': 'LogisticRegression(max_iter=1000)'}},\n",
       " 'head_kind': 'BinaryClassifier',\n",
       " 'head_kwargs': {'activation': 'leakyrelu',\n",
       "  'dropout_rate': 0,\n",
       "  'hidden_size': 4,\n",
       "  'num_classes': 2,\n",
       "  'num_hidden_layers': 1,\n",
       "  'use_batch_norm': False},\n",
       " 'holdout_frac': 0.3,\n",
       " 'other_size': 1,\n",
       " 'train_kwargs': {'adversarial_mini_epochs': 2,\n",
       "  'adversary_weight': 1.5,\n",
       "  'early_stopping_patience': 3,\n",
       "  'encoder_weight': 1,\n",
       "  'eval_funcs': {'adversary_auc': '<function evaluate_adversary_auc at 0x7fb26bbfe820>',\n",
       "   'head_auc': '<function evaluate_head_auc at 0x7fb26bbfe8b0>'},\n",
       "  'head_weight': 0.5,\n",
       "  'l1_reg_weight': 0,\n",
       "  'l2_reg_weight': 0.001,\n",
       "  'lr': 0.01,\n",
       "  'noise_factor': 0.1,\n",
       "  'num_epochs': 10,\n",
       "  'weight_decay': 0}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run['pretrain/kwargs'].fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "InactiveRunException",
     "evalue": "\n\u001b[95m\n----InactiveRunException----------------------------------------\n\u001b[0m\nIt seems you are trying to log metadata to (or fetch it from) a run that was stopped (RCC-29).\n\nHere's what you can do:\n    - Resume the run to continue logging to it:\n    https://docs.neptune.ai/logging/to_existing_object/\n    - Don't invoke `stop()` on a run that you want to access. If you want to stop monitoring only,\n    you can resume a run in read-only mode:\n    https://docs.neptune.ai/api/connection_modes/#read-only-mode\n\nYou may also want to check the following docs pages:\n    - https://docs.neptune.ai/logging/to_existing_object/\n    - https://docs.neptune.ai/usage/querying_metadata/\n\n\u001b[92mNeed help?\u001b[0m-> https://docs.neptune.ai/getting_help\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInactiveRunException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmytest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m43\u001b[39m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/mzlearn_3/lib/python3.9/site-packages/neptune/metadata_containers/metadata_container.py:111\u001b[0m, in \u001b[0;36mensure_not_stopped.<locals>.inner_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fun)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetadataContainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_stopped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/mzlearn_3/lib/python3.9/site-packages/neptune/metadata_containers/run.py:549\u001b[0m, in \u001b[0;36mRun._raise_if_stopped\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_if_stopped\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m ContainerState\u001b[38;5;241m.\u001b[39mSTOPPED:\n\u001b[0;32m--> 549\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InactiveRunException(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sys_id)\n",
      "\u001b[0;31mInactiveRunException\u001b[0m: \n\u001b[95m\n----InactiveRunException----------------------------------------\n\u001b[0m\nIt seems you are trying to log metadata to (or fetch it from) a run that was stopped (RCC-29).\n\nHere's what you can do:\n    - Resume the run to continue logging to it:\n    https://docs.neptune.ai/logging/to_existing_object/\n    - Don't invoke `stop()` on a run that you want to access. If you want to stop monitoring only,\n    you can resume a run in read-only mode:\n    https://docs.neptune.ai/api/connection_modes/#read-only-mode\n\nYou may also want to check the following docs pages:\n    - https://docs.neptune.ai/logging/to_existing_object/\n    - https://docs.neptune.ai/usage/querying_metadata/\n\n\u001b[92mNeed help?\u001b[0m-> https://docs.neptune.ai/getting_help\n"
     ]
    }
   ],
   "source": [
    "run['mytest'] = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = run['pretrain/kwargs'].fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "run['pretrain/encoder_state_dict'].download('/Users/jonaheaton/output/temp/encoder_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('/Users/jonaheaton/output/temp/encoder_state_dict.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_kwargs = kwargs['encoder_kwargs']\n",
    "# input_size = kwargs['input_size']\n",
    "input_size=2736\n",
    "encoder_kind = kwargs['encoder_kind']\n",
    "encoder = get_model(encoder_kind, input_size, **encoder_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] All 0 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/revivemed/RCC/e/RCC-29/metadata\n"
     ]
    }
   ],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mzlearn_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
