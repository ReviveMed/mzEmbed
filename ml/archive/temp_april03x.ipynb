{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from train3 import CompoundDataset\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/DATA2'\n",
    "X_filename = 'X_pretrain'\n",
    "y_filename = 'y_pretrain'\n",
    "eval_name = 'val'\n",
    "\n",
    "X_data_eval = pd.read_csv(f'{data_dir}/{X_filename}_{eval_name}.csv', index_col=0)\n",
    "y_data_eval = pd.read_csv(f'{data_dir}/{y_filename}_{eval_name}.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def create_dataloaders2(torch_dataset, batch_size, holdout_frac=0, shuffle=True, set_name='train'):\n",
    "    \n",
    "    if holdout_frac == 0:\n",
    "        return {set_name: DataLoader(torch_dataset, batch_size=batch_size, shuffle=shuffle)}\n",
    "\n",
    "    train_size = int((1-holdout_frac) * len(torch_dataset))\n",
    "    holdout_size = len(torch_dataset) - train_size\n",
    "\n",
    "    train_dataset, holdout_dataset = torch.utils.data.random_split(torch_dataset, [train_size, holdout_size])\n",
    "\n",
    "    return {set_name: DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle),\n",
    "            f'{set_name}_holdout': DataLoader(holdout_dataset, batch_size=batch_size, shuffle=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(torch_dataset, batch_size, holdout_frac=0, shuffle=True, set_name='train', stratify=None):\n",
    "    if holdout_frac == 0:\n",
    "        return {set_name: DataLoader(torch_dataset, batch_size=batch_size, shuffle=shuffle)}\n",
    "\n",
    "    # Get the targets of your dataset if it's available\n",
    "    if stratify is not None:\n",
    "        targets = [item[stratify] for item in torch_dataset]\n",
    "    else:\n",
    "        targets = None\n",
    "\n",
    "    # Split the indices of your dataset\n",
    "    indices = list(range(len(torch_dataset)))\n",
    "    train_indices, holdout_indices = train_test_split(indices, test_size=holdout_frac, stratify=targets)\n",
    "\n",
    "    # Create samplers\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    holdout_sampler = SubsetRandomSampler(holdout_indices)\n",
    "\n",
    "    return {set_name: DataLoader(torch_dataset, batch_size=batch_size, sampler=train_sampler),\n",
    "            f'{set_name}_holdout': DataLoader(torch_dataset, batch_size=batch_size, sampler=holdout_sampler)}\n",
    "\n",
    "# but the legnth of the dataloader is not the same as the length of the dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_head_cols= ['is Pediatric','Cohort Label ENC', 'is Female']\n",
    "y_adv_cols= ['Study ID ENC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = CompoundDataset(X_data_eval,y_data_eval[y_head_cols], y_data_eval[y_adv_cols])\n",
    "dl_dict = create_dataloaders(eval_dataset, 32, holdout_frac=0.2, shuffle=True, set_name='eval',stratify=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2542"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl_dict['eval_holdout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl_dict['eval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl_dict['eval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 3., 1.],\n",
       "        [1., 2., nan],\n",
       "        [1., 2., nan],\n",
       "        ...,\n",
       "        [0., 0., nan],\n",
       "        [0., 0., nan],\n",
       "        [0., 0., nan]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset.y_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [item[1] for item in eval_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([nan])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[2][torch.isnan(targets[2])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [item[1] for item in eval_dataset]\n",
    "# convert nan to -1\n",
    "for item in targets:\n",
    "    item[torch.isnan(item)] = -1\n",
    "\n",
    "indices = list(range(len(eval_dataset)))\n",
    "train_indices, holdout_indices = train_test_split(indices, test_size=0.2, stratify=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1374,\n",
       " 1566,\n",
       " 1112,\n",
       " 1607,\n",
       " 1356,\n",
       " 1513,\n",
       " 1519,\n",
       " 1452,\n",
       " 124,\n",
       " 1308,\n",
       " 951,\n",
       " 1727,\n",
       " 1152,\n",
       " 985,\n",
       " 1721,\n",
       " 2490,\n",
       " 1196,\n",
       " 1133,\n",
       " 2111,\n",
       " 636,\n",
       " 387,\n",
       " 1399,\n",
       " 1550,\n",
       " 751,\n",
       " 476,\n",
       " 702,\n",
       " 717,\n",
       " 1437,\n",
       " 1808,\n",
       " 1774,\n",
       " 681,\n",
       " 2040,\n",
       " 571,\n",
       " 1782,\n",
       " 1035,\n",
       " 910,\n",
       " 242,\n",
       " 282,\n",
       " 1775,\n",
       " 37,\n",
       " 901,\n",
       " 2154,\n",
       " 1325,\n",
       " 1632,\n",
       " 469,\n",
       " 290,\n",
       " 716,\n",
       " 863,\n",
       " 390,\n",
       " 1364,\n",
       " 60,\n",
       " 374,\n",
       " 2311,\n",
       " 823,\n",
       " 2056,\n",
       " 497,\n",
       " 1989,\n",
       " 1565,\n",
       " 1871,\n",
       " 15,\n",
       " 1846,\n",
       " 661,\n",
       " 884,\n",
       " 2320,\n",
       " 1185,\n",
       " 147,\n",
       " 550,\n",
       " 1638,\n",
       " 2068,\n",
       " 822,\n",
       " 361,\n",
       " 81,\n",
       " 1854,\n",
       " 1878,\n",
       " 1177,\n",
       " 2324,\n",
       " 1537,\n",
       " 1761,\n",
       " 1397,\n",
       " 321,\n",
       " 1818,\n",
       " 87,\n",
       " 1743,\n",
       " 2528,\n",
       " 1612,\n",
       " 1422,\n",
       " 866,\n",
       " 555,\n",
       " 627,\n",
       " 1995,\n",
       " 1645,\n",
       " 32,\n",
       " 1772,\n",
       " 1683,\n",
       " 1903,\n",
       " 1367,\n",
       " 1553,\n",
       " 1318,\n",
       " 99,\n",
       " 1230,\n",
       " 871,\n",
       " 2119,\n",
       " 250,\n",
       " 1851,\n",
       " 2442,\n",
       " 1220,\n",
       " 1733,\n",
       " 451,\n",
       " 1460,\n",
       " 264,\n",
       " 1850,\n",
       " 2441,\n",
       " 1287,\n",
       " 875,\n",
       " 23,\n",
       " 2476,\n",
       " 1996,\n",
       " 1659,\n",
       " 2494,\n",
       " 770,\n",
       " 2139,\n",
       " 630,\n",
       " 607,\n",
       " 650,\n",
       " 1525,\n",
       " 1232,\n",
       " 1555,\n",
       " 262,\n",
       " 405,\n",
       " 63,\n",
       " 166,\n",
       " 2053,\n",
       " 966,\n",
       " 2058,\n",
       " 1505,\n",
       " 2071,\n",
       " 2318,\n",
       " 560,\n",
       " 1703,\n",
       " 1225,\n",
       " 697,\n",
       " 1915,\n",
       " 1677,\n",
       " 1732,\n",
       " 207,\n",
       " 1706,\n",
       " 1549,\n",
       " 2257,\n",
       " 1434,\n",
       " 1128,\n",
       " 2259,\n",
       " 513,\n",
       " 2086,\n",
       " 1637,\n",
       " 979,\n",
       " 2004,\n",
       " 1317,\n",
       " 254,\n",
       " 319,\n",
       " 1676,\n",
       " 2383,\n",
       " 998,\n",
       " 821,\n",
       " 1118,\n",
       " 2122,\n",
       " 474,\n",
       " 934,\n",
       " 1975,\n",
       " 1339,\n",
       " 1932,\n",
       " 2088,\n",
       " 2449,\n",
       " 566,\n",
       " 2447,\n",
       " 2078,\n",
       " 1435,\n",
       " 2439,\n",
       " 548,\n",
       " 2523,\n",
       " 2026,\n",
       " 695,\n",
       " 13,\n",
       " 590,\n",
       " 2170,\n",
       " 2537,\n",
       " 2475,\n",
       " 1615,\n",
       " 1874,\n",
       " 945,\n",
       " 72,\n",
       " 843,\n",
       " 1379,\n",
       " 171,\n",
       " 1784,\n",
       " 1990,\n",
       " 1295,\n",
       " 196,\n",
       " 1730,\n",
       " 600,\n",
       " 1489,\n",
       " 244,\n",
       " 2372,\n",
       " 1641,\n",
       " 128,\n",
       " 1123,\n",
       " 1106,\n",
       " 1587,\n",
       " 1600,\n",
       " 50,\n",
       " 1411,\n",
       " 2424,\n",
       " 1205,\n",
       " 308,\n",
       " 1567,\n",
       " 2278,\n",
       " 1499,\n",
       " 785,\n",
       " 1667,\n",
       " 1610,\n",
       " 241,\n",
       " 2518,\n",
       " 915,\n",
       " 431,\n",
       " 2255,\n",
       " 1470,\n",
       " 2367,\n",
       " 1830,\n",
       " 2217,\n",
       " 427,\n",
       " 874,\n",
       " 2015,\n",
       " 1478,\n",
       " 2150,\n",
       " 1526,\n",
       " 2479,\n",
       " 1083,\n",
       " 1825,\n",
       " 1556,\n",
       " 1959,\n",
       " 1992,\n",
       " 338,\n",
       " 2280,\n",
       " 1780,\n",
       " 2064,\n",
       " 1927,\n",
       " 1994,\n",
       " 1563,\n",
       " 1790,\n",
       " 54,\n",
       " 886,\n",
       " 1591,\n",
       " 963,\n",
       " 1644,\n",
       " 496,\n",
       " 2338,\n",
       " 1601,\n",
       " 429,\n",
       " 2499,\n",
       " 70,\n",
       " 799,\n",
       " 933,\n",
       " 76,\n",
       " 732,\n",
       " 1394,\n",
       " 2302,\n",
       " 131,\n",
       " 2360,\n",
       " 2188,\n",
       " 1323,\n",
       " 2462,\n",
       " 1528,\n",
       " 237,\n",
       " 1616,\n",
       " 1359,\n",
       " 252,\n",
       " 1113,\n",
       " 2336,\n",
       " 1278,\n",
       " 688,\n",
       " 978,\n",
       " 1773,\n",
       " 1384,\n",
       " 6,\n",
       " 989,\n",
       " 369,\n",
       " 465,\n",
       " 1604,\n",
       " 1059,\n",
       " 1870,\n",
       " 1414,\n",
       " 1779,\n",
       " 1003,\n",
       " 1066,\n",
       " 460,\n",
       " 663,\n",
       " 1737,\n",
       " 2183,\n",
       " 1269,\n",
       " 1443,\n",
       " 748,\n",
       " 557,\n",
       " 176,\n",
       " 1194,\n",
       " 1336,\n",
       " 1351,\n",
       " 674,\n",
       " 613,\n",
       " 1183,\n",
       " 1991,\n",
       " 2526,\n",
       " 660,\n",
       " 1508,\n",
       " 1240,\n",
       " 952,\n",
       " 1949,\n",
       " 1423,\n",
       " 400,\n",
       " 2516,\n",
       " 353,\n",
       " 942,\n",
       " 162,\n",
       " 1426,\n",
       " 2452,\n",
       " 1941,\n",
       " 2062,\n",
       " 1913,\n",
       " 725,\n",
       " 1013,\n",
       " 1668,\n",
       " 2159,\n",
       " 2175,\n",
       " 2312,\n",
       " 2024,\n",
       " 1430,\n",
       " 2468,\n",
       " 467,\n",
       " 426,\n",
       " 2279,\n",
       " 960,\n",
       " 812,\n",
       " 2465,\n",
       " 2030,\n",
       " 700,\n",
       " 1542,\n",
       " 499,\n",
       " 2235,\n",
       " 362,\n",
       " 1626,\n",
       " 1274,\n",
       " 1244,\n",
       " 2189,\n",
       " 10,\n",
       " 206,\n",
       " 301,\n",
       " 1283,\n",
       " 1926,\n",
       " 439,\n",
       " 346,\n",
       " 931,\n",
       " 1824,\n",
       " 1588,\n",
       " 794,\n",
       " 2298,\n",
       " 1672,\n",
       " 1368,\n",
       " 1056,\n",
       " 2265,\n",
       " 2146,\n",
       " 949,\n",
       " 49,\n",
       " 1965,\n",
       " 2510,\n",
       " 1065,\n",
       " 312,\n",
       " 652,\n",
       " 775,\n",
       " 679,\n",
       " 584,\n",
       " 964,\n",
       " 284,\n",
       " 711,\n",
       " 1259,\n",
       " 1457,\n",
       " 223,\n",
       " 1574,\n",
       " 86,\n",
       " 2527,\n",
       " 473,\n",
       " 696,\n",
       " 1055,\n",
       " 904,\n",
       " 101,\n",
       " 487,\n",
       " 178,\n",
       " 1143,\n",
       " 2271,\n",
       " 918,\n",
       " 129,\n",
       " 1868,\n",
       " 355,\n",
       " 2400,\n",
       " 1917,\n",
       " 351,\n",
       " 1547,\n",
       " 2385,\n",
       " 996,\n",
       " 1186,\n",
       " 797,\n",
       " 501,\n",
       " 1660,\n",
       " 629,\n",
       " 1968,\n",
       " 2057,\n",
       " 1570,\n",
       " 1006,\n",
       " 234,\n",
       " 2202,\n",
       " 2118,\n",
       " 1577,\n",
       " 1447,\n",
       " 2178,\n",
       " 1795,\n",
       " 46,\n",
       " 2018,\n",
       " 2422,\n",
       " 1369,\n",
       " 193,\n",
       " 1831,\n",
       " 2507,\n",
       " 845,\n",
       " 445,\n",
       " 2258,\n",
       " 2100,\n",
       " 1909,\n",
       " 1710,\n",
       " 1506,\n",
       " 1518,\n",
       " 2010,\n",
       " 2482,\n",
       " 1250,\n",
       " 1403,\n",
       " 1465,\n",
       " 412,\n",
       " 2087,\n",
       " 407,\n",
       " 2047,\n",
       " 1061,\n",
       " 2067,\n",
       " 536,\n",
       " 1876,\n",
       " 2063,\n",
       " 2282,\n",
       " 1257,\n",
       " 563,\n",
       " 2352,\n",
       " 452,\n",
       " 1479,\n",
       " 1590,\n",
       " 2136,\n",
       " 2009,\n",
       " 1290,\n",
       " 1920,\n",
       " 85,\n",
       " 1881,\n",
       " 917,\n",
       " 1515,\n",
       " 2238,\n",
       " 2036,\n",
       " 1618,\n",
       " 1071,\n",
       " 1327,\n",
       " 506,\n",
       " 2133,\n",
       " 559,\n",
       " 659,\n",
       " 1742,\n",
       " 396,\n",
       " 392,\n",
       " 2397,\n",
       " 1340,\n",
       " 693,\n",
       " 1619,\n",
       " 549,\n",
       " 91,\n",
       " 458,\n",
       " 818,\n",
       " 648,\n",
       " 443,\n",
       " 2191,\n",
       " 2521,\n",
       " 457,\n",
       " 45,\n",
       " 813,\n",
       " 1076,\n",
       " 2156,\n",
       " 1697,\n",
       " 1410,\n",
       " 1005,\n",
       " 793,\n",
       " 485,\n",
       " 606,\n",
       " 1857,\n",
       " 1139,\n",
       " 1698,\n",
       " 617,\n",
       " 1491,\n",
       " 363,\n",
       " 1967,\n",
       " 881,\n",
       " 583,\n",
       " 25,\n",
       " 644,\n",
       " 484,\n",
       " 1890,\n",
       " 172,\n",
       " 92,\n",
       " 1129,\n",
       " 1424,\n",
       " 519,\n",
       " 955,\n",
       " 1711,\n",
       " 1867,\n",
       " 2515,\n",
       " 265,\n",
       " 1906,\n",
       " 902,\n",
       " 2420,\n",
       " 2370,\n",
       " 1557,\n",
       " 1807,\n",
       " 1800,\n",
       " 2232,\n",
       " 1679,\n",
       " 575,\n",
       " 2145,\n",
       " 1735,\n",
       " 1724,\n",
       " 466,\n",
       " 1769,\n",
       " 246,\n",
       " 912,\n",
       " 382,\n",
       " 1681,\n",
       " 235,\n",
       " 1765,\n",
       " 2503,\n",
       " 411,\n",
       " 2127,\n",
       " 2414,\n",
       " 343,\n",
       " 47,\n",
       " 614,\n",
       " 576,\n",
       " 2028,\n",
       " 1058,\n",
       " 1759,\n",
       " 903,\n",
       " 1087,\n",
       " 1027,\n",
       " 1753,\n",
       " 1121,\n",
       " 2101,\n",
       " 1736,\n",
       " 208,\n",
       " 977,\n",
       " 1877,\n",
       " 1771,\n",
       " 801,\n",
       " 1001,\n",
       " 710,\n",
       " 2167,\n",
       " 1202,\n",
       " 1720,\n",
       " 773,\n",
       " 1017,\n",
       " 1184,\n",
       " 851,\n",
       " 2292,\n",
       " 249,\n",
       " 2241,\n",
       " 1639,\n",
       " 1675,\n",
       " 2301,\n",
       " 65,\n",
       " 907,\n",
       " 1865,\n",
       " 708,\n",
       " 2355,\n",
       " 152,\n",
       " 1386,\n",
       " 2293,\n",
       " 1215,\n",
       " 227,\n",
       " 526,\n",
       " 1141,\n",
       " 231,\n",
       " 352,\n",
       " 619,\n",
       " 1853,\n",
       " 1880,\n",
       " 69,\n",
       " 1120,\n",
       " 2152,\n",
       " 1187,\n",
       " 1412,\n",
       " 1665,\n",
       " 1037,\n",
       " 116,\n",
       " 1933,\n",
       " 1409,\n",
       " 1969,\n",
       " 286,\n",
       " 1108,\n",
       " 1164,\n",
       " 806,\n",
       " 1089,\n",
       " 2239,\n",
       " 768,\n",
       " 1725,\n",
       " 1544,\n",
       " 1951,\n",
       " 215,\n",
       " 2270,\n",
       " 302,\n",
       " 240,\n",
       " 2418,\n",
       " 1924,\n",
       " 1814,\n",
       " 1385,\n",
       " 1981,\n",
       " 105,\n",
       " 1018,\n",
       " 2093,\n",
       " 1344,\n",
       " 628,\n",
       " 337,\n",
       " 245,\n",
       " 1702,\n",
       " 2192,\n",
       " 188,\n",
       " 1694,\n",
       " 1559,\n",
       " 2340,\n",
       " 112,\n",
       " 538,\n",
       " 1273,\n",
       " 404,\n",
       " 233,\n",
       " 12,\n",
       " 357,\n",
       " 1090,\n",
       " 1256,\n",
       " 1768,\n",
       " 929,\n",
       " 2429,\n",
       " 1575,\n",
       " 197,\n",
       " 305,\n",
       " 213,\n",
       " 893,\n",
       " 991,\n",
       " 1249,\n",
       " 2284,\n",
       " 2493,\n",
       " 1796,\n",
       " 1605,\n",
       " 2394,\n",
       " 97,\n",
       " 1597,\n",
       " 1312,\n",
       " 2076,\n",
       " 142,\n",
       " 911,\n",
       " 1700,\n",
       " 1418,\n",
       " 1589,\n",
       " 1086,\n",
       " 2236,\n",
       " 581,\n",
       " 954,\n",
       " 2008,\n",
       " 1408,\n",
       " 1608,\n",
       " 694,\n",
       " 1002,\n",
       " 2473,\n",
       " 95,\n",
       " 792,\n",
       " 1036,\n",
       " 2300,\n",
       " 2485,\n",
       " 541,\n",
       " 1889,\n",
       " 1163,\n",
       " 861,\n",
       " 509,\n",
       " 100,\n",
       " 1535,\n",
       " 626,\n",
       " 678,\n",
       " 183,\n",
       " 1392,\n",
       " 1603,\n",
       " 1712,\n",
       " 1265,\n",
       " 111,\n",
       " 298,\n",
       " 953,\n",
       " 1358,\n",
       " 1057,\n",
       " 2240,\n",
       " 1534,\n",
       " 1102,\n",
       " 1835,\n",
       " 610,\n",
       " 2184,\n",
       " 2163,\n",
       " 1429,\n",
       " 1319,\n",
       " 2070,\n",
       " 2307,\n",
       " 657,\n",
       " 421,\n",
       " 1806,\n",
       " 1427,\n",
       " 1477,\n",
       " 1690,\n",
       " 2269,\n",
       " 1117,\n",
       " 651,\n",
       " 483,\n",
       " 2248,\n",
       " 2419,\n",
       " 148,\n",
       " 1613,\n",
       " 2501,\n",
       " 837,\n",
       " 5,\n",
       " 1161,\n",
       " 1144,\n",
       " 2398,\n",
       " 1674,\n",
       " 297,\n",
       " 428,\n",
       " 2266,\n",
       " 1485,\n",
       " 704,\n",
       " 350,\n",
       " 1882,\n",
       " 210,\n",
       " 2120,\n",
       " 1950,\n",
       " 1918,\n",
       " 1115,\n",
       " 719,\n",
       " 494,\n",
       " 1757,\n",
       " 807,\n",
       " 2396,\n",
       " 561,\n",
       " 64,\n",
       " 1530,\n",
       " 2261,\n",
       " 1279,\n",
       " 1777,\n",
       " 804,\n",
       " 1333,\n",
       " 358,\n",
       " 296,\n",
       " 1361,\n",
       " 1326,\n",
       " 2488,\n",
       " 814,\n",
       " 1962,\n",
       " 1149,\n",
       " 1809,\n",
       " 2288,\n",
       " 293,\n",
       " 1258,\n",
       " 1322,\n",
       " 1656,\n",
       " 654,\n",
       " 1792,\n",
       " 908,\n",
       " 1503,\n",
       " 18,\n",
       " 1680,\n",
       " 878,\n",
       " 909,\n",
       " 885,\n",
       " 14,\n",
       " 784,\n",
       " 668,\n",
       " 624,\n",
       " 743,\n",
       " 1931,\n",
       " 1337,\n",
       " 1946,\n",
       " 1821,\n",
       " 1828,\n",
       " 1125,\n",
       " 2021,\n",
       " 1448,\n",
       " 1395,\n",
       " 2137,\n",
       " 186,\n",
       " 2179,\n",
       " 2249,\n",
       " 1625,\n",
       " 2315,\n",
       " 706,\n",
       " 471,\n",
       " 2124,\n",
       " 1960,\n",
       " 1752,\n",
       " 1885,\n",
       " 802,\n",
       " 967,\n",
       " 1883,\n",
       " 2378,\n",
       " 2539,\n",
       " 2365,\n",
       " 300,\n",
       " 1105,\n",
       " 1911,\n",
       " 2141,\n",
       " 145,\n",
       " 1766,\n",
       " 2250,\n",
       " 1576,\n",
       " 1207,\n",
       " 2165,\n",
       " 816,\n",
       " 2459,\n",
       " 281,\n",
       " 56,\n",
       " 2403,\n",
       " 1624,\n",
       " 80,\n",
       " 540,\n",
       " 1888,\n",
       " 1377,\n",
       " 2286,\n",
       " 2393,\n",
       " 2536,\n",
       " 1300,\n",
       " 436,\n",
       " 974,\n",
       " 1580,\n",
       " 1276,\n",
       " 1869,\n",
       " 4,\n",
       " 2034,\n",
       " 2158,\n",
       " 375,\n",
       " 84,\n",
       " 1270,\n",
       " 2077,\n",
       " 22,\n",
       " 534,\n",
       " 1029,\n",
       " 891,\n",
       " 107,\n",
       " 1375,\n",
       " 36,\n",
       " 1085,\n",
       " 1212,\n",
       " 1907,\n",
       " 267,\n",
       " 2001,\n",
       " 243,\n",
       " 1178,\n",
       " 2457,\n",
       " 926,\n",
       " 854,\n",
       " 1302,\n",
       " 1165,\n",
       " 1217,\n",
       " 608,\n",
       " 1011,\n",
       " 1993,\n",
       " 1315,\n",
       " 236,\n",
       " 1648,\n",
       " 371,\n",
       " 468,\n",
       " 273,\n",
       " 26,\n",
       " 1335,\n",
       " 1585,\n",
       " 834,\n",
       " 882,\n",
       " 1007,\n",
       " 1272,\n",
       " 96,\n",
       " 1009,\n",
       " 1243,\n",
       " 360,\n",
       " 577,\n",
       " 2309,\n",
       " 1999,\n",
       " 831,\n",
       " 73,\n",
       " 1383,\n",
       " 318,\n",
       " 1813,\n",
       " 2151,\n",
       " 1237,\n",
       " 1751,\n",
       " 410,\n",
       " 1238,\n",
       " 1158,\n",
       " 2260,\n",
       " 330,\n",
       " 2411,\n",
       " 820,\n",
       " 216,\n",
       " 1451,\n",
       " 2506,\n",
       " 669,\n",
       " 2276,\n",
       " 682,\n",
       " 1201,\n",
       " 270,\n",
       " 568,\n",
       " 859,\n",
       " 1750,\n",
       " 1704,\n",
       " 329,\n",
       " 1892,\n",
       " 975,\n",
       " 2115,\n",
       " 2173,\n",
       " 1494,\n",
       " 2262,\n",
       " 378,\n",
       " 2451,\n",
       " 1849,\n",
       " 104,\n",
       " 1166,\n",
       " 1495,\n",
       " 1285,\n",
       " 1070,\n",
       " 1135,\n",
       " 838,\n",
       " 2149,\n",
       " 1077,\n",
       " 1852,\n",
       " 292,\n",
       " 7,\n",
       " 1492,\n",
       " 1622,\n",
       " 1670,\n",
       " 1582,\n",
       " 950,\n",
       " 574,\n",
       " 58,\n",
       " 969,\n",
       " 905,\n",
       " 1181,\n",
       " 174,\n",
       " 79,\n",
       " 1599,\n",
       " 531,\n",
       " 867,\n",
       " 1216,\n",
       " 1748,\n",
       " 1242,\n",
       " 156,\n",
       " 1788,\n",
       " 997,\n",
       " 906,\n",
       " 599,\n",
       " 1246,\n",
       " 1331,\n",
       " 2097,\n",
       " 1770,\n",
       " 1961,\n",
       " 2176,\n",
       " 1311,\n",
       " 530,\n",
       " 653,\n",
       " 1459,\n",
       " 2381,\n",
       " 2193,\n",
       " 271,\n",
       " 1096,\n",
       " 1296,\n",
       " 1723,\n",
       " 2128,\n",
       " 778,\n",
       " 578,\n",
       " 2520,\n",
       " 274,\n",
       " 181,\n",
       " 860,\n",
       " 1895,\n",
       " 1798,\n",
       " 1261,\n",
       " 1696,\n",
       " ...]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(eval_dataset[train_indices], batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval2_dataset = eval_dataset[train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train3.CompoundDataset"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(eval2_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [2033, 3] at entry 0 and [2033, 1] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dl:\n\u001b[1;32m      2\u001b[0m     X, y_head, y_adv, other \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [2033, 3] at entry 0 and [2033, 1] at entry 1"
     ]
    }
   ],
   "source": [
    "for data in dl:\n",
    "    X, y_head, y_adv, other = data\n",
    "    print(X.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0697,  0.0697,  0.0697,  ...,  0.8696,  0.0697,  0.0697],\n",
       "         [ 1.7929,  1.7929,  1.7929,  ...,  1.7929,  1.7929,  1.7929],\n",
       "         [-1.3188, -1.3188, -1.3188,  ...,  0.0595, -1.3188, -1.3188],\n",
       "         ...,\n",
       "         [-0.8660, -1.0555, -0.3842,  ..., -1.0555, -1.0555, -1.0555],\n",
       "         [-1.0225, -1.0225, -1.0225,  ..., -1.0225, -1.0225, -1.0225],\n",
       "         [-1.5796, -0.9991, -0.8102,  ..., -0.0470, -1.0233, -0.2595]]),\n",
       " tensor([[1., 2., nan],\n",
       "         [0., 1., nan],\n",
       "         [1., 3., 1.],\n",
       "         ...,\n",
       "         [1., 3., nan],\n",
       "         [0., 1., 0.],\n",
       "         [1., 2., nan]]),\n",
       " tensor([[ 2.],\n",
       "         [14.],\n",
       "         [18.],\n",
       "         ...,\n",
       "         [12.],\n",
       "         [10.],\n",
       "         [13.]]),\n",
       " tensor([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset[train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2033"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "targets = [item[2] for item in eval_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6.1827, 6.1827, 6.1827,  ..., 2.5858, 6.1827, 6.1827]),\n",
       " tensor([1., 3., 1.]),\n",
       " tensor([18.]),\n",
       " tensor([0.]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = CompoundDataset(X_data_eval,y_data_eval[y_head_cols], y_data_eval[y_adv_cols])\n",
    "\n",
    "train_loader_dct = create_dataloaders(train_dataset, batch_size, holdout_frac, set_name=train_name)\n",
    "eval_loader_dct = create_dataloaders(eval_dataset, batch_size, set_name = eval_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
