diff --git a/Dockerfile_matt b/Dockerfile_matt
new file mode 100644
index 0000000..98eb961
--- /dev/null
+++ b/Dockerfile_matt
@@ -0,0 +1,48 @@
+# Use an official Python runtime as a parent image
+FROM python:3.9-bookworm
+# FROM python:3.9-slim
+
+LABEL Description="ReviveMed Linux environment for matt training code"
+LABEL tags="matt_training_models"
+
+# Set the working directory in the container
+WORKDIR /app
+
+# the more secure method
+# ARG BITBUCKET_ACCESS_KEY
+
+# less secure
+# ENV BITBUCKET_ACCESS_KEY=your_access_key
+
+
+# Copy the current directory contents into the container at /app
+# COPY . /app
+# only copy the requirements_4.txt file
+COPY requirements.txt .
+
+RUN apt-get update
+
+# install git
+RUN apt-get install -y git
+# Install useful system packages
+RUN apt-get install -y screen htop
+RUN apt-get install -y build-essential
+RUN apt-get install -y pkg-config
+RUN apt-get install -y libmariadb-dev-compat
+RUN apt-get update && apt-get install -y vim
+RUN apt-get install -y r-base
+
+RUN pip install --upgrade pip
+RUN pip install mysqlclient
+RUN pip install torch
+
+
+# Install any needed packages specified in requirements.txt
+RUN pip install --no-cache-dir -r requirements.txt
+
+# Make port 8080 available to the world outside this container
+EXPOSE 8080
+EXPOSE 8888
+
+# Define environment variable
+ENV NAME World
\ No newline at end of file
diff --git a/metadata_matching/client-cert.pem b/metadata_matching/client-cert.pem
new file mode 100755
index 0000000..f385b8c
--- /dev/null
+++ b/metadata_matching/client-cert.pem
@@ -0,0 +1,21 @@
+-----BEGIN CERTIFICATE-----
+MIIDcDCCAligAwIBAgIEHle0XTANBgkqhkiG9w0BAQsFADCBhzEtMCsGA1UELhMk
+ZWVjZTk1OWMtY2YyNy00ZDRjLWE0ZGYtMmYyMGZjNzA5OTE5MTMwMQYDVQQDDCpH
+b29nbGUgQ2xvdWQgU1FMIENsaWVudCBDQSBtaW5fbXpsZWFybl9hcHAxFDASBgNV
+BAoTC0dvb2dsZSwgSW5jMQswCQYDVQQGEwJVUzAeFw0yMTA4MzAxOTMxMTBaFw0z
+MTA4MjgxOTMyMTBaMD0xGDAWBgNVBAMMD21pbl9temxlYXJuX2FwcDEUMBIGA1UE
+ChMLR29vZ2xlLCBJbmMxCzAJBgNVBAYTAlVTMIIBIjANBgkqhkiG9w0BAQEFAAOC
+AQ8AMIIBCgKCAQEAyCObS4qJWKd1kFEMW92eNvFuT5XA4xxeeCLaSzUin/MgZ4/K
+ES3P0hrdZMHGX+uNsV/f6TOWOpQkwKODBInWsvadZAt/ltiEFBxc428SVlj8MyuD
+bdNgRItlH2dIkLBp8+kK0q5L/gzdQ/upCRrZZmZ3IFK1wqushhFJctg4Ynf7tm5g
+8v0LLZf65tO5bSWJKKaUgKVDu7137sr21fmTbYNQe3iUSlgF7Us2D+87z6wOrgQG
+dmm1P3zWxmahpWCMCfU6UnjmQYRar65OuPh+J2buXXu4gAxg/ed2iETpGm8F1Ra7
+J3IPPRmKdC5Icr13ZmWCy/CphXrC1KYAJIkwGwIDAQABoy0wKzAJBgNVHRMEAjAA
+MB4GA1UdEQQXMBWBE216aGFuZ0ByZXZpdmVtZWQuaW8wDQYJKoZIhvcNAQELBQAD
+ggEBAG6k+H6KdGQOBl/SSFXrV/NSR7lox9T3Yf2ofpmkHjJI+zRTbDVoD8SHOUU0
+/1pqx/EwMtAu4FbFwmdQUY8hjtFyEXc1alaPd+MUBHUM52Wo1PYxCE4wEF7yhNb6
+tuK4bevyMq94mdaYZe4Q+dGsXYQDq9/Xz9DJYlFd07YvFsrtQTY99jEN5s+R2Xa6
+hVB74vxXKiMFlAelrvtb5nQwUR3vjHF5aoHYi0SVxHMZpR7l9ojko2An/+ufEwIB
+1d5oK4JC11iKSw+t6DbpsfoOweKaYVZm2qVv4QLOB4K5e82TPMnB2h78maI9hLBh
+bI8k15QrSgZtUWHG+609p9yw930=
+-----END CERTIFICATE-----
\ No newline at end of file
diff --git a/metadata_matching/client-key.pem b/metadata_matching/client-key.pem
new file mode 100755
index 0000000..27a337d
--- /dev/null
+++ b/metadata_matching/client-key.pem
@@ -0,0 +1,27 @@
+-----BEGIN RSA PRIVATE KEY-----
+MIIEowIBAAKCAQEAyCObS4qJWKd1kFEMW92eNvFuT5XA4xxeeCLaSzUin/MgZ4/K
+ES3P0hrdZMHGX+uNsV/f6TOWOpQkwKODBInWsvadZAt/ltiEFBxc428SVlj8MyuD
+bdNgRItlH2dIkLBp8+kK0q5L/gzdQ/upCRrZZmZ3IFK1wqushhFJctg4Ynf7tm5g
+8v0LLZf65tO5bSWJKKaUgKVDu7137sr21fmTbYNQe3iUSlgF7Us2D+87z6wOrgQG
+dmm1P3zWxmahpWCMCfU6UnjmQYRar65OuPh+J2buXXu4gAxg/ed2iETpGm8F1Ra7
+J3IPPRmKdC5Icr13ZmWCy/CphXrC1KYAJIkwGwIDAQABAoIBACL9pq8EX5LyZCmB
+IgoFqx2sBD9BzWFnmlSis0um1JDmbunsR8XNHqJ7M+3juw0WH8W9H2akMEW5lNth
+OwzWFIVhfI77O6lh3WWut8bDqo8SK7W+i9HtvMz/GgTth9BUJ5IPUmcXNg4Krbyv
+CRSgbxXqIDW0gDay0Qz3hMHhb6o3REAWETCaBu+fB8dVxA1dlmzS0ys5iZghgse9
+1sEmnUK5yq921NUPAp2rHqJbE3k1fRbVcbNqF4HubMucSuuS/XVna4CLHHCqOGUl
+MSLC+/LbnDPG+UBjDwd/5hXoEZSLnhe2hTvFA8Z2mB+TFoBc05zni3C3qYlMMUlU
+aHs5FRECgYEA/0W2yobhixCCKbkKnrCuMqnjZKrMRnpnxgJYT3poKj5+1+01Yomt
+nBPLin4h4sW7KDRR+izGGzHGxGaYH49zGrd7Yos7hQXy3vVw4cpzrgyom9ypEsVN
+LpvexrLixefe8GEoy3WQTnAG1vUNDly6b/tWP3uifnP6YeZbH5oRhy0CgYEAyLWo
+rdJ/hAJR16Zmf5wIbz3Oq8pNmUH69tgxFwDTttDuohWrK2jocYUvJCQm2wVclZaj
+sTNYjh9GHqlsUs/dEJ17edny9RmjPoX3wWMk0FTX/g/3lC699WuTZe3Sk4WPiIgR
+kuC0w/xAiOh4RX4v+4m7eJKA+CaZTL5xFkKrIWcCgYAZ2giJ+CDtQW29JfUyXvg1
+P0k9D6MCXDEYN3KUEfRsmsmjum0WnpTLYqHRU7bAzX+Hscy/hjtF08Oqbi1nvNJO
+WViQgUM01IZlF/wnkaYncTa+GhmxQfPwDW8BNmqK2lGUjHJiMHS9zNCUglqhIrjq
+0ExKv42UOtCXi4mc6LBvvQKBgQCzzsqGroW+ZbWcVF6PA+IqhlyYWmyaWBnU+mlA
+CmWg6hxe6Lqn8RwMVxycbCbDIFKJUKLlJPK4oBvZbD63EbEiKXNs/mxCV+1/HdWP
+UpqwaNH3saZDAnz7WJx8PEriDk1AK2ZTByvqSBoojNryptGlrwZcRiN0LGA5+IKn
+RqK5EQKBgFPEQUnisSh7J7CEsEA07TcBJl9X9ku5UrNOXn2z7ffQ/85Uv8zAs0rG
+SNDz3PQHlLXu3nCFB9jKjJho0QiUohgn6cYm74x1NOYJHiZ7aTQIhtJ4kpWaRzz5
+M+PJAF1lir1yJeXemj9VJXNeVbYxO+y7Vq4X2xagOB5ebbUfAZhC
+-----END RSA PRIVATE KEY-----
\ No newline at end of file
diff --git a/metadata_matching/metadata_matching.py b/metadata_matching/metadata_matching.py
new file mode 100644
index 0000000..5f23fc8
--- /dev/null
+++ b/metadata_matching/metadata_matching.py
@@ -0,0 +1,201 @@
+import os
+import pandas as pd
+import sys
+import json
+import numpy as np
+import matplotlib.pyplot as plt
+from datetime import datetime
+import shutil
+import pickle
+import mysql.connector
+from mysql.connector.constants import ClientFlag
+from google.cloud import storage
+import gcsfs
+
+########################################################################################################################
+# data base and GCP bucket connection
+########################################################################################################################
+config = {
+    'user': 'mz',
+    'password': 'zm6148mz',
+    'host': '34.134.200.45',
+    'client_flags': [ClientFlag.SSL],
+    'ssl_ca': 'server-ca.pem',
+    'ssl_cert': 'client-cert.pem',
+    'ssl_key': 'client-key.pem',
+    'database': 'mzlearn_webapp_DB'
+}
+cnxn = mysql.connector.connect(**config)
+cursor = cnxn.cursor()
+# bucket connection
+client = storage.Client()
+fs = gcsfs.GCSFileSystem()
+
+########################################################################################################################
+# read the file_info from selected projects
+# match the file name to gathered meta-data
+########################################################################################################################
+gather_meta_data = False
+if gather_meta_data:
+    # priority projects
+    projects = ['ST000909', 'ST001918', 'ST001428', 'ST002331', 'ST001931', 'ST001932', 'ST001849', 'ST001422', 'ST002027',
+                'ST000422', 'ST002244', 'ST002251', 'ST001423', 'ST002112', 'ST001408', 'ST000388', 'ST001519']
+
+    mzlearn_run_ids = [605, 606, 581, 522, 539, 507, 526, 555, 557, 550, 558, 502, 504, 579, 584, 585, 586, 587, 588, 505, 509,
+                       503, 559, 556]
+    # print(f"unique mzlearn_run_id: {len(set(mzlearn_run_ids))}")
+
+    # get the file_info from the selected projects
+    # have to do it one by one from 0 to 23
+    mzlearn_run_ids = [mzlearn_run_ids[22]]
+    for mzlearn_run in mzlearn_run_ids:
+        print(f"mzlearn_run: {mzlearn_run}")
+        # based on the mzlearn_run_id get job detail from the database
+        cursor.execute(f"SELECT * FROM app_user_job_status WHERE id = {mzlearn_run}")
+        job_detail = cursor.fetchall()
+        job_detail = job_detail[0]
+        # print(job_detail)
+        user_id = job_detail[1]
+        creation_time = job_detail[3]
+        public_dataset_code = job_detail[5]
+        if mzlearn_run == 581:
+            public_dataset_code = 'ST000388'
+        # print(user_id, creation_time)
+        # convert the creation time to string
+        creation_time = creation_time.strftime("%Y-%m-%d %H:%M:%S")
+        mzlearn_path = f"mzlearn/{user_id}/{creation_time}"
+        print(f"mzlearn_path: {mzlearn_path}; public_dataset_code: {public_dataset_code}")
+
+        # read the sample_info.csv that every mzlearn run has
+        # mzlearn-webapp.appspot.com/mzlearn/min/2024-02-22 23:52:04/sample_info/sample_info.csv
+        sample_info_path = f"mzlearn-webapp.appspot.com/{mzlearn_path}/sample_info/sample_info.csv"
+        with fs.open(sample_info_path) as f:
+            sample_info = pd.read_csv(f)
+        print(sample_info)
+
+        # read the gathered meta-data based on the public_dataset_code
+        # mzlearn-webapp.appspot.com/Data-engine/ST001519/meta_and_target/auto_built_meta/all_metadata.csv
+        meta_data_path = f"mzlearn-webapp.appspot.com/Data-engine/{public_dataset_code}/meta_and_target/auto_built_meta/all_metadata.csv"
+        with fs.open(meta_data_path) as f:
+            meta_data = pd.read_csv(f)
+        # sort meta_data by Subject ID
+        # meta_data = meta_data.sort_values(by=['Raw_files'])
+        print(meta_data)
+
+        # print(dfsadfsad)
+
+        # loop through the sample_info df and try to find the matching rows from meta_data
+        # by checking if the file_name from sample_info is in the meta_data Raw_files column
+        for index, row in sample_info.iterrows():
+            file_name = row['file_name']
+            # if there is "/" in the file_name, then only take the last part
+            if "/" in file_name:
+                file_name = file_name.split("/")[-1]
+            # if there is "." in the file_name, then only take the first part
+            if "." in file_name:
+                file_name = file_name.split(".")[0]
+
+            # file name only take the first 3 part separated by "_"
+            # file_name = "_".join(file_name.split("_")[:3])
+
+            # extract the last part of the file_name separated by "_"
+            file_name_first_half = "_".join(file_name.split("_")[:-1])
+            file_name_last_half = file_name.split("_")[-1]
+
+            # the file_name_last_half is in the format 001, 002, 003, to 269 tec
+            # add 1 to the file_name_last_half file_name, such that 001 become 002, 260 become 261
+            file_name_last_half = f"{int(file_name_last_half) + 1:03d}"
+            file_name = f"{file_name_first_half}_{file_name_last_half}"
+
+            # # extract subject_id from the file_name
+            # subject_id = f'{file_name.split("_")[2]}'
+            # # print(subject_id)
+            # subject_id = f'{subject_id.split("-")[0]}-{subject_id.split("-")[1]}'
+            # print(f"file_name: {file_name}; subject_id: {subject_id}")
+
+            # find the matching row from meta_data by matching the subject_id to meta-data Subject ID column
+            # there may be multiple matching rows, select the first one
+            column_to_use_for_matching = 'Raw_files'
+            # matching_row = meta_data[meta_data[column_to_use_for_matching] == file_name]
+            matching_row = meta_data[meta_data[column_to_use_for_matching].str.contains(file_name)]
+            # check if the matching_row is empty or not
+            age = 'NA'
+            age_at_symptom_onset = 'NA'
+            gender = 'NA'
+            treatment = 'NA'
+            if matching_row.empty:
+                print(f"file_name: {file_name} not found in meta_data")
+            else:
+                print(f"file_name: {file_name} found in {matching_row['Raw_files']}")
+                # select the first matching row
+                matching_row = matching_row.iloc[0]
+                print(matching_row)
+                try:
+                    age = matching_row['Age']
+                except Exception as e:
+                    print(f"error: {e}")
+
+                try:
+                    age_at_symptom_onset = matching_row['Age at Symptom onset (years)']
+                except Exception as e:
+                    print(f"error: {e}")
+
+                try:
+                    gender = matching_row['Factors.Sex']
+                except Exception as e:
+                    print(f"error: {e}")
+
+            # add the meta-data to the sample_info df
+            sample_info.loc[index, 'age'] = age
+            sample_info.loc[index, 'age_at_symptom_onset'] = age_at_symptom_onset
+            sample_info.loc[index, 'gender'] = gender
+
+        # save the sample_info df with the added meta-data to the GCP bucket
+        # save the sample_info df to the GCP bucket
+        sample_info_path = f"mzlearn-webapp.appspot.com/{mzlearn_path}/sample_info/sample_info_with_meta_data.csv"
+        with fs.open(sample_info_path, 'w') as f:
+            sample_info.to_csv(f, index=False)
+        print(f"sample_info with meta-data saved to: {sample_info_path}")
+
+
+########################################################################################################################
+# combine gathered into one file
+########################################################################################################################
+# the files are saved in {script_path}/mzlearn_pretraining_metadata
+# read each file as panda df and seelct only file_name, age, gender, and combine into one
+combine_into_one = True
+if combine_into_one:
+    gathered_files_path = f"{os.path.dirname(os.path.realpath(__file__))}/mzlearn_pretraining_metadata"
+    # print(gathered_files_path)
+    combined_aga_gender_df = pd.DataFrame()
+    for file in os.listdir(gathered_files_path):
+        if file.endswith(".csv"):
+            file_path = f"{gathered_files_path}/{file}"
+            # print(file_path)
+            with open(file_path) as f:
+                df = pd.read_csv(f)
+            # print(df)
+            # make the column names of the df all into lower case
+            df.columns = map(str.lower, df.columns)
+            # if age not in the columns, then add it as NA
+            if 'age' not in df.columns:
+                df['age'] = 'NA'
+            if 'gender' not in df.columns:
+                df['gender'] = 'NA'
+
+            # select only file_name, age, gender
+            df = df[['file_name', 'age', 'gender']]
+
+            # combine the df
+            combined_aga_gender_df = pd.concat([combined_aga_gender_df, df], ignore_index=True)
+
+    # save the combined df to the local as csv file
+    # fill Nan from combined_aga_gender_df as 'NA'
+    combined_aga_gender_df = combined_aga_gender_df.fillna('NA')
+    # change "-" to "NA" in age column and gender column
+    combined_aga_gender_df = combined_aga_gender_df.replace('-', 'NA')
+    # if there is "/" in collumn file_name, split it and take the last part
+    combined_aga_gender_df['file_name'] = combined_aga_gender_df['file_name'].apply(lambda x: x.split("/")[-1])
+    # save the combined df to the GCP bucket
+    combined_aga_gender_df.to_csv('combined_aga_gender.csv', index=False)
+
diff --git a/metadata_matching/server-ca.pem b/metadata_matching/server-ca.pem
new file mode 100755
index 0000000..a4eaa1c
--- /dev/null
+++ b/metadata_matching/server-ca.pem
@@ -0,0 +1,21 @@
+-----BEGIN CERTIFICATE-----
+MIIDfzCCAmegAwIBAgIBADANBgkqhkiG9w0BAQsFADB3MS0wKwYDVQQuEyQxMDY3
+ZmY5Ny0yZjliLTQyMTgtOWE0OC1lYWM0ZTExNDc0MDgxIzAhBgNVBAMTGkdvb2ds
+ZSBDbG91ZCBTUUwgU2VydmVyIENBMRQwEgYDVQQKEwtHb29nbGUsIEluYzELMAkG
+A1UEBhMCVVMwHhcNMjEwODMwMTU1MzM1WhcNMzEwODI4MTU1NDM1WjB3MS0wKwYD
+VQQuEyQxMDY3ZmY5Ny0yZjliLTQyMTgtOWE0OC1lYWM0ZTExNDc0MDgxIzAhBgNV
+BAMTGkdvb2dsZSBDbG91ZCBTUUwgU2VydmVyIENBMRQwEgYDVQQKEwtHb29nbGUs
+IEluYzELMAkGA1UEBhMCVVMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIB
+AQC0F/0LJhFLBALejxoMndAFCSOzjpJLDMe1jl95AyEbRvjMwgiAn5e++NwWd84j
+090GvH/jYDg1awzprtPQL+qkXKZAx1gXtO1aEgOOZ7BI3D+VItA9DU9zhgXrGuH3
+OYIcG2bMiOaHk2nBiu5hUJazPXqojmufxkfCRby9s+gQfXSKL/D2M4A2ZHoQidHv
+jv4u7J6g2EoJ0o9gRZaw2ioIAwsBOm9G2nO9KdnS+rPFI6jpWpK82c7CaNryoC73
+53ZxYwZltLQXOEssZezf9htE5fD/JG0Myxpqmg3/p5YYrbDiUDmf4Um8m606zDFa
+4zFDrVPYIQHtfzWU+DRv9jUzAgMBAAGjFjAUMBIGA1UdEwEB/wQIMAYBAf8CAQAw
+DQYJKoZIhvcNAQELBQADggEBAD9fkr4nId8QOBibgQTbX1EJmDZgOCEgBXmoRxcF
+CXNXjg7CJKbcJzUpcqfwQkvCP4QX4npb53F/inC+DaFN36RHC1FlDzvDMe/Bnd0o
+OuWQ1GlsMdf57v0ZgjwHzLzQnZRheUFR+/JNuxoF7FmrzgYwyRBwKuUyWclC0o+J
+hBACwhUuMBN83Zllr5ejdYdzY7v4lF9UABGwEIWRgKuA+koHrPVBjt7mu0w1KOQo
+o5ahRzZg60E7HD43fHuWAGdv0pN54uAz7PXnLwtuRIiR4A6v8xO8lTjVjWWV94lm
+RftoT39XJ/0p+dbTuawGog4bYK05KJuusMwTtHf/hGJO9rI=
+-----END CERTIFICATE-----
\ No newline at end of file
diff --git a/ml/.neptune/async/run__9ceeab57-075e-49e4-83fd-9651b5360655__485412__f1cbfno6/last_ack_version b/ml/.neptune/async/run__9ceeab57-075e-49e4-83fd-9651b5360655__485412__f1cbfno6/last_ack_version
deleted file mode 100644
index 72a5d6d..0000000
--- a/ml/.neptune/async/run__9ceeab57-075e-49e4-83fd-9651b5360655__485412__f1cbfno6/last_ack_version
+++ /dev/null
@@ -1 +0,0 @@
-12388
\ No newline at end of file
diff --git a/ml/.neptune/async/run__9ceeab57-075e-49e4-83fd-9651b5360655__485412__f1cbfno6/last_put_version b/ml/.neptune/async/run__9ceeab57-075e-49e4-83fd-9651b5360655__485412__f1cbfno6/last_put_version
deleted file mode 100644
index 72a5d6d..0000000
--- a/ml/.neptune/async/run__9ceeab57-075e-49e4-83fd-9651b5360655__485412__f1cbfno6/last_put_version
+++ /dev/null
@@ -1 +0,0 @@
-12388
\ No newline at end of file
diff --git a/ml/.neptune/async/run__9ceeab57-075e-49e4-83fd-9651b5360655__485412__f1cbfno6/metadata.json b/ml/.neptune/async/run__9ceeab57-075e-49e4-83fd-9651b5360655__485412__f1cbfno6/metadata.json
deleted file mode 100644
index fda0c93..0000000
--- a/ml/.neptune/async/run__9ceeab57-075e-49e4-83fd-9651b5360655__485412__f1cbfno6/metadata.json
+++ /dev/null
@@ -1,10 +0,0 @@
-{
-  "mode": "async",
-  "containerId": "9ceeab57-075e-49e4-83fd-9651b5360655",
-  "containerType": "run",
-  "structureVersion": 3,
-  "os": "Linux-5.10.0-32-cloud-amd64-x86_64-with-glibc2.31",
-  "pythonVersion": "3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]",
-  "neptuneClientVersion": "1.10.4",
-  "createdAt": "2024-09-04T22:28:27.642255+00:00"
-}
\ No newline at end of file
diff --git a/ml/LP_notebooks/pretrain_latnet_task_predict.ipynb b/ml/LP_notebooks/pretrain_latnet_task_predict.ipynb
index 35f7a82..6f9befb 100644
--- a/ml/LP_notebooks/pretrain_latnet_task_predict.ipynb
+++ b/ml/LP_notebooks/pretrain_latnet_task_predict.ipynb
@@ -55,6 +55,350 @@
     "\n"
    ]
   },
+  {
+   "cell_type": "code",
+   "execution_count": 8,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "/home/leilapirhaji/mz_embed_engine/ml/get_pretrain_encoder.py:60: DtypeWarning: Columns (1,8,28,30,31,32,33,34,46,50,51,52,53,54,55,56,57,58) have mixed types. Specify dtype option on import or set low_memory=False.\n",
+      "  y_data_all = pd.read_csv(pretrain_y_all, index_col=0)\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/revivemed/RCC/e/RCC-36657\n",
+      "Deleted existing file at /home/leilapirhaji/pretrained_models/pretrained_models/RCC-36657/encoder_state_dict.pth\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "ed9172eb82c541988bd8d0f17cb45690",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "Fetching file...: 0 [00:00, ?/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
+      "[neptune] [info   ] Done!\n",
+      "[neptune] [info   ] All 0 operations synced, thanks for waiting!\n",
+      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/revivemed/RCC/e/RCC-36657/metadata\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "/home/leilapirhaji/mz_embed_engine/ml/get_pretrain_encoder.py:173: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
+      "  encoder_state_dict = torch.load(model_encoder_file)\n"
+     ]
+    }
+   ],
+   "source": [
+    "import get_pretrain_encoder\n",
+    "importlib.reload(get_pretrain_encoder)\n",
+    "from get_pretrain_encoder import get_pretrain_encoder_from_modelID\n",
+    "# getting the latent space for the model\n",
+    "(encoder, Z_all, Z_train, Z_val, Z_test, y_data_all, y_data_train, y_data_val, y_data_test)=get_pretrain_encoder_from_modelID(model_id, input_data_location, pretrain_save_dir, ml_code_path)\n",
+    "\n"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 9,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "(20548, 200) (14391, 200) (3074, 200) (3083, 200) (20548, 58) (14391, 58) (3074, 58) (3083, 58)\n"
+     ]
+    }
+   ],
+   "source": [
+    "print (Z_all.shape, Z_train.shape, Z_val.shape, Z_test.shape, y_data_all.shape, y_data_train.shape, y_data_val.shape, y_data_test.shape)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 10,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "model_id is RCC-36657\n",
+      "Study ID Val Accuracy: 0.9525\n",
+      "Study ID Test Accuracy: 0.9458\n",
+      "is Female Val Accuracy: 0.8043\n",
+      "is Female Test Accuracy: 0.7567\n",
+      "is Pediatric Val Accuracy: 0.9808\n",
+      "is Pediatric Test Accuracy: 0.9818\n",
+      "Cohort Label v0 Val Accuracy: 0.9619\n",
+      "Cohort Label v0 Test Accuracy: 0.9578\n",
+      "Smoking Status Val Accuracy: 0.9311\n",
+      "Smoking Status Test Accuracy: 0.9314\n",
+      "Cancer Risk Val Accuracy: 0.9233\n",
+      "Cancer Risk Test Accuracy: 0.9190\n",
+      "BMI Val MAE : 3.9232\n",
+      "BMI Test MAE : 3.9238\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "/home/leilapirhaji/.local/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.93296e-08): result may not be accurate.\n",
+      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
+      "/home/leilapirhaji/.local/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.43836e-08): result may not be accurate.\n",
+      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Age Val MAE : 9.9546\n",
+      "Age Test MAE : 9.7178\n"
+     ]
+    }
+   ],
+   "source": [
+    "#def evalute_pretrain_latent_extra_task(model_id, input_data_location, pretrain_save_dir, task_list_cat, task_list_num):\n",
+    "input_data_location='/home/leilapirhaji/PROCESSED_DATA_2'\n",
+    "pretrain_save_dir='/home/leilapirhaji/pretrained_models' \n",
+    "\n",
+    "\n",
+    "\n",
+    "#tasks to predict using encoder\n",
+    "task_list_cat=[ 'Study ID', 'is Female', 'is Pediatric', 'Cohort Label v0','Smoking Status', 'Cancer Risk' ]\n",
+    "\n",
+    "task_list_num=[ 'BMI', 'Age' ]\n",
+    "\n",
+    "model_id='RCC-36657'\n",
+    "\n",
+    "print (f'model_id is {model_id}')\n",
+    "\n",
+    "\n",
+    "# getting the latent space for the model\n",
+    "#(encoder, Z_all, Z_train, Z_val, Z_test, y_data_all, y_data_train, y_data_val, y_data_test)=get_pretrain_encoder_from_modelID(model_id, input_data_location, pretrain_save_dir, ml_code_path)\n",
+    "\n",
+    "\n",
+    "\n",
+    "\n",
+    "# Now use the latnet space to predict the tasks\n",
+    "\n",
+    "model_results = {'Model ID': model_id}\n",
+    "\n",
+    "# Predict the categorical tasks\n",
+    "\n",
+    "for task in task_list_cat:\n",
+    "\n",
+    "    (val_accuracy, test_accuracy) = log_reg_multi_class(task, Z_train, y_data_train, Z_val, y_data_val, Z_test, y_data_test)\n",
+    "\n",
+    "    # Store the results in the dictionary\n",
+    "    model_results[f'{task} Val Accuracy'] = val_accuracy\n",
+    "    model_results[f'{task} Test Accuracy'] = test_accuracy\n",
+    "\n",
+    "    print(f'{task} Val Accuracy: {val_accuracy:.4f}')\n",
+    "    print(f'{task} Test Accuracy: {test_accuracy:.4f}')\n",
+    "\n",
+    "\n",
+    "#now evaluting numercal task predictions\n",
+    "for task in task_list_num:\n",
+    "\n",
+    "    (val_mse, val_mae, val_r2, test_mse, test_mae, test_r2)= ridge_regression_predict(task, Z_train, y_data_train, Z_val, y_data_val, Z_test, y_data_test)\n",
+    "\n",
+    "    # Store the results in the dictionary\n",
+    "    # model_results[f'{task} Val MSE'] = val_mse\n",
+    "    model_results[f'{task} Val MAE'] = val_mae\n",
+    "    # model_results[f'{task} Val R2'] = val_r2\n",
+    "    # model_results[f'{task} Test MSE'] = test_mse\n",
+    "    model_results[f'{task} Test MAE'] = test_mae\n",
+    "    # model_results[f'{task} Test R2'] = test_r2\n",
+    "\n",
+    "    print(f'{task} Val MAE : {val_mae:.4f}')\n",
+    "    print(f'{task} Test MAE : {test_mae:.4f}')\n",
+    "    \n",
+    "\n",
+    "\n",
+    "#return model_results\n"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 11,
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "{'Model ID': 'RCC-36657',\n",
+       " 'Study ID Val Accuracy': 0.9525048796356539,\n",
+       " 'Study ID Test Accuracy': 0.9458319818358741,\n",
+       " 'is Female Val Accuracy': 0.8043478260869565,\n",
+       " 'is Female Test Accuracy': 0.7566666666666667,\n",
+       " 'is Pediatric Val Accuracy': 0.9808067664281067,\n",
+       " 'is Pediatric Test Accuracy': 0.9818358741485566,\n",
+       " 'Cohort Label v0 Val Accuracy': 0.9619388418998048,\n",
+       " 'Cohort Label v0 Test Accuracy': 0.957833279273435,\n",
+       " 'Smoking Status Val Accuracy': 0.9311475409836065,\n",
+       " 'Smoking Status Test Accuracy': 0.9313725490196079,\n",
+       " 'Cancer Risk Val Accuracy': 0.9233067729083665,\n",
+       " 'Cancer Risk Test Accuracy': 0.9190444591904446,\n",
+       " 'BMI Val MAE': 3.9232283557165877,\n",
+       " 'BMI Test MAE': 3.923811241793968,\n",
+       " 'Age Val MAE': 9.95463990170786,\n",
+       " 'Age Test MAE': 9.717826384024695}"
+      ]
+     },
+     "execution_count": 11,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "model_results"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 2,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "[neptune] [warning] NeptuneDeprecationWarning: You're importing the Neptune client library via the deprecated `neptune.new` module, which will be removed in a future release. Import directly from `neptune` instead.\n"
+     ]
+    }
+   ],
+   "source": [
+    "import os\n",
+    "ml_code_path='/home/leilapirhaji/mz_embed_engine/ml'\n",
+    "os.chdir(ml_code_path)\n",
+    "\n",
+    "import pandas as pd\n",
+    "import importlib\n",
+    "from sklearn.preprocessing import LabelEncoder\n",
+    "label_encoder = LabelEncoder()\n",
+    "\n",
+    "\n",
+    "from get_pretrain_encoder import get_pretrain_encoder_from_modelID\n",
+    "from latent_task_predict_pretrain import log_reg_multi_class, ridge_regression_predict\n",
+    "\n",
+    "\n"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 3,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "model_id is RCC-36657\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "/home/leilapirhaji/mz_embed_engine/ml/get_pretrain_encoder.py:60: DtypeWarning: Columns (1,8,28,30,31,32,33,34,46,50,51,52,53,54,55,56,57,58) have mixed types. Specify dtype option on import or set low_memory=False.\n",
+      "  y_data_all = pd.read_csv(pretrain_y_all, index_col=0)\n",
+      "[neptune] [warning] NeptuneWarning: By default, these monitoring options are disabled in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', 'capture_hardware_metrics'. You can set them to 'True' when initializing the run and the monitoring will continue until you call run.stop() or the kernel stops. NOTE: To track the source files, pass their paths to the 'source_code' argument. For help, see: https://docs.neptune.ai/logging/source_code/\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/revivemed/RCC/e/RCC-36657\n",
+      "Deleted existing file at /home/leilapirhaji/pretrained_models/pretrained_models/RCC-36657/encoder_state_dict.pth\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "bba22a58c3ee4585b369466b79a0e358",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "Fetching file...: 0 [00:00, ?/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
+      "[neptune] [info   ] Done!\n",
+      "[neptune] [info   ] All 0 operations synced, thanks for waiting!\n",
+      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/revivemed/RCC/e/RCC-36657/metadata\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "/home/leilapirhaji/mz_embed_engine/ml/get_pretrain_encoder.py:173: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
+      "  encoder_state_dict = torch.load(model_encoder_file)\n"
+     ]
+    },
+    {
+     "ename": "TypeError",
+     "evalue": "expected Tensor as element 0 in argument 0, but got DataFrame",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
+      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m task_list_num\u001b[39m=\u001b[39m[ \u001b[39m'\u001b[39m\u001b[39mBMI\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAge\u001b[39m\u001b[39m'\u001b[39m ]\n\u001b[1;32m     11\u001b[0m model_id\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRCC-36657\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 13\u001b[0m model_results\u001b[39m=\u001b[39mevalute_pretrain_latent_extra_task(model_id, input_data_location, pretrain_save_dir, task_list_cat, task_list_num)\n",
+      "Cell \u001b[0;32mIn[1], line 7\u001b[0m, in \u001b[0;36mevalute_pretrain_latent_extra_task\u001b[0;34m(model_id, input_data_location, pretrain_save_dir, task_list_cat, task_list_num)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel_id is \u001b[39m\u001b[39m{\u001b[39;00mmodel_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39m# getting the latent space for the model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m (encoder, Z_all, Z_train, Z_val, Z_test, y_data_all, y_data_train, y_data_val, y_data_test)\u001b[39m=\u001b[39mget_pretrain_encoder_from_modelID(model_id, input_data_location, pretrain_save_dir, ml_code_path)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m (Z_all\u001b[39m.\u001b[39mshape, Z_train\u001b[39m.\u001b[39mshape, Z_val\u001b[39m.\u001b[39mshape, Z_test\u001b[39m.\u001b[39mshape, y_data_all\u001b[39m.\u001b[39mshape, y_data_train\u001b[39m.\u001b[39mshape, y_data_val\u001b[39m.\u001b[39mshape, y_data_test\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     12\u001b[0m \u001b[39m# Now use the latnet space to predict the tasks\u001b[39;00m\n",
+      "File \u001b[0;32m~/mz_embed_engine/ml/get_pretrain_encoder.py:199\u001b[0m, in \u001b[0;36mget_pretrain_encoder_from_modelID\u001b[0;34m(model_id, path_to_proccessed_data, output_path, ml_code_path, setup_id, project_id, X_size, encoder_kind, latent_passes)\u001b[0m\n\u001b[1;32m    195\u001b[0m     latent_rep_test \u001b[39m=\u001b[39m generate_latent_space(X_data_test, encoder)\n\u001b[1;32m    196\u001b[0m     Z_test\u001b[39m.\u001b[39mappend(latent_rep_test)\n\u001b[0;32m--> 199\u001b[0m Z_all \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(torch\u001b[39m.\u001b[39;49mstack(Z_all), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    200\u001b[0m Z_train \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(torch\u001b[39m.\u001b[39mstack(Z_train), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    201\u001b[0m Z_val \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(torch\u001b[39m.\u001b[39mstack(Z_val), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
+      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got DataFrame"
+     ]
+    }
+   ],
+   "source": [
+    "input_data_location='/home/leilapirhaji/PROCESSED_DATA_2'\n",
+    "pretrain_save_dir='/home/leilapirhaji/pretrained_models' \n",
+    "\n",
+    "\n",
+    "\n",
+    "#tasks to predict using encoder\n",
+    "task_list_cat=[ 'Study ID', 'is Female', 'is Pediatric', 'Cohort Label v0','Smoking Status', 'Cancer Risk' ]\n",
+    "\n",
+    "task_list_num=[ 'BMI', 'Age' ]\n",
+    "\n",
+    "model_id='RCC-36657'\n",
+    "\n",
+    "model_results=evalute_pretrain_latent_extra_task(model_id, input_data_location, pretrain_save_dir, task_list_cat, task_list_num)"
+   ]
+  },
   {
    "attachments": {},
    "cell_type": "markdown",
@@ -722,27 +1066,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 52,
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "'RCC-36657'"
-      ]
-     },
-     "execution_count": 52,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "model_id"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 53,
+   "execution_count": 12,
    "metadata": {},
    "outputs": [
     {
@@ -771,7 +1095,7 @@
     {
      "data": {
       "application/vnd.jupyter.widget-view+json": {
-       "model_id": "bf7b566989404198b532a5708e6c43c3",
+       "model_id": "42e50f8e38024c9097403675e0745986",
        "version_major": 2,
        "version_minor": 0
       },
@@ -800,80 +1124,32 @@
       "  encoder_state_dict = torch.load(model_encoder_file)\n"
      ]
     },
-    {
-     "ename": "TypeError",
-     "evalue": "expected Tensor as element 0 in argument 0, but got DataFrame",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
-      "Cell \u001b[0;32mIn[53], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m importlib\u001b[39m.\u001b[39mreload(eval_pretrain_latent)\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39meval_pretrain_latent\u001b[39;00m \u001b[39mimport\u001b[39;00m evalute_pretrain_latent_extra_task\n\u001b[0;32m----> 4\u001b[0m model_results \u001b[39m=\u001b[39m evalute_pretrain_latent_extra_task(model_id, input_data_location, pretrain_save_dir, task_list_cat, task_list_num)\n",
-      "File \u001b[0;32m~/mz_embed_engine/ml/eval_pretrain_latent.py:34\u001b[0m, in \u001b[0;36mevalute_pretrain_latent_extra_task\u001b[0;34m(model_id, input_data_location, pretrain_save_dir, task_list_cat, task_list_num)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel_id is \u001b[39m\u001b[39m{\u001b[39;00mmodel_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[39m# getting the latent space for the model\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m (encoder, Z_all, Z_train, Z_val, Z_test, y_data_all, y_data_train, y_data_val, y_data_test)\u001b[39m=\u001b[39mget_pretrain_encoder_from_modelID(model_id, input_data_location, pretrain_save_dir, ml_code_path)\n\u001b[1;32m     37\u001b[0m \u001b[39mprint\u001b[39m (Z_all\u001b[39m.\u001b[39mshape, Z_train\u001b[39m.\u001b[39mshape, Z_val\u001b[39m.\u001b[39mshape, Z_test\u001b[39m.\u001b[39mshape, y_data_all\u001b[39m.\u001b[39mshape, y_data_train\u001b[39m.\u001b[39mshape, y_data_val\u001b[39m.\u001b[39mshape, y_data_test\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     39\u001b[0m \u001b[39m# Now use the latnet space to predict the tasks\u001b[39;00m\n",
-      "File \u001b[0;32m~/mz_embed_engine/ml/get_pretrain_encoder.py:199\u001b[0m, in \u001b[0;36mget_pretrain_encoder_from_modelID\u001b[0;34m(model_id, path_to_proccessed_data, output_path, ml_code_path, setup_id, project_id, X_size, encoder_kind, latent_passes)\u001b[0m\n\u001b[1;32m    195\u001b[0m     latent_rep_test \u001b[39m=\u001b[39m generate_latent_space(X_data_test, encoder)\n\u001b[1;32m    196\u001b[0m     Z_test\u001b[39m.\u001b[39mappend(latent_rep_test)\n\u001b[0;32m--> 199\u001b[0m Z_all \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(torch\u001b[39m.\u001b[39;49mstack(Z_all), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    200\u001b[0m Z_train \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(torch\u001b[39m.\u001b[39mstack(Z_train), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    201\u001b[0m Z_val \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(torch\u001b[39m.\u001b[39mstack(Z_val), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
-      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got DataFrame"
-     ]
-    }
-   ],
-   "source": [
-    "import eval_pretrain_latent\n",
-    "importlib.reload(eval_pretrain_latent)\n",
-    "from eval_pretrain_latent import evalute_pretrain_latent_extra_task\n",
-    "\n",
-    "model_results = evalute_pretrain_latent_extra_task(model_id, input_data_location, pretrain_save_dir, task_list_cat, task_list_num)\n",
-    "\n",
-    "model_results\n"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 56,
-   "metadata": {},
-   "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Study ID Val Accuracy: 0.9512\n",
-      "Study ID Test Accuracy: 0.9445\n",
+      "(20548, 200) (14391, 200) (3074, 200) (3083, 200) (20548, 58) (14391, 58) (3074, 58) (3083, 58)\n",
+      "Study ID Val Accuracy: 0.9525\n",
+      "Study ID Test Accuracy: 0.9458\n",
       "is Female Val Accuracy: 0.8043\n",
       "is Female Test Accuracy: 0.7567\n",
-      "is Pediatric Val Accuracy: 0.9792\n",
-      "is Pediatric Test Accuracy: 0.9825\n",
+      "is Pediatric Val Accuracy: 0.9808\n",
+      "is Pediatric Test Accuracy: 0.9818\n",
       "Cohort Label v0 Val Accuracy: 0.9619\n",
-      "Cohort Label v0 Test Accuracy: 0.9588\n",
-      "Smoking Status Val Accuracy: 0.9344\n",
+      "Cohort Label v0 Test Accuracy: 0.9578\n",
+      "Smoking Status Val Accuracy: 0.9311\n",
       "Smoking Status Test Accuracy: 0.9314\n",
       "Cancer Risk Val Accuracy: 0.9233\n",
       "Cancer Risk Test Accuracy: 0.9190\n"
      ]
-    }
-   ],
-   "source": [
-    "model_results = {'Model ID': model_id}\n",
-    "for task in task_list_cat:\n",
-    "\n",
-    "        (val_accuracy, test_accuracy) = log_reg_multi_class(task, Z_train, y_data_train, Z_val, y_data_val, Z_test, y_data_test)\n",
-    "\n",
-    "        # Store the results in the dictionary\n",
-    "        model_results[f'{task} Val Accuracy'] = val_accuracy\n",
-    "        model_results[f'{task} Test Accuracy'] = test_accuracy\n",
-    "\n",
-    "        print(f'{task} Val Accuracy: {val_accuracy:.4f}')\n",
-    "        print(f'{task} Test Accuracy: {test_accuracy:.4f}')\n"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 60,
-   "metadata": {},
-   "outputs": [
+    },
     {
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "/home/leilapirhaji/.local/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.93355e-08): result may not be accurate.\n",
+      "/home/leilapirhaji/.local/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.93296e-08): result may not be accurate.\n",
       "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
-      "/home/leilapirhaji/.local/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.43877e-08): result may not be accurate.\n",
+      "/home/leilapirhaji/.local/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.43836e-08): result may not be accurate.\n",
       "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
      ]
     },
@@ -886,64 +1162,72 @@
       "Age Val MAE : 9.9546\n",
       "Age Test MAE : 9.7178\n"
      ]
+    },
+    {
+     "data": {
+      "text/plain": [
+       "{'Model ID': 'RCC-36657',\n",
+       " 'Study ID Val Accuracy': 0.9525048796356539,\n",
+       " 'Study ID Test Accuracy': 0.9458319818358741,\n",
+       " 'is Female Val Accuracy': 0.8043478260869565,\n",
+       " 'is Female Test Accuracy': 0.7566666666666667,\n",
+       " 'is Pediatric Val Accuracy': 0.9808067664281067,\n",
+       " 'is Pediatric Test Accuracy': 0.9818358741485566,\n",
+       " 'Cohort Label v0 Val Accuracy': 0.9619388418998048,\n",
+       " 'Cohort Label v0 Test Accuracy': 0.957833279273435,\n",
+       " 'Smoking Status Val Accuracy': 0.9311475409836065,\n",
+       " 'Smoking Status Test Accuracy': 0.9313725490196079,\n",
+       " 'Cancer Risk Val Accuracy': 0.9233067729083665,\n",
+       " 'Cancer Risk Test Accuracy': 0.9190444591904446,\n",
+       " 'BMI Val MAE': 3.9232283557165877,\n",
+       " 'BMI Test MAE': 3.923811241793968,\n",
+       " 'Age Val MAE': 9.95463990170786,\n",
+       " 'Age Test MAE': 9.717826384024695}"
+      ]
+     },
+     "execution_count": 12,
+     "metadata": {},
+     "output_type": "execute_result"
     }
    ],
    "source": [
-    "#now evaluting numercal task predictions\n",
-    "for task in task_list_num:\n",
-    "\n",
-    "    (val_mse, val_mae, val_r2, test_mse, test_mae, test_r2)= ridge_regression_predict(task, Z_train, y_data_train, Z_val, y_data_val, Z_test, y_data_test)\n",
+    "import eval_pretrain_latent\n",
+    "importlib.reload(eval_pretrain_latent)\n",
+    "from eval_pretrain_latent import evalute_pretrain_latent_extra_task\n",
     "\n",
-    "    # Store the results in the dictionary\n",
-    "    model_results[f'{task} Val MSE'] = val_mse\n",
-    "    model_results[f'{task} Val MAE'] = val_mae\n",
-    "    model_results[f'{task} Val R2'] = val_r2\n",
-    "    model_results[f'{task} Test MSE'] = test_mse\n",
-    "    model_results[f'{task} Test MAE'] = test_mae\n",
-    "    model_results[f'{task} Test R2'] = test_r2\n",
+    "model_results = evalute_pretrain_latent_extra_task(model_id, input_data_location, pretrain_save_dir, task_list_cat, task_list_num)\n",
     "\n",
-    "    print(f'{task} Val MAE : {val_mae:.4f}')\n",
-    "    print(f'{task} Test MAE : {test_mae:.4f}')"
+    "model_results\n"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 61,
+   "execution_count": 13,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [
        "{'Model ID': 'RCC-36657',\n",
-       " 'Study ID Val Accuracy': 0.9512036434612883,\n",
-       " 'Study ID Test Accuracy': 0.9445345442750568,\n",
+       " 'Study ID Val Accuracy': 0.9525048796356539,\n",
+       " 'Study ID Test Accuracy': 0.9458319818358741,\n",
        " 'is Female Val Accuracy': 0.8043478260869565,\n",
        " 'is Female Test Accuracy': 0.7566666666666667,\n",
-       " 'is Pediatric Val Accuracy': 0.9791802212101497,\n",
-       " 'is Pediatric Test Accuracy': 0.9824845929289653,\n",
+       " 'is Pediatric Val Accuracy': 0.9808067664281067,\n",
+       " 'is Pediatric Test Accuracy': 0.9818358741485566,\n",
        " 'Cohort Label v0 Val Accuracy': 0.9619388418998048,\n",
-       " 'Cohort Label v0 Test Accuracy': 0.958806357444048,\n",
-       " 'Smoking Status Val Accuracy': 0.9344262295081968,\n",
+       " 'Cohort Label v0 Test Accuracy': 0.957833279273435,\n",
+       " 'Smoking Status Val Accuracy': 0.9311475409836065,\n",
        " 'Smoking Status Test Accuracy': 0.9313725490196079,\n",
        " 'Cancer Risk Val Accuracy': 0.9233067729083665,\n",
        " 'Cancer Risk Test Accuracy': 0.9190444591904446,\n",
-       " 'BMI Val MSE': 31.474254022919432,\n",
-       " 'BMI Val MAE': 3.923244522162404,\n",
-       " 'BMI Val R2': 0.16234745248223503,\n",
-       " 'BMI Test MSE': 33.136116736617716,\n",
-       " 'BMI Test MAe': 3.9238094311236593,\n",
-       " 'BMI Test R2': 0.21686598261764212,\n",
-       " 'Age Val MSE': 156.20674821325835,\n",
-       " 'Age Val MAE': 9.954631767943313,\n",
-       " 'Age Val R2': 0.6196750943013511,\n",
-       " 'Age Test MSE': 147.36208627765836,\n",
-       " 'Age Test MAe': 9.717814025494553,\n",
-       " 'Age Test R2': 0.6423280776614397,\n",
-       " 'BMI Test MAE': 3.9238094311236593,\n",
-       " 'Age Test MAE': 9.717814025494553}"
+       " 'BMI Val MAE': 3.9232283557165877,\n",
+       " 'BMI Test MAE': 3.923811241793968,\n",
+       " 'Age Val MAE': 9.95463990170786,\n",
+       " 'Age Test MAE': 9.717826384024695}"
       ]
      },
-     "execution_count": 61,
+     "execution_count": 13,
      "metadata": {},
      "output_type": "execute_result"
     }
diff --git a/ml/eval_finetune_latent.py b/ml/eval_finetune_latent.py
index 43c32d4..aa7450d 100644
--- a/ml/eval_finetune_latent.py
+++ b/ml/eval_finetune_latent.py
@@ -10,9 +10,11 @@ output: evaluation results of the new tasks saved in csv file
 '''
 
 import os
-ml_code_path='/home/leilapirhaji/mz_embed_engine/ml'
+# ml_code_path='/home/leilapirhaji/mz_embed_engine/ml'
+ml_code_path = os.path.dirname(os.path.realpath(__file__))
 os.chdir(ml_code_path)
 
+
 import pandas as pd
 import importlib
 from sklearn.preprocessing import LabelEncoder
diff --git a/ml/eval_pretrain_latent.py b/ml/eval_pretrain_latent.py
index c850286..05905f1 100644
--- a/ml/eval_pretrain_latent.py
+++ b/ml/eval_pretrain_latent.py
@@ -10,7 +10,8 @@ output: evaluation results of the new tasks saved in csv file
 '''
 
 import os
-ml_code_path='/home/leilapirhaji/mz_embed_engine/ml'
+# ml_code_path='/home/leilapirhaji/mz_embed_engine/ml'
+ml_code_path = os.path.dirname(os.path.realpath(__file__))
 os.chdir(ml_code_path)
 
 import pandas as pd
diff --git a/ml/finetune_using_optuna.py b/ml/finetune_using_optuna.py
new file mode 100644
index 0000000..8e8c395
--- /dev/null
+++ b/ml/finetune_using_optuna.py
@@ -0,0 +1,122 @@
+from setup4 import setup_wrapper
+import os
+import pandas as pd
+import optuna
+from utils_neptune import get_latest_dataset
+from prep_study2 import objective_func4
+
+NEPTUNE_API_TOKEN = 'eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIwZDlmZGM4ZC05OGM2LTQ2YzctYmRhNi0zMjIwODMzMWM1ODYifQ=='
+WEBAPP_DB_LOC = 'mysql://root:zm6148mz@34.134.200.45/mzlearn_webapp_DB'
+
+project_id = 'revivemed/RCC'
+homedir = os.path.expanduser("~")
+input_data_dir = f'{homedir}/INPUT_DATA'
+os.makedirs(input_data_dir, exist_ok=True)
+input_data_dir = get_latest_dataset(data_dir=input_data_dir, api_token=NEPTUNE_API_TOKEN, project=project_id)
+
+# Load the selection dataframe
+selections_df = pd.read_csv(f'{input_data_dir}/selection_df.csv', index_col=0)
+
+model_id_names = [37133]
+for model_id_name in model_id_names:
+
+    output_dir = f'{homedir}/PROCESSED_DATA'
+    os.makedirs(output_dir, exist_ok=True)
+    subdir_col = 'Study ID'
+    # model_id_name = 11517
+    optua_study_name = f'finetune-optuna-RCC-{model_id_name}-recon-only-Sep5'
+    encoder_kind = 'VAE'
+
+    STUDY_INFO_DICT = {
+        'study_name': optua_study_name,
+        'encoder_kind': encoder_kind,
+    }
+
+
+    # Define the Optuna objective function
+    def objective(trial):
+        setup_id = 'finetune-optuna'
+
+        # Hyperparameters to optimize
+        # num_epochs use fixed
+        num_epochs = 20
+        # num_epochs = trial.suggest_int('num_epochs', 5, 50)
+        # learning_rate give range
+        learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)
+        # dropout_rate a range as well
+        dropout_rate = trial.suggest_uniform('dropout_rate', 0, 0.5)
+        # weight_decay a range as well
+        weight_decay = trial.suggest_loguniform('weight_decay', 1e-5, 1e-2)
+        # l1_reg_weight a range as well
+        l1_reg_weight = trial.suggest_uniform('l1_reg_weight', 0, 0.01)
+        # l2_reg_weight a range as well
+        l2_reg_weight = trial.suggest_uniform('l2_reg_weight', 0, 0.01)
+
+        # Call the setup_wrapper with Optuna parameters
+        run_id, all_metrics = setup_wrapper(
+            project_id=project_id,
+            api_token=NEPTUNE_API_TOKEN,
+            setup_id=setup_id,
+            tags=optua_study_name,
+            fit_subset_col='Finetune Discovery Train',
+            eval_subset_col_list=['Finetune Discovery Val'],
+            selections_df=selections_df,
+            output_dir=output_dir,
+            head_name_list=['Both-OS'],
+            # head_name_list=['IMDC'],
+            overwrite_params_fit_kwargs={
+                'num_epochs': num_epochs,
+                'learning_rate': learning_rate,
+                'dropout_rate': dropout_rate,
+                'weight_decay': weight_decay,
+                'l1_reg_weight': l1_reg_weight,
+                'l2_reg_weight': l2_reg_weight,
+                'use_rand_init': False,
+            },
+            overwrite_params_task_kwargs={
+                'hidden_size': 0,
+                'num_hidden_layers': 0,
+            },
+            overwrite_existing_params=True,
+            pretrained_model_id=f'RCC-{model_id_name}',
+            pretrained_loc='pretrain',
+            optuna_study_info_dict=STUDY_INFO_DICT,
+            optuna_trial=trial,
+            num_iterations=10,
+            use_rand_init=False,
+        )
+
+        trial.set_user_attr('run_id', run_id)
+        trial.set_user_attr('setup_id', setup_id)
+
+        print(f"all_metrics: {all_metrics}")
+        # get the loss from the all_metrics
+        # Compute val_loss using the method above
+        # task for both os
+        val_loss_list = all_metrics.get(
+            f'{setup_id}__Finetune_Discovery_Val_Reconstruction MSE', [0])
+        if val_loss_list:
+            # use the average of the list
+            val_loss = sum(val_loss_list) / len(val_loss_list)
+        else:
+            val_loss = 10
+        if val_loss == 0:
+            val_loss = 10
+        print(f"val_loss: {val_loss}")
+        return val_loss
+
+    # Run the optimization
+    num_trials = 50
+    study = optuna.create_study(direction='minimize',  # corrected this line
+                                study_name=optua_study_name,
+                                storage=WEBAPP_DB_LOC,
+                                load_if_exists=True)
+
+    study.optimize(objective, n_trials=num_trials)
+
+    # Output the best hyperparameters
+    print(f"Best trial: {study.best_trial.number}")
+    print(f"Best value (validation loss): {study.best_trial.value}")
+    print("Best hyperparameters:")
+    for key, value in study.best_trial.params.items():
+        print(f"  {key}: {value}")
diff --git a/ml/get_finetune_encoder.py b/ml/get_finetune_encoder.py
index ab1fc6b..c95857e 100644
--- a/ml/get_finetune_encoder.py
+++ b/ml/get_finetune_encoder.py
@@ -127,7 +127,7 @@ def get_finetune_encoder_from_modelID(model_id, path_to_proccessed_data, output_
 
 
 
-def get_input_data(data_location):
+def get_finetune_input_data(data_location):
 
     #defining the input datasets
     
diff --git a/ml/get_pretrain_encoder.py b/ml/get_pretrain_encoder.py
index fe7d036..41b5e40 100644
--- a/ml/get_pretrain_encoder.py
+++ b/ml/get_pretrain_encoder.py
@@ -151,18 +151,17 @@ def get_pretrain_encoder_from_modelID(model_id, path_to_proccessed_data, output_
 
     os.makedirs(f'{pretrain_save_dir}/{model_id}',  exist_ok=True)
     
-
     #download the encoder state dict
-    #if not os.path.exists(local_path):
-    #    run['pretrain/models/encoder_state_dict'].download(local_path)
+    if not os.path.exists(model_local_path):
+       # Download the encoder state dict
+        run['pretrain/models/encoder_state_dict'].download(model_encoder_file)
+    
 
-    # Check if the file exists and remove it if necessary
-    if os.path.exists(model_encoder_file):
-        os.remove(model_encoder_file)
-        print(f"Deleted existing file at {model_encoder_file}")
+    # # Check if the file exists and remove it if necessary
+    # if os.path.exists(model_encoder_file):
+    #     os.remove(model_encoder_file)
+    #     print(f"Deleted existing file at {model_encoder_file}")
 
-    # Download the encoder state dict
-    run['pretrain/models/encoder_state_dict'].download(model_encoder_file)
     # stop the run
     run.stop()
     
diff --git a/ml/prep_run.py b/ml/prep_run.py
index bd9b501..b139db4 100644
--- a/ml/prep_run.py
+++ b/ml/prep_run.py
@@ -715,11 +715,12 @@ def make_kwargs_set(sig_figs=2,
 ########################################################################################
 
 def convert_kwargs_for_optuna(run_kwargs,optuna_trial):
-        run_kwargs = convert_model_kwargs_list_to_dict(run_kwargs)
-        run_kwargs = flatten_dict(run_kwargs) # flatten the dict for optuna compatibility
-        run_kwargs = convert_distributions_to_suggestion(run_kwargs, optuna_trial) # convert the distributions to optuna suggestions
-        run_kwargs = round_kwargs_to_sig(run_kwargs,sig_figs=2)
-        run_kwargs = unflatten_dict(run_kwargs) # unflatten the dict for the setup function
+    run_kwargs = convert_model_kwargs_list_to_dict(run_kwargs)
+    run_kwargs = flatten_dict(run_kwargs) # flatten the dict for optuna compatibility
+    run_kwargs = convert_distributions_to_suggestion(run_kwargs, optuna_trial) # convert the distributions to optuna suggestions
+    run_kwargs = round_kwargs_to_sig(run_kwargs,sig_figs=2)
+    run_kwargs = unflatten_dict(run_kwargs) # unflatten the dict for the setup function
+    return run_kwargs
 
 
 def round_kwargs_to_sig(val,sig_figs=2,key=None):
diff --git a/ml/prep_study2.py b/ml/prep_study2.py
index b71444f..1103384 100644
--- a/ml/prep_study2.py
+++ b/ml/prep_study2.py
@@ -26,38 +26,56 @@ def get_default_study_kwargs(head_kwargs_dict,adv_kwargs_dict,**kwargs):
                 head_kwargs_dict=head_kwargs_dict,
                 adv_kwargs_dict=adv_kwargs_dict,
 
-                latent_size=None, latent_size_min=96, latent_size_max=128, latent_size_step=4,
+                latent_size=64, latent_size_min=96, latent_size_max=128, latent_size_step=4,
                 hidden_size=-1, hidden_size_min=16, hidden_size_max=64, hidden_size_step=16,
-                hidden_size_mult=1.5, hidden_size_mult_min=1.25, hidden_size_mult_max=2, hidden_size_mult_step=0.25,
-                num_hidden_layers=None, num_hidden_layers_min=2, num_hidden_layers_max=3, num_hidden_layers_step=1,
-                
-                num_attention_heads=-1, num_attention_heads_min=1, num_attention_heads_max=5, num_attention_heads_step=1,
-                num_decoder_layers=-1, num_decoder_layers_min=1, num_decoder_layers_max=5, num_decoder_layers_step=1,
+                hidden_size_mult=1.5, hidden_size_mult_min=1.25, hidden_size_mult_max=2,
+                hidden_size_mult_step=0.25,
+                num_hidden_layers=2, num_hidden_layers_min=2, num_hidden_layers_max=3,
+                num_hidden_layers_step=1,
+
+                num_attention_heads=-1, num_attention_heads_min=1, num_attention_heads_max=5,
+                num_attention_heads_step=1,
+                num_decoder_layers=-1, num_decoder_layers_min=1, num_decoder_layers_max=5,
+                num_decoder_layers_step=1,
                 embed_dim=-1, embed_dim_min=4, embed_dim_max=64, embed_dim_step=4,
-                decoder_embed_dim=-1, decoder_embed_dim_min=4, decoder_embed_dim_max=64, decoder_embed_dim_step=4,
-                default_hidden_fraction=-1, default_hidden_fraction_min=0, default_hidden_fraction_max=0.5, default_hidden_fraction_step=0.1,
+                decoder_embed_dim=-1, decoder_embed_dim_min=4, decoder_embed_dim_max=64,
+                decoder_embed_dim_step=4,
+                default_hidden_fraction=-1, default_hidden_fraction_min=0,
+                default_hidden_fraction_max=0.5, default_hidden_fraction_step=0.1,
 
                 dropout_rate=0, dropout_rate_min=0, dropout_rate_max=0.5, dropout_rate_step=0.1,
-                encoder_weight=1.0, encoder_weight_min=0, encoder_weight_max=2, encoder_weight_step=0.5,
+                encoder_weight=1.0, encoder_weight_min=0, encoder_weight_max=2,
+                encoder_weight_step=0.5,
                 head_weight=1.0, head_weight_min=0, head_weight_max=2, head_weight_step=0.5,
                 adv_weight=1.0, adv_weight_min=0, adv_weight_max=2, adv_weight_step=0.5,
 
-                task_head_weight=None, task_head_weight_min=0.25, task_head_weight_max=2, task_head_weight_step=0.25,
-                task_adv_weight=-1, task_adv_weight_min=0, task_adv_weight_max=10, task_adv_weight_step=0.1,
-                task_hidden_size=4, task_hidden_size_min=4, task_hidden_size_max=64, task_hidden_size_step=4,
-                task_num_hidden_layers=1, task_num_hidden_layers_min=1, task_num_hidden_layers_max=3, task_num_hidden_layers_step=1,
-
-                weight_decay=None, weight_decay_min=1e-5, weight_decay_max=1e-2, weight_decay_step=0.00001, weight_decay_log=True,
-                l1_reg_weight=0, l1_reg_weight_min=0, l1_reg_weight_max=0.01, l1_reg_weight_step=0.0001, l1_reg_weight_log=False,
-                l2_reg_weight=0, l2_reg_weight_min=0, l2_reg_weight_max=0.01, l2_reg_weight_step=0.0001, l2_reg_weight_log=False,
-                
-                batch_size=96, batch_size_min=16,batch_size_max=128,batch_size_step=16,
+                task_head_weight=-1, task_head_weight_min=0.25, task_head_weight_max=2,
+                task_head_weight_step=0.25,
+                task_adv_weight=-1, task_adv_weight_min=0, task_adv_weight_max=10,
+                task_adv_weight_step=0.1,
+                task_hidden_size=4, task_hidden_size_min=4, task_hidden_size_max=64,
+                task_hidden_size_step=4,
+                task_num_hidden_layers=1, task_num_hidden_layers_min=1, task_num_hidden_layers_max=3,
+                task_num_hidden_layers_step=1,
+
+                weight_decay=0.0001, weight_decay_min=1e-5, weight_decay_max=1e-2,
+                weight_decay_step=0.00001, weight_decay_log=True,
+                l1_reg_weight=0, l1_reg_weight_min=0, l1_reg_weight_max=0.01,
+                l1_reg_weight_step=0.0001, l1_reg_weight_log=False,
+                l2_reg_weight=0, l2_reg_weight_min=0, l2_reg_weight_max=0.01,
+                l2_reg_weight_step=0.0001, l2_reg_weight_log=False,
+
+                batch_size=96, batch_size_min=16, batch_size_max=128, batch_size_step=16,
                 noise_factor=0.1, noise_factor_min=0.01, noise_factor_max=0.1, noise_factor_step=0.01,
-                num_epochs=None, num_epochs_min=50, num_epochs_max=400, num_epochs_step=25, num_epochs_log=False,
-                learning_rate=None, learning_rate_min=0.00001, learning_rate_max=0.005, learning_rate_step=None,learning_rate_log=True,
-                early_stopping_patience=0, early_stopping_patience_min=0, early_stopping_patience_max=50, early_stopping_patience_step=5,
-                adversarial_start_epoch=0, adversarial_start_epoch_min=-1, adversarial_start_epoch_max=10, adversarial_start_epoch_step=2,
-                )
+                num_epochs=20, num_epochs_min=50, num_epochs_max=400, num_epochs_step=25,
+                num_epochs_log=False,
+                learning_rate=0.0005, learning_rate_min=0.00001, learning_rate_max=0.005,
+                learning_rate_step=None, learning_rate_log=True,
+                early_stopping_patience=0, early_stopping_patience_min=0,
+                early_stopping_patience_max=50, early_stopping_patience_step=5,
+                adversarial_start_epoch=0, adversarial_start_epoch_min=-1,
+                adversarial_start_epoch_max=10, adversarial_start_epoch_step=2,
+    )
     
     return run_kwargs
 
diff --git a/ml/run_pretraining_LP.py b/ml/run_pretraining_LP.py
index 2b05083..5951c60 100644
--- a/ml/run_pretraining_LP.py
+++ b/ml/run_pretraining_LP.py
@@ -126,7 +126,7 @@ def main(STUDY_INFO_DICT, num_trials=5,
     os.makedirs(output_dir, exist_ok=True)
     subdir_col = 'Study ID'
 
-    fit_subset_col = 'Pretrain Discovery Train'
+    fit_subset_col = 'Pretrain Discovery Train' #Finetune_Discovery_Train
     eval_subset_col = 'Pretrain Discovery Val'
     test_subset_col = 'Pretrain Test'
     setup_id = 'pretrain'
diff --git a/ml/run_pretraining_LP_min_test.py b/ml/run_pretraining_LP_min_test.py
new file mode 100644
index 0000000..45651e0
--- /dev/null
+++ b/ml/run_pretraining_LP_min_test.py
@@ -0,0 +1,279 @@
+import os
+import optuna
+import pandas as pd
+from prep_run import create_selected_data, make_kwargs_set, get_task_head_kwargs, round_kwargs_to_sig, flatten_dict, \
+    unflatten_dict
+from utils_neptune import get_latest_dataset, get_run_id_list
+from setup3 import setup_neptune_run
+
+from prep_study2 import objective_func4, reuse_run, get_study_objective_keys, get_study_objective_directions, \
+    add_runs_to_study
+from prep_run import get_selection_df, convert_model_kwargs_list_to_dict, convert_distributions_to_suggestion
+# import torch_cpu_loader
+
+## 
+# %% Load the latest data
+
+NEPTUNE_API_TOKEN = 'eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIwZDlmZGM4ZC05OGM2LTQ2YzctYmRhNi0zMjIwODMzMWM1ODYifQ=='
+WEBAPP_DB_LOC = 'mysql://root:zm6148mz@34.134.200.45/mzlearn_webapp_DB'
+
+project_id = 'revivemed/RCC'
+
+USE_WEBAPP_DB = True
+SAVE_TRIALS = True
+ADD_EXISTING_RUNS_TO_STUDY = False
+limit_add = -1  # limit the number of runs added to the study
+
+encoder_kind = 'VAE'
+tag_study='pretrain latent weight w=0.5 Sep4'
+
+STUDY_DICT = {
+    # oputuna study parameters
+    # study name is the optuna optimization study name
+    'study_name': tag_study,
+    'encoder_kind': encoder_kind,
+    'objectives': {
+        'reconstruction_loss': {
+            'weight': 3,
+            'name': 'Reconstruction Loss',
+            'direction': 'minimize',
+            'default_value': 9999
+        }
+    }
+}
+
+
+def get_study_kwargs(head_kwargs_dict, adv_kwargs_dict,
+                     latent_size_min=100, latent_size_max=254,
+                     num_hidden_layers_min=2, num_hidden_layers_max=4):
+    kwargs = make_kwargs_set(encoder_kind=encoder_kind,
+                             head_kwargs_dict=head_kwargs_dict,
+                             adv_kwargs_dict=adv_kwargs_dict,
+
+                             # vae model paremeters
+                             # if you want to skip tuning, change the None the desired value
+                             # -1 means the parameter was not used
+                             # fixed value is fixed to the value
+                             latent_size=None, latent_size_min=latent_size_min, latent_size_max=latent_size_max,
+                             latent_size_step=8,
+                             hidden_size=-1, hidden_size_min=16, hidden_size_max=64, hidden_size_step=16,
+                             hidden_size_mult=1.5, hidden_size_mult_min=1.25, hidden_size_mult_max=2,
+                             hidden_size_mult_step=0.25,
+                             num_hidden_layers=None, num_hidden_layers_min=num_hidden_layers_min,
+                             num_hidden_layers_max=num_hidden_layers_max,
+                             num_hidden_layers_step=1,
+
+                             # metabol-transformer model parameters
+                             num_attention_heads=-1, num_attention_heads_min=1, num_attention_heads_max=5,
+                             num_attention_heads_step=1,
+                             num_decoder_layers=-1, num_decoder_layers_min=1, num_decoder_layers_max=5,
+                             num_decoder_layers_step=1,
+                             embed_dim=-1, embed_dim_min=4, embed_dim_max=64, embed_dim_step=4,
+                             decoder_embed_dim=-1, decoder_embed_dim_min=4, decoder_embed_dim_max=64,
+                             decoder_embed_dim_step=4,
+                             default_hidden_fraction=-1, default_hidden_fraction_min=0, default_hidden_fraction_max=0.5,
+                             default_hidden_fraction_step=0.1,
+
+                             dropout_rate=0, dropout_rate_min=0, dropout_rate_max=0.5, dropout_rate_step=0.1,
+                             encoder_weight=1.0, encoder_weight_min=0, encoder_weight_max=2, encoder_weight_step=0.5,
+                             head_weight=1.0, head_weight_min=0, head_weight_max=2, head_weight_step=0.5,
+                             adv_weight=1.0, adv_weight_min=0, adv_weight_max=2, adv_weight_step=0.5,
+
+                             task_head_weight=None, task_head_weight_min=0, task_head_weight_max=15,
+                             task_head_weight_step=0.05,
+                             task_adv_weight=-1, task_adv_weight_min=0, task_adv_weight_max=10,
+                             task_adv_weight_step=0.1,
+                             task_hidden_size=4, task_hidden_size_min=4, task_hidden_size_max=64,
+                             task_hidden_size_step=4,
+                             task_num_hidden_layers=1, task_num_hidden_layers_min=1, task_num_hidden_layers_max=3,
+                             task_num_hidden_layers_step=1,
+
+                             weight_decay=None, weight_decay_min=1e-5, weight_decay_max=1e-2, weight_decay_step=0.00001,
+                             weight_decay_log=True,
+                             l1_reg_weight=0, l1_reg_weight_min=0, l1_reg_weight_max=0.01, l1_reg_weight_step=0.0001,
+                             l1_reg_weight_log=False,
+                             l2_reg_weight=0, l2_reg_weight_min=0, l2_reg_weight_max=0.01, l2_reg_weight_step=0.0001,
+                             l2_reg_weight_log=False,
+
+                             batch_size=96, batch_size_min=32, batch_size_max=128, batch_size_step=32,
+                             noise_factor=None, noise_factor_min=0, noise_factor_max=0.25, noise_factor_step=0.05,
+                             num_epochs=20, num_epochs_min=50, num_epochs_max=400, num_epochs_step=25,
+                             num_epochs_log=False,
+                             learning_rate=None, learning_rate_min=0.00001, learning_rate_max=0.005,
+                             learning_rate_step=None, learning_rate_log=True,
+                             early_stopping_patience=0, early_stopping_patience_min=0, early_stopping_patience_max=50,
+                             early_stopping_patience_step=5,
+                             adversarial_start_epoch=0, adversarial_start_epoch_min=-1, adversarial_start_epoch_max=10,
+                             adversarial_start_epoch_step=2,
+                             )
+    return kwargs
+
+
+def main(STUDY_INFO_DICT, num_trials=5,
+         latent_size_min=100, latent_size_max=254,
+         num_hidden_layers_min=2, num_hidden_layers_max=4,
+         tag='tag'):
+    neptune_api_token = NEPTUNE_API_TOKEN
+    homedir = os.path.expanduser("~")
+    input_data_dir = f'{homedir}/INPUT_DATA'
+    os.makedirs(input_data_dir, exist_ok=True)
+    input_data_dir = get_latest_dataset(data_dir=input_data_dir, api_token=NEPTUNE_API_TOKEN, project=project_id)
+
+    selections_df = pd.read_csv(f'{input_data_dir}/selection_df.csv', index_col=0)
+
+    output_dir = f'{homedir}/PROCESSED_DATA'
+    PROCESSED_DATA_dir=output_dir
+    os.makedirs(output_dir, exist_ok=True)
+    subdir_col = 'Study ID'
+
+    fit_subset_col = 'Pretrain Discovery Train'
+    eval_subset_col = 'Pretrain Discovery Val'
+    test_subset_col = 'Pretrain Test'
+    eval_subset_col3 = 'Pretrain All'
+    setup_id = 'pretrain'
+
+    _, fit_file_id = create_selected_data(input_data_dir=input_data_dir,
+                                          sample_selection_col=fit_subset_col,
+                                          subdir_col=subdir_col,
+                                          output_dir=output_dir,
+                                          metadata_df=None,
+                                          selections_df=selections_df)
+
+    _, eval_file_id = create_selected_data(input_data_dir=input_data_dir,
+                                           sample_selection_col=eval_subset_col,
+                                           subdir_col=subdir_col,
+                                           output_dir=output_dir,
+                                           metadata_df=None,
+                                           selections_df=selections_df)
+    
+    _, test_file_id = create_selected_data(input_data_dir=input_data_dir,
+                                           sample_selection_col=test_subset_col,
+                                           subdir_col=subdir_col,
+                                           output_dir=output_dir,
+                                           metadata_df=None,
+                                           selections_df=selections_df)
+
+    _, eval_file_id3 = create_selected_data(input_data_dir=input_data_dir,
+                                            sample_selection_col=eval_subset_col3,
+                                            subdir_col=subdir_col,
+                                            output_dir=output_dir,
+                                            metadata_df=None,
+                                            selections_df=selections_df)
+    
+
+
+    X_eval_file = f'{output_dir}/X_{eval_file_id}.csv'
+    y_eval_file = f'{output_dir}/y_{eval_file_id}.csv'
+    X_fit_file = f'{output_dir}/X_{fit_file_id}.csv'
+    y_fit_file = f'{output_dir}/y_{fit_file_id}.csv'
+    X_test_file = f'{output_dir}/X_{test_file_id}.csv'
+    y_test_file = f'{output_dir}/y_{test_file_id}.csv'
+
+    # Determine the Task Heads
+    plot_latent_space_cols = []
+    y_head_cols = []
+    y_adv_cols = []
+    head_kwargs_dict = {}
+    adv_kwargs_dict = {}
+
+    def compute_objective(run_id):
+        return objective_func4(run_id,
+                               study_info_dict=STUDY_INFO_DICT,
+                               project_id=project_id,
+                               neptune_api_token=neptune_api_token,
+                               setup_id=setup_id,
+                               eval_file_id=eval_file_id)
+
+    def objective(trial):
+
+        try:
+            kwargs = get_study_kwargs(head_kwargs_dict, adv_kwargs_dict,
+                                      latent_size_min=latent_size_min, latent_size_max=latent_size_max,
+                                      num_hidden_layers_min=num_hidden_layers_min,
+                                      num_hidden_layers_max=num_hidden_layers_max)
+
+            kwargs = convert_model_kwargs_list_to_dict(kwargs)
+            kwargs = flatten_dict(kwargs)  # flatten the dict for optuna compatibility
+            kwargs = convert_distributions_to_suggestion(kwargs,
+                                                         trial)  # convert the distributions to optuna suggestions
+            kwargs = round_kwargs_to_sig(kwargs, sig_figs=2)
+            kwargs = unflatten_dict(kwargs)  # unflatten the dict for the setup function
+
+            kwargs['study_info_dict'] = STUDY_INFO_DICT
+
+            run_id = setup_neptune_run(PROCESSED_DATA_dir, input_data_dir,
+                                       setup_id=setup_id,
+                                       project_id=project_id,
+
+                                       neptune_mode='async',
+                                       yes_logging=True,
+                                       neptune_api_token=neptune_api_token,
+                                       tags=[tag],
+                                       y_head_cols=y_head_cols,
+                                       y_adv_cols=y_adv_cols,
+                                       num_repeats=1,
+
+                                       run_training=True,
+                                       X_fit_file=X_fit_file,
+                                       y_fit_file=y_fit_file,
+                                       train_name=fit_file_id,
+
+                                       run_evaluation=True,
+                                       X_eval_file=X_eval_file,
+                                       y_eval_file=y_eval_file,
+                                       eval_name=eval_file_id,
+
+                                       X_test_file=X_test_file,
+                                       y_test_file=y_test_file,
+                                       test_name=test_file_id,
+
+                                       save_latent_space=True,
+                                       plot_latent_space_cols=plot_latent_space_cols,
+                                       plot_latent_space='sns',
+
+                                       # with_run_id=with_run_id,
+                                       # load_model_from_run_id=None,
+                                       # load_model_loc = None,
+                                       # load_encoder_loc= 'pretrain',
+
+                                       **kwargs)
+
+            trial.set_user_attr('run_id', run_id)
+            trial.set_user_attr('setup_id', setup_id)
+
+            return compute_objective(run_id)
+
+        # except Exception as e:
+        except ValueError as e:
+            print(e)
+            # return float('nan')
+            raise optuna.TrialPruned()
+
+    if USE_WEBAPP_DB:
+        print('using webapp database')
+        storage_name = WEBAPP_DB_LOC
+
+    if 'study_name' in STUDY_INFO_DICT:
+        if 'encoder_kind' in STUDY_INFO_DICT:
+            study_name = STUDY_INFO_DICT['study_name'] + f' {STUDY_INFO_DICT["encoder_kind"]}'
+        else:
+            study_name = STUDY_INFO_DICT['study_name']
+    else:
+        study_name = f'{encoder_kind} Study'
+
+    study = optuna.create_study(directions=get_study_objective_directions(STUDY_INFO_DICT),
+                                study_name=study_name,
+                                storage=storage_name,
+                                load_if_exists=True)
+
+    study.optimize(objective, n_trials=num_trials)
+
+
+if __name__ == '__main__':
+    # 250-350
+    main(STUDY_DICT, num_trials=200,
+         latent_size_min=128, latent_size_max=554,
+         num_hidden_layers_min=2, num_hidden_layers_max=4,
+         # change neptune run tag to keep track of the runs
+         tag=tag_study
+         )
\ No newline at end of file
diff --git a/ml/setup3.py b/ml/setup3.py
index f415255..4ea36f5 100644
--- a/ml/setup3.py
+++ b/ml/setup3.py
@@ -30,7 +30,8 @@ from neptune.exceptions import NeptuneException
 
 
 import os
-ml_code_path='/home/leilapirhaji/mz_embed_engine/ml'
+# ml_code_path='/home/leilapirhaji/mz_embed_engine/ml'
+ml_code_path = os.path.dirname(os.path.realpath(__file__))
 os.chdir(ml_code_path)
 
 import pandas as pd
diff --git a/ml/setup4.py b/ml/setup4.py
index d9ad423..ccf43f0 100644
--- a/ml/setup4.py
+++ b/ml/setup4.py
@@ -15,7 +15,7 @@ import optuna
 from collections import defaultdict
 import re
 import argparse
-
+import random
 import matplotlib.pyplot as plt
 import seaborn as sns
 import plotly.express as px
@@ -65,6 +65,16 @@ def setup_wrapper(**kwargs):
     overwrite_params_fit_kwargs = kwargs.get('overwrite_params_fit_kwargs',{})
     overwrite_params_task_kwargs = kwargs.get('overwrite_params_task_kwargs',{})
     overwrite_params_other_kwargs = kwargs.get('overwrite_params_other_kwargs',{})
+
+    #### setting the same seed for everything
+    random_seed = kwargs.get('random_seed', 42)
+    np.random.seed(random_seed)
+    torch.manual_seed(random_seed)
+    torch.cuda.manual_seed_all(random_seed)
+    np.random.seed(random_seed)
+    random.seed(random_seed)
+    torch.backends.cudnn.deterministic = True
+    torch.backends.cudnn.benchmark = False
     
     if fit_subset_col is None:
         raise ValueError('fit_subset_col must be provided')
@@ -179,6 +189,8 @@ def setup_wrapper(**kwargs):
         else:
             encoder_kwargs = run_kwargs['encoder_kwargs']
 
+        # TODO: quick fix for optuna, no need to pass the head_kwargs_dict and adv_kwargs_dict (min)
+        run_kwargs['adv_kwargs_dict'] = {}
 
         params = {
             'task_kwargs': {
@@ -213,7 +225,7 @@ def setup_wrapper(**kwargs):
 
         run['dataset'].track_files(input_data_dir)
         run['params'] = stringify_unsupported(params)
-
+        run['model_id'] = pretrained_model_id
 
     if eval_params_list is None:
         # eval_params_list0 = [x for x in default_eval_params_list if x['y_cols'][0] in params['task_kwargs']['y_head_cols']]
diff --git a/startup_vm.py b/startup_vm.py
index 54603d4..373a10d 100644
--- a/startup_vm.py
+++ b/startup_vm.py
@@ -16,6 +16,7 @@ import seaborn as sns
 import umap
 import plotly.express as px
 from plotly.offline import plot
+import itertools
 
 from sklearn.neighbors import KNeighborsRegressor
 import matplotlib.pyplot as plt
@@ -76,13 +77,14 @@ def download_from_bucket(bucket_name, blob_path, local_path):
                 blob.download_to_filename(downloadpath)
 
 
-def get_mspeak_from_job_id(script_path_mspeak, job_id, freq_th):
+def get_mspeak_from_job_id(script_path_mspeak, job_id, freq_th, max_samples_th):
     # process the reference study
     query = ("SELECT * FROM app_user_job_status WHERE id = " + str(job_id) + ";")
     cursor.execute(query)
     records = cursor.fetchall()
     user_id = records[0][1]
     job_time = records[0][3]
+    user_selected_normalization_method = records[0][48]
     # job_time = job_time.strftime("%Y-%m-%d %H:%M:%S")
     mzlearn_path = f"mzlearn/{user_id}/{job_time}"
 
@@ -96,7 +98,7 @@ def get_mspeak_from_job_id(script_path_mspeak, job_id, freq_th):
     # mzlearn-webapp.appspot.com/mzlearn/min/2023-09-29 15:43:35/mzlearn_intermediate_results
     full_intermediate_folder_path = f"mzlearn-webapp.appspot.com/{mzlearn_path}"
     if fs.exists(full_intermediate_folder_path):
-        print("try to download mzlearn_intermediate_results to local")
+        print("try to download files to build mspeak object")
         # when downloading only need the
         # sample_info/sample_info.csv
         # targets.csv do not have?
@@ -112,6 +114,7 @@ def get_mspeak_from_job_id(script_path_mspeak, job_id, freq_th):
             download_from_bucket(bucket_name, final_peaks_folder_path, f"{dst_path}/final_peaks")
             blob = bucket.blob(params_overall_fild_path)
             blob.download_to_filename(f"{dst_path}/params_overall.csv")
+        print("downloaded files to build mspeak object")
     else:
         print("Did not download mzlearn_intermediate_results to local")
 
@@ -130,14 +133,18 @@ def get_mspeak_from_job_id(script_path_mspeak, job_id, freq_th):
                                         )
 
     # use pool_map normalization if possible, else use synthetic normalization
-    pool_map_intensity_path = f"{script_path}/{job_id}/result-/final_peaks/intensity_max_pool_map_norm.csv"
-    synthetic_norm_intensity_path = f"{script_path}/{job_id}/result-/final_peaks/intensity_max_synthetic_map_norm.csv"
-    normalized_intensity_df = pd.DataFrame()
-    if os.path.exists(pool_map_intensity_path):
-        normalized_intensity_df = pd.read_csv(pool_map_intensity_path, index_col=0)
-    else:  # use synthetic normalization if pool_map normalization does not exist
-        normalized_intensity_df = pd.read_csv(synthetic_norm_intensity_path, index_col=0)
-    # if normalized_intensity_df is not empty, then use it to update the intensity of the origin_study
+    # use user selected normalization method
+    # normalization_methods: hall_mark_normalization,pool_map_normalization,synthetic_map_normalization
+    # pool_map_intensity_path = f"{script_path}/{job_id}/result-/final_peaks/intensity_max_pool_map_norm.csv"
+    # synthetic_norm_intensity_path = f"{script_path}/{job_id}/result-/final_peaks/intensity_max_synthetic_map_norm.csv"
+    if user_selected_normalization_method == 'pool_map_normalization':
+        normalized_intensity_peak_list_path = f"{script_path}/{job_id}/result-/final_peaks/intensity_max_pool_map_norm.csv"
+    elif user_selected_normalization_method == 'synthetic_map_normalization':
+        normalized_intensity_peak_list_path = f"{script_path}/{job_id}/result-/final_peaks/intensity_max_synthetic_map_norm.csv"
+    else:
+        normalized_intensity_peak_list_path = f"{script_path}/{job_id}/result-/final_peaks/intensity_max_norm.csv"
+
+    normalized_intensity_df = pd.read_csv(normalized_intensity_peak_list_path, index_col=0)
     if not normalized_intensity_df.empty:
         print("peak intensity added")
         study_mspeak.add_peak_intensity(normalized_intensity_df)
@@ -203,6 +210,13 @@ if len(records) > 0:
     reference_job_freq_th = records[0][5]
     other_job_freq_th = records[0][6]
     alignment_methods = records[0][8]
+    max_num_samples = records[0][10]
+
+    if max_num_samples:
+        max_num_samples = max_num_samples.split(',')
+        max_num_samples = [int(i) for i in max_num_samples]
+    else:
+        max_num_samples = [None]
 
     alignment_methods = alignment_methods.split(',')
     other_job_ids = other_job_ids.split(',')
@@ -282,356 +296,418 @@ if len(records) > 0:
         # append the sample_info_df to all_job_sample_info
         all_job_sample_info = pd.concat([all_job_sample_info, sample_info_df], sort=False,
                                         ignore_index=True)
+        # mzlearn-webapp.appspot.com/mzlearn/min/2023-10-20 13:55:12/targets_peaks/name_matched_targets.csv
+        # save this file to local storage if it exists
+        targets_path = f"mzlearn-webapp.appspot.com/{mzlearn_path}/targets_peaks/name_matched_targets.csv"
+        if fs.exists(targets_path):
+            if not os.path.exists(f"{script_path}/{job_id}"):
+                os.makedirs(f"{script_path}/{job_id}")
+            with fs.open(targets_path) as f:
+                targets_df = pd.read_csv(f, sep=",")
+            targets_df.to_csv(f"{script_path}/{job_id}/targets.csv", index=False)
     print(all_job_sample_info)
 
     ####################################################################################################################
     # TODO: add a new loop there to loop through all the other studies frequency threshold
     # TODO: clearup existing code and get read to add new method
     ####################################################################################################################
-    grid_search_summary_df = pd.DataFrame()
-    for alignment_method in alignment_methods:
-        for reference_freq_th in origin_freq_th:
-            for freq_th in other_study_freq_th:
-
-                # frequency sub dir
-                freq_grid_search_dir_name = f'{alignment_method}_reference_freq_th_{reference_freq_th}_freq_th_{freq_th}'
-
-                # get mspeak object for the reference study
-                print("get original study data")
-                origin_study = get_mspeak_from_job_id(script_path, str(reference_job_id), reference_freq_th)
-
-                # fill missing values
-                origin_study.fill_missing_values(method=fill_na_strat)
-                origin_study.add_study_id(reference_job_id, rename_samples=False)
-                if not os.path.exists(f"{script_path}/{reference_job_id}/{freq_grid_search_dir_name}"):
-                    os.makedirs(f"{script_path}/{reference_job_id}/{freq_grid_search_dir_name}")
-                origin_study.save_to_pickle(
-                    os.path.join(f"{script_path}/{reference_job_id}/{freq_grid_search_dir_name}",
-                                 f"{reference_job_id}.pkl"))
-                origin_peak_obj_path = os.path.join(f"{script_path}/{reference_job_id}/{freq_grid_search_dir_name}",
-                                                    f"{reference_job_id}.pkl")
-
-                # save the alignment results different folder depends on the frequency threshold
-                align_save_dir_freq_th = os.path.join(align_save_dir, f'{freq_grid_search_dir_name}')
-                # if no alignment folder exists, create one
-                if not os.path.exists(align_save_dir_freq_th):
-                    os.makedirs(align_save_dir_freq_th)
-                # save other studies to folder
-                input_peak_obj_path_list = []
-                print("get other study data")
-                for study_id in other_job_ids:
-                    print(study_id)
-                    # process rest of the jobs and aligin to origin_study
-                    # get mspeak object for the study_id study
-                    new_study = get_mspeak_from_job_id(script_path, str(study_id), freq_th)
-                    # fill missing values
-                    new_study.fill_missing_values(method=fill_na_strat)
-                    new_study.add_study_id(study_id, rename_samples=False)
-                    if not os.path.exists(f"{script_path}/{study_id}/{freq_grid_search_dir_name}"):
-                        os.makedirs(f"{script_path}/{study_id}/{freq_grid_search_dir_name}")
-                    new_study.save_to_pickle(
-                        os.path.join(f"{script_path}/{study_id}/{freq_grid_search_dir_name}", f"{study_id}.pkl"))
-                    input_peak_obj_path_list.append(
-                        os.path.join(f"{script_path}/{study_id}/{freq_grid_search_dir_name}", f"{study_id}.pkl"))
-
-                ########################################################################################################
-                # alignment happens here using
-                ########################################################################################################
-                other_job_ids = [str(i) for i in other_job_ids]
-                alignment_df = align_multiple_ms_studies(origin_peak_obj_path, input_peak_obj_path_list,
-                                                         align_save_dir_freq_th,
-                                                         origin_name=str(reference_job_id),
-                                                         input_name_list=other_job_ids,
-                                                         alignment_method=alignment_method)
-                alignment_df.to_csv(os.path.join(align_save_dir_freq_th, 'alignment_df.csv'), index=True)
-                    # try:
-                #     align_ms_studies(origin_study,
-                #                      new_study,
-                #                      origin_name=reference_job_id,
-                #                      input_name=study_id,
-                #                      save_dir=align_save_dir_freq_th)
-                # except Exception as e:
-                #     print(f'Alignment failed for {study_id} with error {e}')
-
-                # alignment_df = combine_alignments_in_dir(align_save_dir_freq_th, origin_name=reference_job_id)
-                # alignment_df.to_csv(os.path.join(align_save_dir_freq_th, 'alignment_df.csv'), index=True)
-
-                # based on alignment_df build the grid_search_summary_df
-                # this summary df has the following columns:
-                # 1. freq_th
-                # 2. peaks from origin study
-                # 3. peaks from other study (each study has a column)
-                # 4. common peaks found in all studies
-                print(alignment_df.columns)
-                dummy_row = {'method': alignment_method,
-                             'reference_cohort_freq_threshold': f"{int(reference_freq_th * 100)}%",
-                             'remaining_cohorts_freq_threshold': f"{int(freq_th * 100)}%",
-                             'common_peaks': (~alignment_df.isna()).all(axis=1).sum(),
-                             # common peaks is the count of rows from alignment_df that has no nan
-                             'reference_cohort_peaks': alignment_df.shape[0]}
-                for study_id in other_job_ids:
-                    dummy_row[f"remaining_cohort_{study_id}_peaks"] = alignment_df[str(study_id)].count()
-
-                dummy_row['common_peaks'] = (~alignment_df.isna()).all(axis=1).sum()
-                grid_search_summary_df = grid_search_summary_df.append(dummy_row, ignore_index=True)
-
-                ########################################################################################################
-                # rename the features in each study to correspond to the origin, remove the features that
-                # do not align to origin
-                ########################################################################################################
-                rename_inputs_to_origin(align_save_dir_freq_th,
-                                        multi_alignment_df=None,
-                                        input_name_list=None,
-                                        load_dir=None,
-                                        input_peak_obj_path_list=input_peak_obj_path_list)
-
-                # for study_id in other_job_ids:
-                #     result_path = os.path.join(f"{script_path}/{study_id}/{freq_grid_search_dir_name}",
-                #                                f"{study_id}.pkl")
-                #     input_study_pkl_file = os.path.join(f"{script_path}/{study_id}/{freq_grid_search_dir_name}",
-                #                                         f"{study_id}.pkl")
-                #     renamed_study_pkl_file = os.path.join(f"{script_path}/{study_id}/{freq_grid_search_dir_name}",
-                #                                           f"{study_id}_renamed.pkl")
-                #     if os.path.exists(input_study_pkl_file):
-                #         input_study = load_mspeaks_from_pickle(input_study_pkl_file)
-                #         input_alignment = alignment_df['Compound_ID_' + str(study_id)].copy()
-                #         input_alignment.dropna(inplace=True)
-                #
-                #         current_ids = input_alignment.values
-                #         new_ids = input_alignment.index
-                #         input_study.rename_selected_peaks(current_ids, new_ids, verbose=False)
-                #         input_study.save_to_pickle(renamed_study_pkl_file)
-
-                ########################################################################################################
-                # do stats on alignment results
-                ########################################################################################################
-                # save the alignment results to a csv on gcp bucket
-                # mzlearn-webapp.appspot.com/mzlearn_pretraining/peak_combine_results/{job_id}/alignment_df.csv
-                # TODO: save the alignment results to a csv on gcp bucket based on threshold as well
-                gcp_file_path = f"mzlearn-webapp.appspot.com/mzlearn_pretraining/peak_combine_results/{peak_combine_job_id}/{freq_grid_search_dir_name}/alignment_df.csv"
-                with fs.open(gcp_file_path, 'w') as f:
-                    alignment_df.to_csv(f, index=True)
-
-                num_studies = alignment_df.shape[1]
-                print(f'Number of studies: {num_studies}')
-                num_origin_feats = alignment_df.shape[0]
-                print(f'Number of Origin features: {num_origin_feats}')
-
-                feat_count = (~alignment_df.isna()).sum(axis=1)
-                plt.hist(feat_count)
-                plt.xlabel('Number of studies')
-                plt.ylabel('Number of features')
-                plt.title('Number of features detected in each study')
-                plt.savefig(os.path.join(align_save_dir_freq_th, 'num_features_matched_across_studies.png'))
-                print(f'Number of features detected in all studies: {np.sum(feat_count == num_studies)}')
-
-                ########################################################################################################################
-                # based on the alignment results, do peak combination
-                ########################################################################################################################
-                # TODO: add save here based on other job frequency threshold
-                feat_thresh_name = f'num_cohorts_thresh_{num_cohorts_thresh}'
-                chosen_feats = alignment_df.index[feat_count >= num_studies * num_cohorts_thresh].tolist()
-                print(f'Number of features selected: {len(chosen_feats)}')
-
-                # remove nan from chosen_feats
-                chosen_feats = [i for i in chosen_feats if i in origin_study.peak_intensity.index]
-
-                select_feats_dir = os.path.join(align_save_dir_freq_th, feat_thresh_name)
-                os.makedirs(select_feats_dir, exist_ok=True)
-
-                # load the reference study first and do log2 transformation
-                combined_study = origin_study.peak_intensity.loc[chosen_feats, :].copy()
-                combined_study_nan_mask = origin_study.missing_val_mask.loc[chosen_feats, :].copy()
-                combined_study = np.log2(combined_study)
-
-                # get all the file names for the origin_study
-                origin_study_file_list = origin_study.peak_intensity.columns.to_list()
-                study_id2file_name = {str(reference_job_id): origin_study_file_list}
-
-                # get the cohort labels for the origin_study
-                # read the database entry for the origin_study based on the job_id
-                study_id2cohort_label = {}
+    # new way to to grid search, build the grid search parameters list first
+    # then loop through the list to do the alignment and peak combination
+    gridsearch_params_combinations = list(itertools.product(alignment_methods,
+                                                            origin_freq_th,
+                                                            other_study_freq_th,
+                                                            max_num_samples,
+                                                            ))
+    gridsearch_params_combinations = pd.DataFrame(gridsearch_params_combinations,
+                                                  columns=['method',
+                                                           'reference_cohort_freq_threshold',
+                                                           'remaining_cohorts_freq_threshold',
+                                                           'max_num_samples',
+                                                           ])
+
+    print(f"gridsearch_params_combinations: {gridsearch_params_combinations}")
+
+    for index, row in gridsearch_params_combinations.iterrows():
+        alignment_method = row['method']
+        reference_freq_th = row['reference_cohort_freq_threshold']
+        freq_th = row['remaining_cohorts_freq_threshold']
+        max_num_samples = row['max_num_samples']
+
+        # grid search sub dir
+        freq_grid_search_dir_name = f"grid_search_index_{index}"
+
+        # get mspeak object for the reference study
+        print("get original study data")
+        origin_study = get_mspeak_from_job_id(script_path, str(reference_job_id), reference_freq_th, None)
+
+        # fill missing values
+        origin_study.fill_missing_values(method=fill_na_strat)
+        origin_study.add_study_id(reference_job_id, rename_samples=False)
+        if not os.path.exists(f"{script_path}/{reference_job_id}/{freq_grid_search_dir_name}"):
+            os.makedirs(f"{script_path}/{reference_job_id}/{freq_grid_search_dir_name}")
+        origin_study.save_to_pickle(
+            os.path.join(f"{script_path}/{reference_job_id}/{freq_grid_search_dir_name}",
+                         f"{reference_job_id}.pkl"))
+        origin_peak_obj_path = os.path.join(f"{script_path}/{reference_job_id}/{freq_grid_search_dir_name}",
+                                            f"{reference_job_id}.pkl")
+
+        # save the alignment results different folder depends on the frequency threshold
+        align_save_dir_freq_th = os.path.join(align_save_dir, f'{freq_grid_search_dir_name}')
+        # if no alignment folder exists, create one
+        if not os.path.exists(align_save_dir_freq_th):
+            os.makedirs(align_save_dir_freq_th)
+        # save other studies to folder
+        input_peak_obj_path_list = []
+        print("get other study data")
+        for study_id in other_job_ids:
+            print(study_id)
+            # process rest of the jobs and aligin to origin_study
+            # get mspeak object for the study_id study
+            new_study = get_mspeak_from_job_id(script_path, str(study_id), freq_th, max_num_samples)
+            # fill missing values
+            new_study.fill_missing_values(method=fill_na_strat)
+            new_study.add_study_id(study_id, rename_samples=False)
+            if not os.path.exists(f"{script_path}/{study_id}/{freq_grid_search_dir_name}"):
+                os.makedirs(f"{script_path}/{study_id}/{freq_grid_search_dir_name}")
+            new_study.save_to_pickle(
+                os.path.join(f"{script_path}/{study_id}/{freq_grid_search_dir_name}", f"{study_id}.pkl"))
+            input_peak_obj_path_list.append(
+                os.path.join(f"{script_path}/{study_id}/{freq_grid_search_dir_name}", f"{study_id}.pkl"))
+
+        ########################################################################################################
+        # alignment happens here using
+        ########################################################################################################
+        other_job_ids = [str(i) for i in other_job_ids]
+        alignment_df = align_multiple_ms_studies(origin_peak_obj_path, input_peak_obj_path_list,
+                                                 align_save_dir_freq_th,
+                                                 origin_name=str(reference_job_id),
+                                                 input_name_list=other_job_ids,
+                                                 alignment_method=alignment_method)
+        alignment_df.to_csv(os.path.join(align_save_dir_freq_th, 'alignment_df.csv'), index=True)
+
+        # based on alignment_df add columns to row in the gridsearch_params_combinations
+        # this summary df has the following columns:
+        # 1. freq_th
+        # 2. peaks from origin study
+        # 3. peaks from other study (each study has a column)
+        # 4. max_num_of_samples
+        # 5. common peaks found in all studies
+        # edit the row in gridsearch_params_combinations to add new columns
+        gridsearch_params_combinations.at[index, 'common_peaks'] = (~alignment_df.isna()).all(axis=1).sum()
+        gridsearch_params_combinations.at[index, 'reference_cohort_peaks'] = alignment_df.shape[0]
+        for study_id in other_job_ids:
+            gridsearch_params_combinations.at[index, f"remaining_cohort_{study_id}_peaks"] = alignment_df[
+                str(study_id)].count()
+
+        ########################################################################################################
+        # rename the features in each study to correspond to the origin, remove the features that
+        # do not align to origin
+        ########################################################################################################
+        rename_inputs_to_origin(align_save_dir_freq_th,
+                                multi_alignment_df=None,
+                                input_name_list=None,
+                                load_dir=None,
+                                input_peak_obj_path_list=input_peak_obj_path_list)
+
+        ########################################################################################################
+        # do stats on alignment results
+        ########################################################################################################
+        # save the alignment results to a csv on gcp bucket
+        # mzlearn-webapp.appspot.com/mzlearn_pretraining/peak_combine_results/{job_id}/alignment_df.csv
+        # TODO: save the alignment results to a csv on gcp bucket based on threshold as well
+        gcp_file_path = f"mzlearn-webapp.appspot.com/mzlearn_pretraining/peak_combine_results/{peak_combine_job_id}/{freq_grid_search_dir_name}/alignment_df.csv"
+        with fs.open(gcp_file_path, 'w') as f:
+            alignment_df.to_csv(f, index=True)
+
+        num_studies = alignment_df.shape[1]
+        print(f'Number of studies: {num_studies}')
+        num_origin_feats = alignment_df.shape[0]
+        print(f'Number of Origin features: {num_origin_feats}')
+
+        feat_count = (~alignment_df.isna()).sum(axis=1)
+        plt.hist(feat_count)
+        plt.xlabel('Number of studies')
+        plt.ylabel('Number of features')
+        plt.title('Number of features detected in each study')
+        plt.savefig(os.path.join(align_save_dir_freq_th, 'num_features_matched_across_studies.png'))
+        print(f'Number of features detected in all studies: {np.sum(feat_count == num_studies)}')
+
+        ################################################################################################################
+        # based on the alignment results, do peak combination
+        ################################################################################################################
+        feat_thresh_name = f'num_cohorts_thresh_{num_cohorts_thresh}'
+        chosen_feats = alignment_df.index[feat_count >= num_studies * num_cohorts_thresh].tolist()
+        print(f'Number of features selected: {len(chosen_feats)}')
+
+        # remove nan from chosen_feats
+        chosen_feats = [i for i in chosen_feats if i in origin_study.peak_intensity.index]
+
+        select_feats_dir = os.path.join(align_save_dir_freq_th, feat_thresh_name)
+        os.makedirs(select_feats_dir, exist_ok=True)
+
+        # load the reference study first and do log2 transformation
+        combined_study = origin_study.peak_intensity.loc[chosen_feats, :].copy()
+        combined_study_nan_mask = origin_study.missing_val_mask.loc[chosen_feats, :].copy()
+        combined_study = np.log2(combined_study)
+
+        # get all the file names for the origin_study
+        origin_study_file_list = origin_study.peak_intensity.columns.to_list()
+        study_id2file_name = {str(reference_job_id): origin_study_file_list}
+
+        # get the cohort labels for the origin_study
+        # read the database entry for the origin_study based on the job_id
+        study_id2cohort_label = {}
+        try:
+            query = f"select cohort_label from app_user_job_status where id = {reference_job_id}"
+            cursor.execute(query)
+            records = cursor.fetchall()
+            study_id2cohort_label[str(reference_job_id)] = records[0][0]
+        except Exception as e:
+            print(f'Error in reading cohort labels: {e}')
+            study_id2cohort_label[str(reference_job_id)] = "NA"
+
+        # for each other study, load the peak intensity and do log2 transformation
+        for study_id in other_job_ids:
+            print(study_id)
+            print(freq_grid_search_dir_name)
+            # input_study_pkl_file = os.path.join(output_dir, f'{result_name}_renamed.pkl')
+            input_study_pkl_file = os.path.join(f"{script_path}/{study_id}/{freq_grid_search_dir_name}",
+                                                f"{study_id}_renamed.pkl")
+            if os.path.exists(input_study_pkl_file):
+                # input_study = load_mspeaks_from_pickle(input_study_pkl_file)
+                input_study = MSPeaks()
+                input_study.load(input_study_pkl_file)
+                input_study_file_list = input_study.peak_intensity.columns.to_list()
+                # add a key to study_id2file_name
+                study_id2file_name[str(study_id)] = input_study_file_list
+                # add the key to study_id2cohort_label
                 try:
-                    query = f"select cohort_label from app_user_job_status where id = {reference_job_id}"
+                    query = f"select cohort_label from app_user_job_status where id = {study_id}"
                     cursor.execute(query)
                     records = cursor.fetchall()
-                    study_id2cohort_label[str(reference_job_id)] = records[0][0]
+                    study_id2cohort_label[str(study_id)] = records[0][0]
                 except Exception as e:
                     print(f'Error in reading cohort labels: {e}')
-                    study_id2cohort_label[str(reference_job_id)] = "NA"
-
-                # for each other study, load the peak intensity and do log2 transformation
-                for study_id in other_job_ids:
-                    print(study_id)
-                    print(freq_grid_search_dir_name)
-                    # input_study_pkl_file = os.path.join(output_dir, f'{result_name}_renamed.pkl')
-                    input_study_pkl_file = os.path.join(f"{script_path}/{study_id}/{freq_grid_search_dir_name}",
-                                                        f"{study_id}_renamed.pkl")
-                    if os.path.exists(input_study_pkl_file):
-                        # input_study = load_mspeaks_from_pickle(input_study_pkl_file)
-                        input_study = MSPeaks()
-                        input_study.load(input_study_pkl_file)
-                        input_study_file_list = input_study.peak_intensity.columns.to_list()
-                        # add a key to study_id2file_name
-                        study_id2file_name[str(study_id)] = input_study_file_list
-                        # add the key to study_id2cohort_label
-                        try:
-                            query = f"select cohort_label from app_user_job_status where id = {study_id}"
-                            cursor.execute(query)
-                            records = cursor.fetchall()
-                            study_id2cohort_label[str(study_id)] = records[0][0]
-                        except Exception as e:
-                            print(f'Error in reading cohort labels: {e}')
-                            study_id2cohort_label[str(study_id)] = "NA"
-                        subset_chosen = [i for i in chosen_feats if i in input_study.peak_intensity.index]
-                        input_peaks = input_study.peak_intensity.loc[subset_chosen, :].copy()
-                        input_study_nan_mask = input_study.missing_val_mask.loc[subset_chosen, :].copy()
-                        input_peaks = np.log2(input_peaks)
-                        # input_peaks = min_max_scale(input_peaks)
-                        # combined_study = combined_study.join(input_peaks, lsuffix=reference_job_id, rsuffix=study_id, how='outer')
-                        combined_study = combined_study.join(input_peaks, how='outer')
-                        combined_study_nan_mask = combined_study_nan_mask.join(input_study_nan_mask, how='outer')
-
-                # Verify that the sample names are the same in the combined study as they are in the combined metadata
-                combined_study.fillna(combined_study.mean(), inplace=True)
-                combined_study.to_csv(os.path.join(align_save_dir_freq_th, 'combined_study.csv'))
-
-                print(combined_study_nan_mask)
-                combined_study_nan_mask.fillna(True, inplace=True)
-                combined_study_nan_mask.to_csv(os.path.join(align_save_dir_freq_th, 'combined_study_nan_mask.csv'))
-                # combined_study_nan_mask do a transpose to get a new dataframe with file_name as index and peak intensity as columns
-                combined_study_nan_mask = combined_study_nan_mask.T
-                # calculate the number of missing values for each file (missing value for each row)
-                # that is count the true from each row and divide by the number of columns
-                combined_study_nan_mask['missing_values'] = combined_study_nan_mask.sum(axis=1) / \
-                                                            combined_study_nan_mask.shape[1]
-                # reformt the combined_study_nan_mask['missing_values'] to save only first 2 decimal points and convert to percentage
-                combined_study_nan_mask['missing_values'] = combined_study_nan_mask['missing_values'].apply(
-                    lambda x: round(x * 100, 2))
-                # add % to combined_study_nan_mask['missing_values'] value
-                combined_study_nan_mask['missing_values'] = combined_study_nan_mask['missing_values'].astype(str) + '%'
-
-                # check if combined_study is empty
-                if combined_study.empty:
-                    print("combined_study is empty")
-                    continue
-
-                # TODO: correct for cohort effects using cohort_labels (study id)
-                # get the study_id2file_name
-                print(study_id2file_name.keys)
-                # build a metadata_df that has file_name, study_id
-                metadata_df = pd.DataFrame()
-                # use the columns from combined_study to build the metadata_df file_name column
-                metadata_df['file_name'] = combined_study.columns
-                # create a new column study_id, that is the study_id of the file_name from study_id2file_name
-                metadata_df['mzlearn_cohort_id'] = metadata_df['file_name'].apply(
-                    lambda x: [k for k, v in study_id2file_name.items() if x in v][0])
-                print(metadata_df)
-                metadata_df.to_csv(os.path.join(align_save_dir_freq_th, 'combined_study_cohort_ids.csv'))
-
-                # need to know the study id for each study used here use job id for each file
-                try:
-                    cohort_labels = metadata_df['mzlearn_cohort_id'].to_list()
-                    data_corrected = standardize_across_cohorts(combined_study, cohort_labels,
-                                                                method=cohort_correction_method)
-                    # data_corrected = combined_study
-                    # calculate number of peaks and number of files from data_corrected
-                    num_peaks = data_corrected.shape[0]
-                    num_files = data_corrected.shape[1]
-                except Exception as e:
-                    print(f'Error in standardization: {e}')
-                    continue
-
-                ########################################################################################################
-                # %% Look at the PCA of the combined study
-                # fill nan with  0
-                try:
-                    data_corrected = data_corrected.fillna(0)
-                    pca = PCA(n_components=2)
-                    pca_result = pca.fit_transform(data_corrected.T)
-                    pca_df = pd.DataFrame(pca_result, columns=['PC1', 'PC2'], index=data_corrected.columns)
-                    # edit the metadata_df['mzlearn_cohort_id'].to_list() list to inclucde cohort label
-                    mzlearn_cohort_ids = metadata_df['mzlearn_cohort_id'].to_list()
-                    new_mzlearn_cohort_ids = []
-                    for mzlearn_cohort_id in mzlearn_cohort_ids:
-                        new_mzlearn_cohort_ids.append(
-                            f"{mzlearn_cohort_id} ({study_id2cohort_label[mzlearn_cohort_id]})")
-                    pca_df['mzlearn_cohort_id'] = new_mzlearn_cohort_ids
-                    pca_df['file_name'] = metadata_df['file_name'].to_list()
-                    pca_df['MV percentage'] = combined_study_nan_mask['missing_values'].to_list()
-                    # based on the file_name, get the run order from all_job_sample_info
-                    run_order = []
-                    for file_name in pca_df['file_name']:
-                        run_order.append(
-                            all_job_sample_info[all_job_sample_info['file_name'] == file_name]['run_order'].values[0])
-                    pca_df['run_order'] = run_order
-                    # pca_df['Study_num'] = metadata_df['Study_num']
-                    # pca_df['label'] = metadata_df[pretrain_label_col]
-                    pca_df.to_csv(os.path.join(align_save_dir_freq_th, f'pca_df.csv'))
-
-                    # # plot the PCA and add file_name as hover and add title to show num_peaks and num_files
-                    # hover_data = ['MV percentage']
-                    # graph = px.scatter(pca_df, x="PC1", y="PC2", color='mzlearn_cohort_id',
-                    #                    color_discrete_sequence=px.colors.qualitative.Plotly,
-                    #                    title=f'PCA with {num_peaks} peaks and {num_files} files',
-                    #                    hover_name='file_name',
-                    #                    hover_data=hover_data)
-                    #
-                    # graph.update_traces(marker={'size': 4.5})
-                    # graph_div = plot({'data': graph}, output_type='div')
-                    # pickle.dump(graph_div, open(f'{align_save_dir_freq_th}/pca_plot.pkl', 'wb'))
-
-                    ########################################################################################################
-                    # %% Look at the UMAP of the combined study
-                    reducer = umap.UMAP()
-                    umap_result = reducer.fit_transform(data_corrected.T)
-                    umap_df = pd.DataFrame(umap_result, columns=['UMAP1', 'UMAP2'], index=data_corrected.columns)
-                    umap_df['mzlearn_cohort_id'] = new_mzlearn_cohort_ids
-                    umap_df['file_name'] = metadata_df['file_name'].to_list()
-                    umap_df['MV percentage'] = combined_study_nan_mask['missing_values'].to_list()
-                    # umap_df['Study_num'] = metadata_df['Study_num']
-                    # umap_df['label'] = metadata_df[pretrain_label_col]
-                    # based on the file_name, get the run order from all_job_sample_info
-                    run_order = []
-                    for file_name in umap_df['file_name']:
-                        run_order.append(
-                            all_job_sample_info[all_job_sample_info['file_name'] == file_name]['run_order'].values[0])
-                    umap_df['run_order'] = run_order
-                    umap_df.to_csv(os.path.join(align_save_dir_freq_th, f'umap_df.csv'))
-
-                    # hover_data = ['MV percentage']
-                    # graph = px.scatter(umap_df, x="UMAP1", y="UMAP2", color='mzlearn_cohort_id',
-                    #                    color_discrete_sequence=px.colors.qualitative.Plotly,
-                    #                    title=f'UMAP with {num_peaks} peaks and {num_files} files',
-                    #                    hover_name='file_name',
-                    #                    hover_data=hover_data)
-                    # graph.update_traces(marker={'size': 4.5})
-                    # graph_div = plot({'data': graph}, output_type='div')
-                    # pickle.dump(graph_div, open(f'{align_save_dir_freq_th}/umap_plot.pkl', 'wb'))
-                except Exception as e:
-                    print(f'Error in PCA and UMAP: {e}')
-
-                ########################################################################################################
-                # save the combined peak intensity to gcp bucket
-                # gcp_file_path = f"mzlearn-webapp.appspot.com/mzlearn_pretraining/peak_combine_results/{peak_combine_job_id}/{freq_grid_search_dir_name}
-                # save all results to gcp as well
-                gcp_file_path = f"mzlearn_pretraining/peak_combine_results/{peak_combine_job_id}/{freq_grid_search_dir_name}"
-                # upload all files from folders: keras_autoencoder_models0 and classical_models to all_resuls_file_folder_gcp_path
-                bucket_name = 'mzlearn-webapp.appspot.com'
-                upload_to_gcs(align_save_dir_freq_th, bucket_name, gcp_file_path)
-
-                # mzlearn-webapp.appspot.com/mzlearn_pretraining/peak_combine_results/{job_id}/alignment_df.csv
-                # gcp_file_path = f"mzlearn-webapp.appspot.com/mzlearn_pretraining/peak_combine_results/{peak_combine_job_id}/{freq_grid_search_dir_name}/combined_study.csv"
-                # with fs.open(gcp_file_path, 'w') as f:
-                #     combined_study.to_csv(f, index=True)
-                # print("combined peak intensity saved to gcp bucket")
+                    study_id2cohort_label[str(study_id)] = "NA"
+                subset_chosen = [i for i in chosen_feats if i in input_study.peak_intensity.index]
+                input_peaks = input_study.peak_intensity.loc[subset_chosen, :].copy()
+                input_study_nan_mask = input_study.missing_val_mask.loc[subset_chosen, :].copy()
+                input_peaks = np.log2(input_peaks)
+                # input_peaks = min_max_scale(input_peaks)
+                # combined_study = combined_study.join(input_peaks, lsuffix=reference_job_id, rsuffix=study_id, how='outer')
+                combined_study = combined_study.join(input_peaks, how='outer')
+                combined_study_nan_mask = combined_study_nan_mask.join(input_study_nan_mask, how='outer')
+
+        # Verify that the sample names are the same in the combined study as they are in the combined metadata
+        combined_study.fillna(combined_study.mean(), inplace=True)
+        combined_study.to_csv(os.path.join(align_save_dir_freq_th, 'combined_study.csv'))
+
+        print(combined_study_nan_mask)
+        combined_study_nan_mask.fillna(True, inplace=True)
+        combined_study_nan_mask.to_csv(os.path.join(align_save_dir_freq_th, 'combined_study_nan_mask.csv'))
+        # combined_study_nan_mask do a transpose to get a new dataframe with file_name as index and peak intensity as columns
+        combined_study_nan_mask = combined_study_nan_mask.T
+        # calculate the number of missing values for each file (missing value for each row)
+        # that is count the true from each row and divide by the number of columns
+        combined_study_nan_mask['missing_values'] = combined_study_nan_mask.sum(axis=1) / \
+                                                    combined_study_nan_mask.shape[1]
+        # reformt the combined_study_nan_mask['missing_values'] to save only first 2 decimal points and convert to percentage
+        combined_study_nan_mask['missing_values'] = combined_study_nan_mask['missing_values'].apply(
+            lambda x: round(x * 100, 2))
+        # add % to combined_study_nan_mask['missing_values'] value
+        combined_study_nan_mask['missing_values'] = combined_study_nan_mask['missing_values'].astype(str) + '%'
+
+        # check if combined_study is empty
+        if combined_study.empty:
+            print("combined_study is empty")
+            continue
+
+        # get the study_id2file_name
+        print(study_id2file_name.keys)
+        # build a metadata_df that has file_name, study_id
+        metadata_df = pd.DataFrame()
+        # use the columns from combined_study to build the metadata_df file_name column
+        metadata_df['file_name'] = combined_study.columns
+        # create a new column study_id, that is the study_id of the file_name from study_id2file_name
+        metadata_df['mzlearn_cohort_id'] = metadata_df['file_name'].apply(
+            lambda x: [k for k, v in study_id2file_name.items() if x in v][0])
+        print(metadata_df)
+        metadata_df.to_csv(os.path.join(align_save_dir_freq_th, 'combined_study_cohort_ids.csv'))
+
+        # need to know the study id for each study used here use job id for each file
+        try:
+            cohort_labels = metadata_df['mzlearn_cohort_id'].to_list()
+            data_corrected = standardize_across_cohorts(combined_study, cohort_labels,
+                                                        method=cohort_correction_method)
+            # data_corrected = combined_study
+            # calculate number of peaks and number of files from data_corrected
+            num_peaks = data_corrected.shape[0]
+            num_files = data_corrected.shape[1]
+        except Exception as e:
+            print(f'Error in standardization: {e}')
+            continue
+
+        ########################################################################################################
+        # Look at the PCA of the combined study
+        ########################################################################################################
+        # fill nan with  0
+        try:
+            data_corrected = data_corrected.fillna(0)
+            pca = PCA(n_components=2)
+            pca_result = pca.fit_transform(data_corrected.T)
+            pca_df = pd.DataFrame(pca_result, columns=['PC1', 'PC2'], index=data_corrected.columns)
+            # edit the metadata_df['mzlearn_cohort_id'].to_list() list to inclucde cohort label
+            mzlearn_cohort_ids = metadata_df['mzlearn_cohort_id'].to_list()
+            new_mzlearn_cohort_ids = []
+            for mzlearn_cohort_id in mzlearn_cohort_ids:
+                new_mzlearn_cohort_ids.append(
+                    f"{mzlearn_cohort_id} ({study_id2cohort_label[mzlearn_cohort_id]})")
+            pca_df['mzlearn_cohort_id'] = new_mzlearn_cohort_ids
+            pca_df['file_name'] = metadata_df['file_name'].to_list()
+            pca_df['MV percentage'] = combined_study_nan_mask['missing_values'].to_list()
+            # based on the file_name, get the run order from all_job_sample_info
+            run_order = []
+            for file_name in pca_df['file_name']:
+                run_order.append(
+                    all_job_sample_info[all_job_sample_info['file_name'] == file_name]['run_order'].values[0])
+            pca_df['run_order'] = run_order
+            pca_df.to_csv(os.path.join(align_save_dir_freq_th, f'pca_df.csv'))
+
+            ########################################################################################################
+            # %% Look at the UMAP of the combined study
+            reducer = umap.UMAP()
+            umap_result = reducer.fit_transform(data_corrected.T)
+            umap_df = pd.DataFrame(umap_result, columns=['UMAP1', 'UMAP2'], index=data_corrected.columns)
+            umap_df['mzlearn_cohort_id'] = new_mzlearn_cohort_ids
+            umap_df['file_name'] = metadata_df['file_name'].to_list()
+            umap_df['MV percentage'] = combined_study_nan_mask['missing_values'].to_list()
+            # umap_df['Study_num'] = metadata_df['Study_num']
+            # umap_df['label'] = metadata_df[pretrain_label_col]
+            # based on the file_name, get the run order from all_job_sample_info
+            run_order = []
+            for file_name in umap_df['file_name']:
+                run_order.append(
+                    all_job_sample_info[all_job_sample_info['file_name'] == file_name]['run_order'].values[0])
+            umap_df['run_order'] = run_order
+            umap_df.to_csv(os.path.join(align_save_dir_freq_th, f'umap_df.csv'))
+        except Exception as e:
+            print(f'Error in PCA and UMAP: {e}')
+
+        ########################################################################################################
+        # look at the targed peak info from the combined study and plot bar plots based on alignment_df
+        ########################################################################################################
+        # based on the alignment_df, for each study build a dictionary of reference_study_peak_id2targets
+        # print(f"alignment_df is {alignment_df}")
+        # drop the rows that have nan in all columns
+        alignment_df_path = f"{align_save_dir_freq_th}/alignment_df.csv"
+        alignment_df = pd.read_csv(alignment_df_path)
+        alignment_df = alignment_df.dropna(how='all')
+        print(f"alignment_df is {alignment_df}")
+
+        # based on the column names of alignment_df, get the study_id
+        # loop through each column of alignment_df and find the corresponding study_id
+        study_id2list_of_peak_matches = {}
+        for column in alignment_df.columns:
+            # for each study_id, create a list of list of peak matched to a peak id
+            list_of_peak_target_matches = []
+            # loop through each row of this column
+            # get the study_id from the column name
+            study_id = column
+            # based on the study_id, get the targeted data info from mzlearn run that was saved before
+            # local target file path f"{script_path}/{job_id}/targets.csv"
+            target_file_path = f"{script_path}/{study_id}/targets.csv"
+            if os.path.exists(target_file_path):
+                targets_df = pd.read_csv(target_file_path)
+                # loop through each row of this column
+                for row in alignment_df[column]:
+                    peak_id = row
+                    # print(f"peak_id is {peak_id}")
+                    # find the HMDB_match value in the targets_df from the row with feats == peak_id
+                    # if found, then add the HMDB_match value to list_of_peak_target_matches
+                    matched_target = "NA"
+                    if not pd.isna(peak_id):
+                        target_row = targets_df[targets_df['feats'] == peak_id]
+                        if not target_row.empty:
+                            matched_target = target_row['HMDB_match'].values[0]
+                    list_of_peak_target_matches.append(matched_target)
+
+            # read the target file if it exists
+            study_id2list_of_peak_matches[study_id] = list_of_peak_target_matches
+
+        # how long each key of study_id2list_of_peak_matches is
+        for key, value in study_id2list_of_peak_matches.items():
+            print(f"study_id: {key} has {len(value)} peaks matched")
+
+        # start comparison between the studies, each other_job_ids compared to reference_job_id once
+        # get the study_id2list_of_peak_matches for the reference_job_id
+        reference_study_id_list_of_peak_matches = study_id2list_of_peak_matches[str(reference_job_id)]
+        # loop through each study_id in other_job_ids
+        alignment_targets_tracking_results = pd.DataFrame()
+        for study_id in other_job_ids:
+            print(f"other study_id: {study_id}")
+            other_study_id_list_of_peak_matches = study_id2list_of_peak_matches[str(study_id)]
+
+            if len(other_study_id_list_of_peak_matches) > 0:
+                print(f"this study has targeted peaks")
+
+                # combine reference_study_id_list_of_peak_matches and other_study_id_list_of_peak_matches
+                all_peak_matches = reference_study_id_list_of_peak_matches + other_study_id_list_of_peak_matches
+                # drop all "NA" and None from all_peak_matches
+                all_peak_matches = [i for i in all_peak_matches if i != "NA"]
+                # count the number of unique peaks in all_peak_matches
+                unique_peaks = len(set(all_peak_matches))
+
+                # compare the reference_study_id_list_of_peak_matches and other_study_id_list_of_peak_matches
+                # to see how many peaks are common
+                correct_alignment_peaks = 0
+                miss_aligned_peaks = 0
+                for ref_peak_matches, other_peak_matches in zip(reference_study_id_list_of_peak_matches,
+                                                                other_study_id_list_of_peak_matches):
+                    # if both ref_peak_matches and other_peak_matches are not "NA" and not None
+                    if ref_peak_matches != "NA" and other_peak_matches != "NA":
+                        if ref_peak_matches == other_peak_matches:
+                            correct_alignment_peaks += 1
+                        else:
+                            miss_aligned_peaks += 1
+
+                # build a row to add to alignment_targets_tracking_results
+                row = {'reference_study_id': str(int(reference_job_id)),
+                       'other_study_id': str(int(study_id)),
+                       'total_possible_aligned_targets': unique_peaks,
+                       'correct_alignment_targets': correct_alignment_peaks,
+                       'miss_aligned_peaks': miss_aligned_peaks,
+                       'correct_alignment_percentage': correct_alignment_peaks / unique_peaks * 100}
+                alignment_targets_tracking_results = alignment_targets_tracking_results.append(row, ignore_index=True)
+
+        # save the alignment_targets_tracking_results to the freq_grid_search_dir_name folder
+        alignment_targets_tracking_results.to_csv(os.path.join(align_save_dir_freq_th, f'alignment_targets_tracking_results.csv'))
+
+        ########################################################################################################
+        # save the combined peak intensity to gcp bucket
+        ########################################################################################################
+        # gcp_file_path = f"mzlearn-webapp.appspot.com/mzlearn_pretraining/peak_combine_results/{peak_combine_job_id}/{freq_grid_search_dir_name}
+        # save all results to gcp as well
+        gcp_file_path = f"mzlearn_pretraining/peak_combine_results/{peak_combine_job_id}/{freq_grid_search_dir_name}"
+        # upload all files from folders: keras_autoencoder_models0 and classical_models to all_resuls_file_folder_gcp_path
+        bucket_name = 'mzlearn-webapp.appspot.com'
+        upload_to_gcs(align_save_dir_freq_th, bucket_name, gcp_file_path)
 
+    ####################################################################################################################
     # save the grid search summary to gcp bucket
-    print(grid_search_summary_df)
-    grid_search_summary_df.to_csv(os.path.join(align_save_dir, 'grid_search_summary_df.csv'), index=False)
+    ####################################################################################################################
+    print(gridsearch_params_combinations)
+    # edit the gridsearch_params_combinations
+    #reference_freq_th = row['reference_cohort_freq_threshold']
+    # freq_th = row['remaining_cohorts_freq_threshold']
+    # convert the values from reference_cohort_freq_threshold and remaining_cohorts_freq_threshold to percentage and with % sign
+    gridsearch_params_combinations['reference_cohort_freq_threshold'] = gridsearch_params_combinations[
+        'reference_cohort_freq_threshold'].apply(lambda x: f"{x * 100}%")
+    gridsearch_params_combinations['remaining_cohorts_freq_threshold'] = gridsearch_params_combinations[
+        'remaining_cohorts_freq_threshold'].apply(lambda x: f"{x * 100}%")
+    gridsearch_params_combinations.to_csv(os.path.join(align_save_dir, 'grid_search_summary_df.csv'), index=False)
     gcp_file_path = f"mzlearn-webapp.appspot.com/mzlearn_pretraining/peak_combine_results/{peak_combine_job_id}/grid_search_summary_df.csv"
     with fs.open(gcp_file_path, 'w') as f:
-        grid_search_summary_df.to_csv(f, index=True)
+        gridsearch_params_combinations.to_csv(f, index=True)
 
     ####################################################################################################################
     # update the database
