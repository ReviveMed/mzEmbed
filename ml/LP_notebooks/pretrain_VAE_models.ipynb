{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune VAE models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneDeprecationWarning: You're importing the Neptune client library via the deprecated `neptune.new` module, which will be removed in a future release. Import directly from `neptune` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader\t LabelEncoder\t TensorDataset\t get_pretrain_input_data\t label_encoder\t ml_code_path\t optim\t os\t pd\t \n",
      "torch\t \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "ml_code_path='/home/leilapirhaji/mz_embed_engine/ml'\n",
    "os.chdir(ml_code_path)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from get_pretrain_encoder import get_pretrain_input_data\n",
    "\n",
    "%who"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting Finetune datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leilapirhaji/mz_embed_engine/ml/get_pretrain_encoder.py:60: DtypeWarning: Columns (1,8,28,30,31,32,33,34,46,50,51,52,53,54,55,56,57,58) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  y_data_all = pd.read_csv(pretrain_y_all, index_col=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((14391, 2736),\n",
       " (14391, 58),\n",
       " (3074, 2736),\n",
       " (3074, 58),\n",
       " (3083, 2736),\n",
       " (3083, 58))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_data_location='/home/leilapirhaji/PROCESSED_DATA_2'\n",
    "pretrain_save_dir='/home/leilapirhaji/pretrained_VAE_models' \n",
    "\n",
    "\n",
    "(X_data_all, y_data_all, X_data_train, y_data_train, X_data_val, y_data_val, X_data_test, y_data_test)=get_pretrain_input_data(input_data_location)\n",
    "\n",
    "\n",
    "X_data_train.shape, y_data_train.shape, X_data_val.shape, y_data_val.shape, X_data_test.shape, y_data_test.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-train VAE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14391, 2736),\n",
       " (14391, 58),\n",
       " (3074, 2736),\n",
       " (3074, 58),\n",
       " (3083, 2736),\n",
       " (3083, 58))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_train.shape, y_data_train.shape, X_data_val.shape, y_data_val.shape, X_data_test.shape, y_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 64.60926751030816\n",
      "Validation Loss: 64.5248378831513\n",
      "Epoch 2/3, Loss: 64.5556440226237\n",
      "Validation Loss: 64.50877707345145\n",
      "Epoch 3/3, Loss: 64.54763275146485\n",
      "Validation Loss: 64.50805461649992\n",
      "Model kwargs saved to /home/leilapirhaji/pretrained_VAE_models/model_hyperparameters.json\n",
      "Model saved to /home/leilapirhaji/pretrained_VAE_models/vae_model.pth\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import models_VAE\n",
    "importlib.reload(models_VAE)\n",
    "from models_VAE import VAE  # Import the VAE model class\n",
    "\n",
    "import train_pretrain_vae\n",
    "importlib.reload(train_pretrain_vae)\n",
    "from train_pretrain_vae import pretrain_vae\n",
    "\n",
    "\n",
    "# Simulated data for example purposes\n",
    "\n",
    "pretrain_vae(X_data_train, y_data_train, X_data_val, y_data_val, X_data_test, y_data_test, \n",
    "                latent_size=128, \n",
    "                num_hidden_layers=3, dropout_rate=0.2, activation='leakyrelu', \n",
    "                use_batch_norm=True, epochs=3, learning_rate=1e-3, \n",
    "                save_path=pretrain_save_dir, model_name='vae_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder hidden sizes: [1242, 563, 256]\n",
      "Decoder hidden sizes should mirror encoder: Sequential(\n",
      "  (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (1): LeakyReLU(negative_slope=0.01)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=563, bias=True)\n",
      "  (4): LeakyReLU(negative_slope=0.01)\n",
      "  (5): Dropout(p=0.2, inplace=False)\n",
      "  (6): Linear(in_features=563, out_features=1242, bias=True)\n",
      "  (7): LeakyReLU(negative_slope=0.01)\n",
      "  (8): Dropout(p=0.2, inplace=False)\n",
      "  (9): Linear(in_features=1242, out_features=2736, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import models_VAE\n",
    "importlib.reload(models_VAE)\n",
    "from models_VAE import VAE  # Import the VAE model class\n",
    "\n",
    "vae = VAE(input_size=2736, latent_size=128, num_hidden_layers=3)\n",
    "print(\"Encoder hidden sizes:\", vae.encoder.hidden_sizes)\n",
    "print(\"Decoder hidden sizes should mirror encoder:\", vae.decoder.network)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_3160887/2290562983.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  vae.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "import models_VAE\n",
    "importlib.reload(models_VAE)\n",
    "from models_VAE import VAE  # Import the VAE model class\n",
    "\n",
    "\n",
    "model_path = f'{pretrain_save_dir}/vae_model.pth'\n",
    "hyperparameters_path = f'{pretrain_save_dir}/model_hyperparameters.json'\n",
    "#Step 1: Load hyperparameters from the JSON file\n",
    "with open(hyperparameters_path, 'r') as f:\n",
    "    hyperparameters = json.load(f)\n",
    "\n",
    "# Step 2: Initialize the VAE model using the loaded hyperparameters\n",
    "vae = VAE(**hyperparameters)\n",
    "\n",
    "# Step 3: Load the saved model state (weights) into the VAE model\n",
    "vae.load_state_dict(torch.load(model_path))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vae\u001b[39m.\u001b[39;49mencoder\u001b[39m.\u001b[39;49mhidden_sizes()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "vae.encoder.hidden_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (encoder): Dense_Layers(\n",
      "    (network): Sequential(\n",
      "      (0): Linear(in_features=2736, out_features=1242, bias=True)\n",
      "      (1): BatchNorm1d(1242, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "      (3): Dropout(p=0.2, inplace=False)\n",
      "      (4): Linear(in_features=1242, out_features=563, bias=True)\n",
      "      (5): BatchNorm1d(563, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): LeakyReLU(negative_slope=0.01)\n",
      "      (7): Dropout(p=0.2, inplace=False)\n",
      "      (8): Linear(in_features=563, out_features=256, bias=True)\n",
      "      (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): LeakyReLU(negative_slope=0.01)\n",
      "      (11): Dropout(p=0.2, inplace=False)\n",
      "      (12): Linear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder): Dense_Layers(\n",
      "    (network): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "      (3): Dropout(p=0.2, inplace=False)\n",
      "      (4): Linear(in_features=256, out_features=563, bias=True)\n",
      "      (5): BatchNorm1d(563, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): LeakyReLU(negative_slope=0.01)\n",
      "      (7): Dropout(p=0.2, inplace=False)\n",
      "      (8): Linear(in_features=563, out_features=1242, bias=True)\n",
      "      (9): BatchNorm1d(1242, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): LeakyReLU(negative_slope=0.01)\n",
      "      (11): Dropout(p=0.2, inplace=False)\n",
      "      (12): Linear(in_features=1242, out_features=2736, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print (vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
